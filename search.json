[{"path":"https://mufflyt.github.io/tyler/mysteryshopper/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2024 Tyler Muffly Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/articles/Poisson_Regression_and_Effects.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Analyzing Wait Times for Appointments: Poisson Regression and Interaction Effects","text":"healthcare, understanding wait times medical appointments crucial factor improving patient care. vignette demonstrates analyze waiting times appointments using Poisson regression, appropriate count data, number business days patient’s appointment. Specifically, investigate insurance type medical scenario influence waiting times explore interaction effects two variables. Additionally, use Estimated Marginal Means (EMMs) interpret results, allowing clearer comparisons across groups.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/articles/Poisson_Regression_and_Effects.html","id":"data-preparation","dir":"Articles","previous_headings":"Introduction","what":"1. Data Preparation","title":"Analyzing Wait Times for Appointments: Poisson Regression and Interaction Effects","text":"begin analysis, need prepare load data. data ’ll use contains following columns: dataset contains following columns: Scenario: Different medical conditions (e.g., Tubo-Ovarian Abscess, Pregnancy Tubal Ligation, UTI, Vaginitis). Insurance: Patient insurance types (e.g., Medicaid, Blue Cross/Blue Shield). Business Days Appointment: Number days takes patients secure appointment. NPI: National Provider Identifier, representing healthcare providers (used random effect).","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/articles/Poisson_Regression_and_Effects.html","id":"simulating-example-data","dir":"Articles","previous_headings":"Introduction > 1. Data Preparation","what":"Simulating Example Data","title":"Analyzing Wait Times for Appointments: Poisson Regression and Interaction Effects","text":"also simulate data demonstration purposes. , ’ve simulated data outcome variable, business_days_until_appointment, follows Poisson distribution, suitable model count data like . insurance column includes two types insurance, Medicaid Blue Cross/Blue Shield, scenario column includes different medical situations.","code":"# Load required libraries library(dplyr) ## Error in get(paste0(generic, \".\", class), envir = get_method_env()) :  ##   object 'type_sum.accel' not found ##  ## Attaching package: 'dplyr' ## The following objects are masked from 'package:stats': ##  ##     filter, lag ## The following objects are masked from 'package:base': ##  ##     intersect, setdiff, setequal, union library(ggplot2) library(lme4) ## Loading required package: Matrix library(emmeans) ## Welcome to emmeans. ## Caution: You lose important information if you filter this package's results. ## See '? untidy' library(knitr) library(tidyr) ##  ## Attaching package: 'tidyr' ## The following objects are masked from 'package:Matrix': ##  ##     expand, pack, unpack # Example data preparation set.seed(123) df <- data.frame(   scenario = rep(c(\"TOA\", \"Pregnancy after Tubal Ligation\", \"UTI\", \"Vaginitis\"), each = 50),   insurance = rep(c(\"Medicaid\", \"Blue Cross/Blue Shield\"), times = 100),   business_days_until_appointment = rpois(200, lambda = 20),   NPI = sample(1:20, 200, replace = TRUE) )"},{"path":[]},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/articles/Poisson_Regression_and_Effects.html","id":"fit-the-interaction-model","dir":"Articles","previous_headings":"2. Fitting a Poisson Regression Model","what":"2.1 Fit the Interaction Model","title":"Analyzing Wait Times for Appointments: Poisson Regression and Interaction Effects","text":"analyze effect insurance scenario waiting times, fit Poisson regression model using glmer function lme4 package. model accounts interaction insurance type scenario, well random intercept NPI (since different healthcare providers might different waiting times). Poisson regression model assumes count data (waiting time days) follows Poisson distribution allows us estimate effects predictor variables (insurance scenario) outcome (business_days_until_appointment). glmer function includes random intercept NPI, accounting fact healthcare providers may systematically different wait times. Poisson regression model assumes count data (waiting time days) follows Poisson distribution allows us estimate effects predictor variables (insurance scenario) outcome (business_days_until_appointment). glmer function includes random intercept NPI, accounting fact healthcare providers may systematically different wait times.","code":"interaction_model <- glmer(   business_days_until_appointment ~ scenario * insurance + (1 | NPI),   data = df,   family = poisson(link = \"log\") )"},{"path":[]},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/articles/Poisson_Regression_and_Effects.html","id":"extract-emms","dir":"Articles","previous_headings":"3. Estimated Marginal Means (EMMs)","what":"3.1 Extract EMMs","title":"Analyzing Wait Times for Appointments: Poisson Regression and Interaction Effects","text":"now use Estimated Marginal Means (EMMs) obtain adjusted estimates waiting times. EMMs allow us make comparisons levels predictor variables (e.g., insurance type), controlling factors model. emmeans function computes estimated marginal means combination scenario insurance type, providing us adjusted waiting times. adjusted means account variables model, helping us focus effect insurance type wait times.","code":"interaction_result <- emmeans::emmeans(interaction_model, ~ scenario * insurance, type = \"response\") interaction_data <- as.data.frame(interaction_result)"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/articles/create_isochrones.html","id":"overview","dir":"Articles","previous_headings":"","what":"Overview","title":"Gathering Drive Time Isochrones","text":"create_isochrones_for_dataframe function powerful tool allows calculate isochrones given location using hereR package. Isochrones represent areas can reached specific point within certain travel time distance. visual representations valuable various applications, location analysis, logistics, transportation planning. guide, walk use create_isochrones function.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/articles/create_isochrones.html","id":"geodesic-versus-drive-time-for-patient-travel","dir":"Articles","previous_headings":"","what":"Geodesic versus Drive-Time for Patient Travel","title":"Gathering Drive Time Isochrones","text":"methods calculating patient travel distance hospitals can vary significantly. paper aims provide overview different methods characteristics. primary factor influencing travel distance calculations choice distance measure, specifically, whether ’s driving distance straight-line distance. distinction significant impact results.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/articles/create_isochrones.html","id":"straight-line-distance","dir":"Articles","previous_headings":"Geodesic versus Drive-Time for Patient Travel","what":"Straight-Line Distance","title":"Gathering Drive Time Isochrones","text":"common practice AHRQ calculate shortest “straight-line” distance (geodetic great circle distance) patient location point care (e.g., hospital emergency department). method favored can easily computed using statistical software like SAS®. Agency Healthcare Research Quality (AHRQ): AHRQ employs equation convert straight-line distance drive time. equation includes various parameters like baseline distance, census division dummy variables, urban/rural location dummy variables, error terms. AHRQ utilizes ggmap package geocode addresses hospitals. AHRQ also considers alternative metric, driving distance driving times. can obtained various mapping software Google Maps, MapQuest, OpenStreetMaps, ArcGIS Network Analyst. AHRQ uses patient location geographic centroid patient’s zip code. (https://hcup-us.ahrq.gov/reports/methods/MS2021-02-Distance--Hospital.jsp) March Dimes Maternity Care Deserts: organization also uses drive time metric calculating travel distance. Reference ESRI Methodology: ESRI methodology creating drive-time areas, certain limitations travel times distances. Reference. Limitations: “must granted network analysis privilege use Create Drive-Time Areas.”, “Travel times exceed 9 hours (540 minutes) walking 5 hours (300 minutes) travel times.”, * “Travel distances exceed 27 miles (43.45 kilometers) walking 300 miles (482.8 kilometers) travel distances.” Veteran’s Administration: Veteran’s Administration utilizes drive time calculations. Reference Department Transportation: Department Transportation provides tools distance calculations. Reference","code":"`Di=αBi+Ciβ+ LiΥ + εi`   Where:  - i indexes patients - Di : driving distance - Bi : baseline distance - Ci : vector of census division dummy variables - Li : vector of urban/rural location dummy variables - α : coefficient for baseline distance - β : vector of coefficients for census division dummy variables - Υ : vector of coefficients for urban/rural location dummy variables - εi : mean-zero error term"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/articles/create_isochrones.html","id":"potential-references-comparing-drive-time-vs--geodesic","dir":"Articles","previous_headings":"","what":"Potential References comparing Drive Time vs. Geodesic","title":"Gathering Drive Time Isochrones","text":"Lidsky , Sun Z, Nussbaum DP, Adam MA, Speicher PJ, Blazer DG. “Going extra mile: improved survival pancreatic cancer patients traveling high-volume centers.” Annals Surgery. 2017;266(2):333–8. Bliss RL, Katz JN, Wright EA, Losina E. “Estimating proximity care: straight line zipcode centroid distances acceptable measures?” Medical Care. 2012;50(1):99–106. isprs-archives-XLVIII-4-W7-2023-53-2023.pdf comprehensive overview highlights diversity methods used calculate patient travel distance hospitals potential impact healthcare outcomes.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/articles/create_isochrones.html","id":"prerequisites","dir":"Articles","previous_headings":"Potential References comparing Drive Time vs. Geodesic","what":"Prerequisites","title":"Gathering Drive Time Isochrones","text":"start using create_isochrones function, make sure completed following steps: API Key: need API key. don’t one, can obtain Developer Portal. Environment Variable: Set API key environment variable named HERE_API_KEY. essential secure access services. Load tyler package: Ensure load tyler package, contains create_isochrones function.","code":"library(tyler) ## Loading required package: dplyr ## Error in get(paste0(generic, \".\", class), envir = get_method_env()) :  ##   object 'type_sum.accel' not found ##  ## Attaching package: 'dplyr' ## The following objects are masked from 'package:stats': ##  ##     filter, lag ## The following objects are masked from 'package:base': ##  ##     intersect, setdiff, setequal, union"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/articles/create_isochrones.html","id":"usage","dir":"Articles","previous_headings":"Potential References comparing Drive Time vs. Geodesic","what":"Usage","title":"Gathering Drive Time Isochrones","text":"Now prerequisites place, let’s explore use create_isochrones_for_dataframe function. use API calculate optimal routes directions various modes transportation, including driving, walking, cycling, public transit. provides detailed turn--turn instructions, estimated travel times, route alternatives. simpler using OSRM server running AWS cloud, cost minimal.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/articles/create_isochrones.html","id":"input-parameters","dir":"Articles","previous_headings":"Potential References comparing Drive Time vs. Geodesic > Usage","what":"Input Parameters","title":"Gathering Drive Time Isochrones","text":"create_isochrones function accepts following parameters: * location: sf object representing location isolines calculated. Need separate lat long columns. * range: numeric vector time ranges seconds. time ranges determine extent isolines. * posix_time: POSIXct object representing date time calculation. default set “2023-10-20 08:00:00”. chose date Influenza season people see physicians first appointment day 0800. may need split geometry column separate lat long columns using code: join postmastr file postmastr_clinician_data.csv geocoded results file geocoded_data_to_match_house_number. API allow pass master ID number API data washed geocoding. postmastr package allows parse addresses clinician_data can match addresses together based : state, house number, zip code. done exploratory.io read back Gathering data.R.","code":"geocoded_data1 <- geocoded_data %>%         dplyr::mutate(lat = sf::st_coordinates(.)[, \"Y\"],                long = sf::st_coordinates(.)[, \"X\"])  readr::write_csv(geocoded_data1, \"/NPPES_November_filtered_data_for_geocoding_geocoded_addresses_not_sf.csv\") inner_join(`geocoded_data_to_match_house_number`, by = join_by(   `postmastr.pm.state` == `here.state_code`,    `postmastr.pm.zip` == `here.postal_code`,    `postmastr.pm.house` == `here.house_number`)) inner_join_postmastr_clinician_data <- readr::read_csv(\"data/inner_join_postmastr_clinician_data.csv\")  %>%   st_as_sf(coords = c(\"long\", \"lat\"), crs = 4326) %>%   dplyr::mutate(geometry = location)    create_isochrones_for_dataframe(inner_join_postmastr_clinician_data_sf, range = c(30*60, 60*60, 120*60, 180*60))"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/articles/create_isochrones.html","id":"example","dir":"Articles","previous_headings":"Potential References comparing Drive Time vs. Geodesic > Usage","what":"Example","title":"Gathering Drive Time Isochrones","text":"added code needed read RDS, xlsx, xls, csv files. can also read sf files. needed column called ‘location’ another called geometry. ’s example use create_isochrones_for_dataframe function:","code":"input_file <- \"data/inner_join_postmastr_clinician_data.csv\" isochrones_data <- create_isochrones_for_dataframe(input_file, breaks = c(30*60, 60*60, 120*60, 180*60))  > isochrones_data [1] 1 splay setup instructions: To create isochrones for a specific point(s) use the following code: tryLocationMemo(location = location, range = c(1800, 3600, 7200, 10800)) Setting up the hereR access... Sending 1 request(s) with unlimited RPS to: 'https://isoline.router.hereapi.com/v8/isolines?...' Received 1 response(s) with total size: 2.8 Kb Isoline successfully produced for range: 1800 seconds Sending 1 request(s) with unlimited RPS to: 'https://isoline.router.hereapi.com/v8/isolines?...' Received 1 response(s) with total size: 3.1 Kb Isoline successfully produced for range: 3600 seconds Sending 1 request(s) with unlimited RPS to: 'https://isoline.router.hereapi.com/v8/isolines?...' Received 1 response(s) with total size: 4.8 Kb Isoline successfully produced for range: 7200 seconds Sending 1 request(s) with unlimited RPS to: 'https://isoline.router.hereapi.com/v8/isolines?...' Received 1 response(s) with total size: 6.9 Kb Isoline successfully produced for range: 10800 seconds"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/articles/create_isochrones.html","id":"output","dir":"Articles","previous_headings":"Potential References comparing Drive Time vs. Geodesic > Usage","what":"Output","title":"Gathering Drive Time Isochrones","text":"function returns list isolines different time ranges. isoline represented sf object, making easy visualize analyze. create_isochrones function wrapped memoise nice job caching data. note, none columns feed function come side going API. Therefore, hoping 1:1 relationship rows isochrones. may need mark column different time feed API pseudo-identifier.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/articles/create_isochrones.html","id":"conclusion","dir":"Articles","previous_headings":"Potential References comparing Drive Time vs. Geodesic","what":"Conclusion","title":"Gathering Drive Time Isochrones","text":"create_isochrones function simplifies process calculating isolines location-based analysis. Whether ’re exploring accessibility, optimizing routes, conducting spatial analysis, isochrones provide valuable insights travel times distances. tyler package create_isochrones function, can streamline location-based workflows make informed decisions.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/articles/create_isochrones.html","id":"features-and-bugs","dir":"Articles","previous_headings":"","what":"Features and bugs","title":"Gathering Drive Time Isochrones","text":"ideas features make name handling easier, find bug, best approach either report add !","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/articles/geocode.html","id":"overview","dir":"Articles","previous_headings":"","what":"Overview","title":"Geocoding","text":"geocode function designed help geocode datasets containing addresses change lattitude longitude.","code":""},{"path":[]},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/articles/geocode.html","id":"installation","dir":"Articles","previous_headings":"Overview > Step 1","what":"Installation","title":"Geocoding","text":"can harness power search_by_taxonomy function, essential ensure tyler package installed. can effortlessly install using following command:","code":"library(tyler)"},{"path":[]},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/articles/geocode.html","id":"understanding-geocoding","dir":"Articles","previous_headings":"Example Usage","what":"Understanding Geocoding","title":"Geocoding","text":"Certainly! Geocoding, process converting addresses place names geographic coordinates (latitude longitude), advantages disadvantages. ’s overview pluses minuses geocoding: Pluses Geocoding: Location Accuracy: Geocoding provides precise location information, allowing pinpoint addresses places map high accuracy. crucial various applications mapping, navigation, location-based services. Spatial Analysis: Geocoded data enables spatial analysis, allowing perform tasks like proximity analysis, spatial clustering, spatial interpolation. ’s invaluable geographic information systems (GIS) geographic research. Geographic Visualization: Geocoded data can visualized maps, making easier understand communicate spatial patterns trends. particularly useful data presentation decision-making. Routing Navigation: Geocoding essential navigation systems, delivery route optimization, location-based apps provide directions estimated travel times. Minuses Geocoding: Data Quality Issues: Geocoding accuracy heavily relies quality underlying address data. Inaccurate outdated address information can lead geocoding errors. Costs: Geocoding services software often come associated costs, particularly large-scale geocoding operations. costs can include data licensing fees usage charges. Complexity: Advanced geocoding tasks, reverse geocoding (converting coordinates addresses) batch geocoding, can technically complex may require expertise specialized tools. summary, geocoding offers numerous benefits terms location accuracy, spatial analysis, visualization, navigation. However, also comes challenges related data quality, costs, complexity. Careful consideration factors essential using geocoding various applications. geocode Zip codes several issues limitations associated geocoding solely based zip codes: Lack Precision: Zip codes designed cover group addresses area, specific points. Therefore, geocoding based solely zip code provides approximation location, often center centroid zip code area. lack precision can problematic applications require accurate coordinates. Zip Code Boundaries: Zip code boundaries can irregular may align natural administrative boundaries. means geocoding based zip codes can result coordinates reflect actual geography area, leading inaccuracies. Zip Code Changes: Zip code boundaries assignments can change time due population growth, urban development, administrative reasons. Geocoding based outdated zip code data can lead incorrect locations. Large Zip Codes: zip codes cover vast geographic areas, especially rural regions. Geocoding center large zip code areas can highly inaccurate specific locations within area. Overlapping Zip Codes: cases, zip codes may overlap one another. Geocoding based solely zip code may distinguish overlapping areas, leading ambiguity. Urban Density: densely populated urban areas, zip codes can small densely packed addresses. Geocoding solely zip code may still result lack precision trying identify particular location within zip code.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/articles/geocode.html","id":"step-2-prepare-your-data","dir":"Articles","previous_headings":"Example Usage","what":"Step 2: Prepare Your Data","title":"Geocoding","text":"can provide data either dataframe CSV file argument input_data. hood ggmap::geocode accessing Google API. ggmap::geocode program AHRQ uses. data CSV file, pass file path input_data parameter. Sometimes data needs separate lat long columns. code can : match geocoded_data orginal dataframe? can use postmastr package allows addresses dataframes parsed house number, street, state, etc. individual parts can join together. seems janky af. postmast’s functionality rests order operations must followed ensure correct parsing: prep postal code state city unit house number ranged house number fractional house number house suffix street directionals street suffix street name reconstruct","code":"output_data <- geocode_unique_addresses(     file_path =\"address_for_geocoding.csv\",     google_maps_api_key = \"123\",     output_file_path = \"data/geocoded_unique_addresses.csv\") geocoded_data1 <- geocoded_data %>%         dplyr::mutate(lat = sf::st_coordinates(.)[, \"Y\"],                long = sf::st_coordinates(.)[, \"X\"]) # install.packages(\"remotes\")       # remotes::install_github(\"slu-openGIS/postmastr\")       library(postmastr)       abc <- read_csv(csv_file)       abc %>% pm_identify(var = \"address\") -> sushi2       sushi2_min <- pm_prep(sushi2, var = \"address\", type = \"street\")       pm_postal_all(sushi2_min)       sushi2_min <- pm_postal_parse(sushi2_min)       moDict <- pm_dictionary(locale = \"us\", type = \"state\", case = c(\"title\", \"upper\"))       moDict       pm_state_all(sushi2_min, dictionary = moDict) #Checks to make sure that all states have matches       sushi2_min <- pm_state_parse(sushi2_min, dictionary = moDict)       pm_house_all(sushi2_min)       sushi2_min <- pm_house_parse(sushi2_min)       sushi2_min <- pm_streetDir_parse(sushi2_min)       sushi2_min <- pm_streetSuf_parse(sushi2_min)       sushi2_min <- pm_street_parse(sushi2_min, ordinal = TRUE, drop = TRUE)       sushi2_parsed <- pm_replace(sushi2_min, source = sushi2)       readr::write_csv(sushi2_parsed, \"~/Dropbox (Personal)/workforce/Master_References/NPPES/NPPES_November_filtered_data_address_parsed.csv\")"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/articles/geocode.html","id":"conclusion","dir":"Articles","previous_headings":"","what":"Conclusion","title":"Geocoding","text":"validate_and_remove_invalid_npi function handy tool cleaning validating datasets NPI numbers. following steps outlined vignette, can ensure data contains valid NPIs analysis processing.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/articles/geocode.html","id":"features-and-bugs","dir":"Articles","previous_headings":"","what":"Features and bugs","title":"Geocoding","text":"ideas features make name handling easier, find bug, best approach either report add !","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/articles/get_census_data.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Getting Data from the US Census Bureau for Isochrones","text":"vignette demonstrates usage get_census_data function, designed retrieve Census data states’ block groups. leverages censusapi package query U.S. Census Bureau’s API collect demographic information specified state FIPS codes. ’ll get population block group using censusapi library relies heavily vignette.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/articles/get_census_data.html","id":"centers-for-medicare-and-medicaid-services-doctors-and-clinicians-downloadable-file","dir":"Articles","previous_headings":"Introduction","what":"Centers for Medicare and Medicaid Services Doctors and Clinicians Downloadable file","title":"Getting Data from the US Census Bureau for Isochrones","text":"Downloadable File housed CMS Medicare Compare (aka Physician Compare site): CMS Medicare Compare. downloaded full data set file left join runs risk date give data update monthly. data dictionary file: CMS Medicare Compare Data Dictionar. Doctors Clinicians national downloadable file organized individual clinician level; line unique clinicianenrollment record-group-address (NPI-Ind_enrl_ID-Org_PAC_ID-adrs_id) level. Clinicians multiple Medicare enrollment records /single enrollments linking multiple practice locations listed multiple lines.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/articles/get_census_data.html","id":"state-federal-information-processing-standards-codes","dir":"Articles","previous_headings":"Introduction","what":"State Federal Information Processing Standards Codes","title":"Getting Data from the US Census Bureau for Isochrones","text":"function retrieves Census data using censusapi states’ block groups looping specified list state FIPS codes. brings back data females “B01001_01, 26, 33:49E”. FIPS codes, Federal Information Processing Standards codes, standardized set codes used uniquely identify geographic areas United States. codes assigned various administrative geographical entities, states, counties, cities, . used block groups analysis. GEOID block groups United States can constructed using following format: STATECOUNTYTRACTBLOCK_GROUP. Specifically: * STATE 2-digit code state. * COUNTY 3-digit code county. * TRACT 6-digit code census tract. * BLOCK_GROUP 1-digit code block group within tract.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/articles/get_census_data.html","id":"block-group-as-the-unit-of-measurement","dir":"Articles","previous_headings":"Introduction","what":"Block Group as the Unit of Measurement","title":"Getting Data from the US Census Bureau for Isochrones","text":"United States Census Bureau’s geographic hierarchy, “block group” smaller detailed geographic unit used collecting reporting demographic statistical data. Block groups subdivisions census tracts typically designed contain 600 3,000 people, although can vary depending population density area. Census block group borders defined based visible easily identifiable features roads, rivers, streets, natural boundaries like mountains parks. Census Bureau aims create block group boundaries follow features make easily distinguishable. Block groups used primary units collecting detailed demographic socioeconomic data decennial census American Community Survey (ACS). Census enumerators visit households within block group collect information population, housing, employment, income, education, . densely populated urban area, block group might represent city block small neighborhood within larger city. example, block group cover city blocks downtown Manhattan, New York City.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/articles/get_census_data.html","id":"data-from-the-us-census-bureau","dir":"Articles","previous_headings":"","what":"Data From the US Census Bureau","title":"Getting Data from the US Census Bureau for Isochrones","text":"variables part dataset obtained U.S. Census Bureau’s American Community Survey (ACS). U.S. Census Bureau’s American Community Survey (ACS) ongoing nationwide survey conducted United States Census Bureau. designed collect provide detailed demographic, social, economic, housing information American population. key features aspects ACS: Continuous Survey: ACS conducted continuously throughout year, providing updated current data. Unlike decennial census, occurs every ten years, ACS conducted annually, allowing frequent timely information. Sampling: ACS uses sample-based approach collect data representative subset U.S. population. sample includes households individuals 50 states, District Columbia, Puerto Rico. Questionnaire: Respondents asked complete detailed questionnaire covers wide range topics, including demographics (age, sex, race, etc.), housing characteristics, education, employment, income, health insurance, . Geographic Coverage: ACS provides data various geographic levels, including national, state, county, city, town, even census tract block group. allows detailed analysis communities regions. Data Release: ACS releases data various forms, including one-year estimates, three-year estimates, five-year estimates. One-year estimates available areas larger populations, three-year five-year estimates designed smaller areas subpopulations. five-year estimates provide reliable data small geographic areas specific demographic groups. Accessibility: ACS data publicly accessible can accessed Census Bureau’s website, data.census.gov, data dissemination platforms. Researchers, policymakers, businesses, general public use ACS data various purposes, including policy development, market research, community planning. Importance: ACS critical tool understanding changing demographics socio-economic characteristics U.S. population. used congressional apportionment, resource allocation, grant distribution, various research purposes. Privacy Confidentiality: Census Bureau takes privacy confidentiality seriously. Personal information collected ACS questionnaire protected law, responses aggregated ensure individual respondents identified. Census Long Form Replacement: ACS introduced replace long-form questionnaire part decennial census. long-form collected detailed demographic housing information, ACS continues provide valuable data ongoing basis. represent demographic information block groups within various states. ’s explanation variable: name: variable represents name label block group. total_females: represents total number females block group. female_21_yo: variable represents number females aged 21 years older block group. female_22_to_24_years: represents number females aged 22 24 years block group. female_25_to_29_years: variable represents number females aged 25 29 years block group. female_30_to_34_years: represents number females aged 30 34 years block group. etc. Eventually data matched onto Block Groups. block group shapefile 2021 ACS via National Historical Geographic Information System (NHGIS). calculate many people live within outside drive time isochrones, ’ll need identify percent Census block group lies within isochrones.","code":"name = NAME,     total_females = B01001_026E,     female_21_yo = B01001_033E,     female_22_to_24_years = B01001_034E,     female_25_to_29_years = B01001_035E,     female_30_to_34_years = B01001_036E,     female_35_to_39_years = B01001_037E,     female_40_to_44_years = B01001_038E,     female_45_to_49_years = B01001_039E,     female_50_to_54_years = B01001_040E,     female_55_to_59_years = B01001_041E,     female_60_to_61_years = B01001_042E,     female_62_to_64_years = B01001_043E,     female_65_to_66_years = B01001_044E,     female_67_to_69_years = B01001_045E,     female_70_to_74_years = B01001_046E,     female_75_to_79_years = B01001_047E,     female_80_to_84_years = B01001_048E,     female_85_years_and_older = B01001_049E,     fips_state = state"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/articles/get_census_data.html","id":"function-description","dir":"Articles","previous_headings":"","what":"Function Description","title":"Getting Data from the US Census Bureau for Isochrones","text":"get_census_data function retrieves Census data states’ block groups. ’s brief description parameters: us_fips: vector state FIPS (Federal Information Processing Standards) codes. code uniquely identifies U.S. state. example, Colorado represented FIPS code 08. resulting data combined single dataframe analysis.","code":""},{"path":[]},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/articles/get_census_data.html","id":"installation","dir":"Articles","previous_headings":"Function Description > Step 1","what":"Installation","title":"Getting Data from the US Census Bureau for Isochrones","text":"using tyler::get_census_data function, need install load required packages. can running following code: lists contain metadata general variables variables related race ethnicity.","code":"# Install and load the necessary packages install.packages(\"censusapi\") library(censusapi) library(dplyr) library(tyler)"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/articles/get_census_data.html","id":"all-variables","dir":"Articles","previous_headings":"Function Description > Step 1 > Installation","what":"All Variables","title":"Getting Data from the US Census Bureau for Isochrones","text":"","code":"acs_vars <- censusapi::listCensusMetadata(name = \"acs/acs5\",        vintage = 2019, group = \"B01001\") %>%        readr::write_csv(\"data/acs_vars.csv\")        # This code cleans it up a bit acs_vars <- acs_vars %>%   dplyr::select(-predicateType, -group, -limit, -predicateOnly) %>%   dplyr::filter(!stringr::str_detect(label, fixed(\"!!Male:!!\", ignore_case = TRUE))) %>%   dplyr::filter(!stringr::str_detect(label, fixed(\"Annotation of Margin of Error\", ignore_case = TRUE))) %>%   dplyr::mutate(label = stringr::str_remove(label, regex(\"^Annotation of Estimate!!Total:!!Female:!!\", ignore_case = TRUE))) %>%   dplyr::filter(!stringr::str_detect(label, fixed(\"Margin of Error!!\", ignore_case = TRUE))) %>%   dplyr::mutate(label = stringr::str_remove(label, regex(\"^Annotation of Estimate!!Total:!!Female:!!\", ignore_case = TRUE))) %>%   dplyr::mutate(label = stringr::str_remove(label, regex(\"^Estimate!!Total:!!Female:!!\", ignore_case = TRUE))) %>%   dplyr::filter(!stringr::str_detect(name, fixed(\"EA\")) & !str_detect(label, fixed(\"!!Male:\"))) %>%   dplyr::mutate(numbers = purrr::map_chr(str_extract_all(label, \"^[:digit:]+\"), ~ ifelse(length(.) == 0, NA_character_, paste(.x, collapse = \"\")))) %>%   dplyr::mutate(numbers = as.numeric(numbers)) %>%   dplyr::mutate(numbers = tidyr::replace_na(numbers, 0)) %>%   dplyr::mutate(numbers = as.numeric(numbers)) %>%   dplyr::arrange(numbers)    > acs_vars           name                     label    concept numbers 1  B01001_026E Estimate!!Total:!!Female: SEX BY AGE       0 2  B01001_027E             Under 5 years SEX BY AGE       0 3  B01001_001E          Estimate!!Total: SEX BY AGE       0 4  B01001_028E              5 to 9 years SEX BY AGE       5 5  B01001_029E            10 to 14 years SEX BY AGE      10"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/articles/get_census_data.html","id":"race-variables","dir":"Articles","previous_headings":"Function Description > Step 1 > Installation","what":"Race Variables","title":"Getting Data from the US Census Bureau for Isochrones","text":"","code":"acs_race_vars <- censusapi::listCensusMetadata(name = \"acs/acs5\",        vintage = 2019, group = \"B02001\") %>%       readr::write_csv(\"data/acs_race_vars.csv\")  #output: > acs_race_vars # A tibble: 40 × 7    name         label                                                      concept predicateType group limit predicateOnly    <chr>        <chr>                                                      <chr>   <chr>         <chr> <dbl> <lgl>          1 B02001_010EA Annotation of Estimate!!Total:!!Two or more races:!!Two r… RACE    string        B020…     0 TRUE           2 B02001_010MA Annotation of Margin of Error!!Total:!!Two or more races:… RACE    string        B020…     0 TRUE           3 B02001_001EA Annotation of Estimate!!Total:                             RACE    string        B020…     0 TRUE           4 B02001_001MA Annotation of Margin of Error!!Total:                      RACE    string        B020…     0 TRUE           5 B02001_004EA Annotation of Estimate!!Total:!!American Indian and Alask… RACE    string        B020…     0 TRUE           6 B02001_004MA Annotation of Margin of Error!!Total:!!American Indian an… RACE    string        B020…     0 TRUE           7 B02001_005EA Annotation of Estimate!!Total:!!Asian alone                RACE    string        B020…     0 TRUE           8 B02001_005MA Annotation of Margin of Error!!Total:!!Asian alone         RACE    string        B020…     0 TRUE           9 B02001_002EA Annotation of Estimate!!Total:!!White alone                RACE    string        B020…     0 TRUE          10 B02001_002MA Annotation of Margin of Error!!Total:!!White alone         RACE    string        B020…     0 TRUE"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/articles/get_census_data.html","id":"race-and-ethnicity-variables","dir":"Articles","previous_headings":"Function Description > Step 1 > Installation","what":"Race and Ethnicity Variables","title":"Getting Data from the US Census Bureau for Isochrones","text":"","code":"acs_raceeth_vars <- censusapi::listCensusMetadata(name = \"acs/acs5\",        vintage = 2019, group = \"B03002\") %>%       readr::write_csv(\"data/acs_raceeth_vars.csv\")"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/articles/get_census_data.html","id":"step-2-prepare-your-data","dir":"Articles","previous_headings":"Function Description","what":"Step 2: Prepare Your Data","title":"Getting Data from the US Census Bureau for Isochrones","text":"Define vector state FIPS codes. example, can use tigris package obtain FIPS codes U.S. states:","code":"us_fips_list <- tigris::fips_codes %>%     dplyr::select(state_code, state_name) %>%     dplyr::distinct(state_code, .keep_all = TRUE) %>%     filter(state_code < 56) %>%                         #state_codes over 56 are territories     dplyr::select(state_code) %>%     dplyr::pull()                                                # All US State FIPS Codes us_fips_list <- c(\"01\", \"02\", \"04\", \"05\", \"06\", \"08\", \"09\", \"10\", \"11\", \"12\", \"13\", \"15\", \"16\", \"17\", \"18\", \"19\", \"20\", \"21\", \"22\", \"23\", \"24\", \"25\", \"26\", \"27\", \"28\", \"29\", \"30\", \"31\", \"32\", \"33\", \"34\", \"35\", \"36\", \"37\", \"38\", \"39\", \"40\", \"41\", \"42\", \"44\", \"45\", \"46\", \"47\", \"48\", \"49\", \"50\", \"51\", \"53\", \"54\", \"55\")"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/articles/get_census_data.html","id":"step-3-gather-the-data-from-the-us-census-bureau-api","dir":"Articles","previous_headings":"Function Description","what":"Step 3: Gather the Data from the US Census Bureau API","title":"Getting Data from the US Census Bureau for Isochrones","text":"Call get_census_data function us_fips_list vector. example:","code":"all_census_data <- get_census_data(us_fips = us_fips_list)  ########################################################################## # Get Census data by block group in relevant states # Construct: for=block group:*&in=state:01&in=county:*&in=tract:* ###########################################################################  #output GOES HERE!!!!"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/articles/get_census_data.html","id":"step-4-the-function-will-retrieve-census-data-for-all-specified-states-and-combine-it-into-a-single-dataframe-which-you-can-use-for-further-analysis-","dir":"Articles","previous_headings":"Function Description","what":"Step 4: The function will retrieve Census data for all specified states and combine it into a single dataframe, which you can use for further analysis.","title":"Getting Data from the US Census Bureau for Isochrones","text":"","code":"demographics_bg <- acs_block_group %>%   rename(     name = NAME,     total_females = B01001_026E,     female_21_yo = B01001_033E,     female_22_to_24_years = B01001_034E,     female_25_to_29_years = B01001_035E,     female_30_to_34_years = B01001_036E,     female_35_to_39_years = B01001_037E,     female_40_to_44_years = B01001_038E,     female_45_to_49_years = B01001_039E,     female_50_to_54_years = B01001_040E,     female_55_to_59_years = B01001_041E,     female_60_to_61_years = B01001_042E,     female_62_to_64_years = B01001_043E,     female_65_to_66_years = B01001_044E,     female_67_to_69_years = B01001_045E,     female_70_to_74_years = B01001_046E,     female_75_to_79_years = B01001_047E,     female_80_to_84_years = B01001_048E,     female_85_years_and_older = B01001_049E,     fips_state = state   ) %>%   mutate(     fips_county = paste0(fips_state, county),     fips_tract = paste0(fips_state, county, tract),     fips_block_group = paste0(       fips_state,       county,       str_pad(tract, width = 6, pad = \"0\"),       block_group     )   ) %>%   mutate(     population = female_21_yo + female_22_to_24_years + female_25_to_29_years +       female_30_to_34_years + female_35_to_39_years + female_40_to_44_years +       female_45_to_49_years +       female_50_to_54_years +       female_55_to_59_years +       female_60_to_61_years +       female_62_to_64_years +       female_65_to_66_years +       female_67_to_69_years +       female_70_to_74_years +       female_75_to_79_years +       female_80_to_84_years +       female_85_years_and_older   ) %>% #total of reproductive age women   arrange(fips_state) %>%   select(     fips_block_group,     fips_state,     fips_county,     fips_tract,     name,     population,     everything()   ) %>%   select(-starts_with(\"B\"),          -contains(\"universe\"),          -county,          -tract,          -block_group)  colnames(demographics_bg)  demographics_bg <- demographics_bg %>% arrange(fips_block_group) readr::write.csv(demographics_bg, \"data/acs-block-group-demographics.csv\", na = \"\", row.names = F) readr::write_rds(demographics_bg, \"data/acs-block-group-demographics.rds\")"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/articles/get_census_data.html","id":"step-5-join-the-data-to-the-block-groups","dir":"Articles","previous_headings":"Function Description","what":"Step 5: Join the Data to the Block Groups","title":"Getting Data from the US Census Bureau for Isochrones","text":"code starts loading block group shapefile using sf::st_read() function. shapefile path replaced actual file path. left join performed “demographics_bg” dataset “bg_shape” dataset using dplyr::left_join(). join based matching “fips_block_group” column “demographics_bg” “GEOID” column “bg_shape”.","code":"# Load the block group shapefile using sf::st_read() function # Replace \"/data/shp/block_group/\" with the actual file path to the shapefile bg_shape <- sf::st_read(/data/shp/block_group/\") %>%      # Remove leading zeros from the GEOID column using stringr::str_remove()   # This is a common step to ensure GEOIDs are consistent      dplyr::mutate(GEOID = stringr::str_remove(GEOID, regex(\"^0\", ignore_case = TRUE))) %>%      # Select only the GEOID and geometry columns from the shapefile   dplyr::select(GEOID, geometry)   # Write the block group shapefile with selected columns to a CSV file # This will create a CSV file with GEOID and geometry information bg_shape %>%   readr::write_csv(\"bg_shape_with_geometry.csv\")   # Convert the \"fips_block_group\" column in the \"demographics_bg\" dataset to character # This is done to ensure compatibility for joining with the GEOID column in the shapefile demographics_bg$fips_block_group <- as.character(demographics_bg$fips_block_group)   # Perform a left join between the demographics dataset and the block group shapefile # Join the datasets using the \"fips_block_group\" column from demographics_bg # and the \"GEOID\" column from bg_shape  geometry <- dplyr::left_join(x = demographics_bg,            y = bg_shape,            by = c(\"fips_block_group\" = \"GEOID\")) # Write the resulting dataset with geometry information to a CSV file # This will create a CSV file containing demographic data and geometry information readr::write_csv(geometry, \"block_groups_with_geometry.csv\")"},{"path":[]},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/articles/get_census_data.html","id":"usage-tips","dir":"Articles","previous_headings":"","what":"Usage Tips","title":"Getting Data from the US Census Bureau for Isochrones","text":"Ensure valid Census API key access data. Replace \"your_census_api_key_here\" actual API key function call. included one second pause function loop mindful rate limiting API usage policies making multiple requests Census Bureau’s API.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/articles/get_census_data.html","id":"conclusion","dir":"Articles","previous_headings":"","what":"Conclusion","title":"Getting Data from the US Census Bureau for Isochrones","text":"get_census_data function simplifies process obtaining Census data states’ block groups.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/articles/get_census_data.html","id":"features-and-bugs","dir":"Articles","previous_headings":"","what":"Features and bugs","title":"Getting Data from the US Census Bureau for Isochrones","text":"ideas features make name handling easier, find bug, best approach either report add !","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/articles/my-vignette.html","id":"overview","dir":"Articles","previous_headings":"","what":"Overview","title":"Searching the NPI Database Starting with Taxonomy Codes","text":"tyler::taxonomy data tyler::search_by_taxonomy function R package offers convenient efficient way query NPI Database healthcare providers based taxonomy descriptions. vignette provides comprehensive guide effectively utilize function, explores various capabilities, offers illustrative use cases.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/articles/my-vignette.html","id":"installation","dir":"Articles","previous_headings":"Overview","what":"Installation","title":"Searching the NPI Database Starting with Taxonomy Codes","text":"can harness power search_by_taxonomy function, essential ensure tyler package installed. can effortlessly install using following command:","code":""},{"path":[]},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/articles/my-vignette.html","id":"understanding-taxonomy-descriptions","dir":"Articles","previous_headings":"Example Usage","what":"Understanding Taxonomy Descriptions","title":"Searching the NPI Database Starting with Taxonomy Codes","text":"Taxonomy descriptions, derived National Physician Taxonomy Codes NPPES (National Plan Provider Enumeration System) database, fundamental components United States healthcare system. play pivotal role identification categorization healthcare providers various purposes, including billing, insurance, regulatory compliance. particular, tyler::taxonomy data frame contains NUCC taxonomy codes utilized NPPES data files. Taxonomy Code comprises unique ten-character identifier aids identification healthcare provider types areas expertise. Notably, OBGYN taxonomy codes sourced Version 23.1 dated July 1, 2023. Taxonomy codes can obtained National Uniform Claim Committee (NUCC) website . can employ codes pinpoint specific taxonomy descriptions search. instance, interested finding taxonomy codes include string \"GYN\" can use code facilitate search search_by_taxonomy function.","code":"obgyn_taxonomy <- tyler::taxonomy %>%    dplyr::filter(str_detect(`Classification`, fixed(\"GYN\", ignore_case = TRUE))) %>%    dplyr::select(Code, Specialization) Code       Specialization                                       <chr>      <chr>                                              1 207V00000X NA                                                 2 207VC0300X Complex Family Planning                            3 207VC0200X Critical Care Medicine                             4 207VF0040X Female Pelvic Medicine and Reconstructive Surgery  5 207VX0201X Gynecologic Oncology                               6 207VG0400X Gynecology                                         7 207VH0002X Hospice and Palliative Medicine                    8 207VM0101X Maternal & Fetal Medicine                          9 207VB0002X Obesity Medicine                                  10 207VX0000X Obstetrics                                        11 207VE0102X Reproductive Endocrinology"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/articles/my-vignette.html","id":"search-by-taxonomy-description","dir":"Articles","previous_headings":"Example Usage","what":"Search by Taxonomy Description","title":"Searching the NPI Database Starting with Taxonomy Codes","text":"search_by_taxonomy function excels searching NPI Database healthcare providers based taxonomy descriptions. functionality proves invaluable verifying external data regarding subspecialist provider counts filling gaps providers may board-certified actively practicing (board-eligible). data can seamlessly integrated databases, enhancing utility. internal use, can refer \"Exploratory/Workforce/subspecialists_only\". One significant advantage search results include National Provider Identifier (NPI).","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/articles/my-vignette.html","id":"example-usage-1","dir":"Articles","previous_headings":"Example Usage","what":"Example Usage","title":"Searching the NPI Database Starting with Taxonomy Codes","text":"illustrative example, employ search_by_taxonomy function identify healthcare providers specializing “Hospice Palliative Medicine” based taxonomy descriptions. resulting output dataframe containing information physicians either MD qualification, practicing United States individuals, self-identifying taxonomy “Hospice Palliative Medicine.” can easily view resulting data frame user-friendly format. often need merge rows search_taxonomy data get_clinicians data. steps needed make structure names similar get_clinicians data.","code":"# Search for providers based on taxonomy descriptions taxonomy_descriptions <- c(\"Hospice and Palliative Medicine\")  data <- search_by_taxonomy(taxonomy_to_search = taxonomy_descriptions) #> 1200 records requested #> Requesting records 0-200... #> Requesting records 200-400... #> Requesting records 400-600... #> Requesting records 600-800... #> Requesting records 800-1000... #> Requesting records 1000-1200... > data           npi basic_first_name basic_last_name basic_sole_proprietor basic_gender basic_enumeration_date 1  1437277092         MARIETTA   ABALOS-GALITO                   YES            F             2007-03-26 2  1629034905          ANTHONY        ABBRUZZI                    NO            M             2006-04-25 3  1093806697            AYMAN     ABDEL HALIM                    NO            M             2006-09-27 # View the resulting data frame head(data) all_taxonomy_search_data <- data %>%    distinct(npi, .keep_all = TRUE) %>%      # Keep only the OBGYN subspecialist taxonomy descriptions.     filter(taxonomies_desc %in% c(\"Obstetrics & Gynecology, Female Pelvic Medicine and Reconstructive Surgery\", \"Obstetrics & Gynecology, Gynecologic Oncology\", \"Obstetrics & Gynecology, Maternal & Fetal Medicine\", \"Obstetrics & Gynecology, Reproductive Endocrinology\")) %>%      # Extract the first five of the zip code.     mutate(addresses_postal_code = str_sub(addresses_postal_code,1 ,5)) %>%   mutate(basic_enumeration_date = ymd(basic_enumeration_date)) %>%      # Pull the year out of the enumeration full data.     mutate(basic_enumeration_date_year = year(basic_enumeration_date), .after = ifelse(\"basic_enumeration_date\" %in% names(.), \"basic_enumeration_date\", last_col())) %>%   mutate(basic_middle_name = str_sub(basic_middle_name,1 ,1)) %>%   mutate(across(c(basic_first_name, basic_last_name, basic_middle_name), .fns = ~str_remove_all(., \"[[\\\\p{P}][\\\\p{S}]]\"))) %>%      # Get data ready to add these taxonomy rows to the `search_npi`/GOBA data set.     rename(NPI = npi, first_name = basic_first_name, last_name = basic_last_name, middle_name = basic_middle_name, GenderPhysicianCompare = basic_gender, sub1 = taxonomies_desc, city = addresses_city, state = addresses_state, name.x = full_name, `Zip CodePhysicianCompare` = addresses_postal_code) %>%   mutate(GenderPhysicianCompare = recode(GenderPhysicianCompare, \"F\" = \"Female\", \"M\" = \"Male\", type_convert = TRUE)) %>%      # Show the subspecialty from goba.     mutate(sub1 = recode(sub1, \"Obstetrics & Gynecology, Female Pelvic Medicine and Reconstructive Surgery\" = \"FPM\", \"Obstetrics & Gynecology, Gynecologic Oncology\" = \"ONC\", \"Obstetrics & Gynecology, Maternal & Fetal Medicine\" = \"MFM\", \"Obstetrics & Gynecology, Reproductive Endocrinology\" = \"REI\", type_convert = TRUE))"},{"path":[]},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/articles/my-vignette.html","id":"parameters","dir":"Articles","previous_headings":"Example Usage > Function Details","what":"Parameters","title":"Searching the NPI Database Starting with Taxonomy Codes","text":"taxonomy_to_search: character vector contain desired taxonomy description(s) used search criteria.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/articles/my-vignette.html","id":"output","dir":"Articles","previous_headings":"Example Usage > Function Details","what":"Output","title":"Searching the NPI Database Starting with Taxonomy Codes","text":"function returns data frame filtered include NPI data matching specified taxonomy description(s).","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/articles/my-vignette.html","id":"conclusion","dir":"Articles","previous_headings":"","what":"Conclusion","title":"Searching the NPI Database Starting with Taxonomy Codes","text":"search_by_taxonomy function stands wrapper exploring NPI Database taxonomy descriptions. empowers users identify healthcare providers precise specializations, rendering resource healthcare-related research -depth analysis.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/articles/my-vignette.html","id":"features-and-bugs","dir":"Articles","previous_headings":"","what":"Features and bugs","title":"Searching the NPI Database Starting with Taxonomy Codes","text":"ideas features make name handling easier, find bug, best approach either report add !","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/articles/search_and_process_npi.html","id":"overview","dir":"Articles","previous_headings":"","what":"Overview","title":"Search and Process NPI Numbers","text":"search_and_process_npi function tool working datasets containing National Provider Identifier (NPI) numbers. search_and_process_npi wrapper fantastic npi package. Thank authors maintainers npi package. NPI numbers provide standardized way identify track healthcare providers, including physicians, across United States. Government agencies, Centers Medicare & Medicaid Services (CMS), use NPI-based data plan allocate healthcare resources, including provider reimbursements, medical services, workforce distribution. search_and_process_npi allows search NPIs based first last names clinicians start many mystery caller projects getting names patient-facing directory physicians. Getting NPI number unlock multiple demographics physicians (gender, medical school type, address) function like `retrieve_clinician_data``.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/articles/search_and_process_npi.html","id":"why-use-apis-for-healthcare-data","dir":"Articles","previous_headings":"Overview","what":"Why use APIs for healthcare data?","title":"Search and Process NPI Numbers","text":"Accessing APIs retrieve healthcare data can offer several advantages downloading joining data multiple sources: Real-Time Data: APIs often provide access real-time near-real-time data. Downloading static data files may result using outdated information, APIs can provide latest data becomes available. Data Integrity: APIs typically offer structured validated data. access data via API, can confident quality consistency. contrast, downloading joining data various sources may introduce data integrity issues, missing mismatched records. Efficiency: APIs allow request specific subsets data, reducing amount data transferred processed. can improve efficiency reduce processing time, especially dealing large datasets. Downloading joining entire datasets can time-consuming resource-intensive. Reduced Storage Requirements: Storing large datasets locally can costly terms storage space. Accessing data APIs means don’t need maintain local copy entire dataset, saving storage costs reducing risk data redundancy. Scalability: APIs designed handle high volume requests. Security Privacy: Healthcare data often contains sensitive information, APIs can provide better control data access authentication. Data Source Aggregation: APIs can provide centralized point access data multiple sources. Data Governance: APIs often come documentation usage policies, can help ensure compliance data governance privacy regulations. provides transparency data usage, making easier adhere legal ethical standards. Version Control: APIs versioned, allowing users specify version API want use. ensures backward compatibility provides level stability accessing data. downloading joining data files, version control can challenging. Reduced Maintenance: APIs maintained updated data providers. using APIs, rely provider manage data updates, ensuring always access latest information.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/articles/search_and_process_npi.html","id":"installation","dir":"Articles","previous_headings":"","what":"Installation","title":"Search and Process NPI Numbers","text":"can use search_and_process_npi function, make sure tyler package installed. can install using following command:","code":"# install.packages(\"tyler\") library(tyler)"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/articles/search_and_process_npi.html","id":"example-usage","dir":"Articles","previous_headings":"","what":"Example Usage","title":"Search and Process NPI Numbers","text":"National Provider Identifier Search defaults find individual people (individuals enumeration_type = “ind”), physicians (“MD”, “”) United States listed NPPES.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/articles/search_and_process_npi.html","id":"step-1-load-your-data","dir":"Articles","previous_headings":"Example Usage","what":"Step 1: Load Your Data","title":"Search and Process NPI Numbers","text":"can provide data either dataframe specify path CSV, XLS, XLSX file containing data. dataframe must column named first another named last surname. acog_presidents example data set can use case.","code":"# Toy example using a dataframe data_df <- data.frame(   first = c(\"John\", \"Jane\", \"Bob\"),   last = c(\"Doe\", \"Smith\", \"Johnson\") )  # Example using a CSV file input_file <- \"acog_presidents.csv\"  # Note the file must have a column named \"first\" and a column named \"last\"."},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/articles/search_and_process_npi.html","id":"step-2-call-the-search_and_process_npi-function","dir":"Articles","previous_headings":"Example Usage","what":"Step 2: Call the search_and_process_npi Function","title":"Search and Process NPI Numbers","text":"Now, let’s use search_and_process_npi function search NPI numbers based first last names data. cast WIDE net matches specialties.","code":"# Example using a CSV file output_result <- search_and_process_npi(input_file = input_file)"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/articles/search_and_process_npi.html","id":"step-3-customize-your-search","dir":"Articles","previous_headings":"Example Usage","what":"Step 3: Customize Your Search","title":"Search and Process NPI Numbers","text":"can customize NPI search specifying parameters enumeration_type, limit, country_code, filter_credentials. Magic numbers :) take long time run. Best run overnight 2,000 searches. acog_president dataframe take 10 minutes. ’s can : worried message API accessed. just means match NAMES.","code":"# Example with custom search parameters result_df <- search_and_process_npi(   input_data = input_file,   enumeration_type = \"ind\",               # Search for individual NPIs   limit = 10,                             # Set the search limit to 10 results per name pair   country_code = \"US\",                    # Filter for NPIs in the United States   filter_credentials = c(\"MD\", \"DO\")      # Filter for specific credentials ) ERROR : `df` must be an npi_results S3 object, not tbl_df."},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/articles/search_and_process_npi.html","id":"step-4-access-the-results","dir":"Articles","previous_headings":"Example Usage","what":"Step 4: Access the Results","title":"Search and Process NPI Numbers","text":"function return data frame containing processed NPI search results. can access data frame analysis.going lot duplicates need clean thoughtfully.","code":"# Access the result data frame result_df  > output_result               npi basic_first_name basic_last_name basic_middle_name basic_credential basic_sole_proprietor basic_gender     1: 1053601807             RYAN       SCHLUETER            JEWELL               DO                   YES            M     2: 1184186256            LAURA          MARTIN         ELIZABETH               DO                    NO            F     3: 1063703494           LAUREN          BISHOP            ALICIA             M.D.                    NO            F     4: 1740800705           LAUREN          BISHOP         ELISABETH             M.D.                    NO            F             basic_enumeration_date basic_last_updated basic_certification_date basic_status taxonomies_code     1:             2011-04-13         2021-09-30               2021-09-30            A      207VM0101X     2:             2019-04-05         2023-03-16               2023-03-16            A      207P00000X     3:             2011-04-19         2023-03-16               2023-03-16            A      207VE0102X     4:             2020-04-20         2023-07-03               2023-07-03            A      207Q00000X                           taxonomies_taxonomy_group                                     taxonomies_desc taxonomies_state     1: 193400000X - Single Specialty Group  Obstetrics & Gynecology, Maternal & Fetal Medicine               GA     2:                                                                      Emergency Medicine               MS     3:                                     Obstetrics & Gynecology, Reproductive Endocrinology               NY     4:                                                                         Family Medicine               TX                 taxonomies_license taxonomies_primary basic_name_prefix basic_name_suffix     1:              80379               TRUE              <NA>              <NA>     2:              29372               TRUE               Dr.              <NA>     3:          302927-01               TRUE               Dr.              <NA>     4:              U5076               TRUE              <NA>              <NA>"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/articles/search_and_process_npi.html","id":"step-5-analyze-the-results","dir":"Articles","previous_headings":"Example Usage","what":"Step 5: Analyze the Results","title":"Search and Process NPI Numbers","text":"can now analyze NPI search results needed specific use case. result_df data frame contains information NPIs match search criteria. NPI numbers directly NPPES need run validate_and_remove_invalid_npi. One key step cleaning data filtering taxonomies. can changed different applications various subspecialties. Note people tricky list taxonomy specialty “Specialist” something else super vague. create code fix well, shown . Finally helpful join results called processed_result input_file called acog_presidents code can used .","code":"# Remove selected columns from the 'output_result' dataframe processed_result <- output_result %>%   dplyr::select(     -basic_middle_name,      -basic_certification_date,      -basic_name_prefix,      -basic_name_suffix,      -taxonomies_taxonomy_group,      -taxonomies_license,      -taxonomies_primary   ) %>%    mutate(across(c(basic_first_name, basic_last_name, basic_credential),        .fns = ~str_remove_all(., \"[[\\\\p{P}][\\\\p{S}]]\"))) %>%   mutate(basic_credential = str_to_upper(basic_credential)) %>%   filter(str_detect(basic_credential, \"MD|DO\")) %>%   mutate(basic_credential = str_sub(basic_credential,1 ,2)) %>%   filter(basic_credential %in% c(\"DO\", \"MD\")) %>%   filter(str_detect(taxonomies_desc, fixed(\"Gyn\", ignore_case=TRUE))) %>%   distinct(npi, .keep_all = TRUE)  > processed_result %>% head(5)           npi basic_first_name basic_last_name basic_credential basic_sole_proprietor basic_gender basic_enumeration_date 1: 1053601807             RYAN       SCHLUETER               DO                   YES            M             2011-04-13 2: 1063703494           LAUREN          BISHOP               MD                    NO            F             2011-04-19 3: 1376862383            JAMIE     SZCZEPANSKI               MD                    NO            F             2010-06-01 4: 1457676405          JESSICA         SHIELDS               DO                    NO            F             2010-04-01 5: 1366752107         CAROLINA          SUELDO               MD                    NO            F             2010-10-14    basic_last_updated basic_status taxonomies_code                                     taxonomies_desc taxonomies_state 1:         2021-09-30            A      207VM0101X  Obstetrics & Gynecology, Maternal & Fetal Medicine               GA 2:         2023-03-16            A      207VE0102X Obstetrics & Gynecology, Reproductive Endocrinology               NY 3:         2020-07-23            A      207V00000X                             Obstetrics & Gynecology               NY 4:         2019-07-18            A      207V00000X                             Obstetrics & Gynecology               MA 5:         2019-02-25            A      207V00000X                             Obstetrics & Gynecology               FL # Filter out rows where 'taxonomies_desc' contains the substring \"Gyn\" (case-insensitive).  This can be changed for different applications: \"Ortho\", \"Rheum\", \"Otolary\", \"Heme\", \"Anesthesi\".    processed_result <- processed_result %>%   dplyr::filter(stringr::str_detect(taxonomies_desc, fixed(\"gyn\", ignore_case = TRUE)) |   stringr::str_detect(taxonomies_desc, fixed(\"specialist\", ignore_case = TRUE))) combined_acog_presidents <-    acog_presidents %>%   dplyr::left_join(`processed_result`, by = c(\"first\" = \"basic_first_name\",                                                \"last\" = \"basic_last_name\",                                                \"honorrific\" = \"basic_credential\"),                                                ignore.case=TRUE)"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/articles/search_and_process_npi.html","id":"conclusion","dir":"Articles","previous_headings":"","what":"Conclusion","title":"Search and Process NPI Numbers","text":"search_and_process_npi function simplifies task searching processing NPI numbers healthcare datasets.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/articles/search_and_process_npi.html","id":"features-and-bugs","dir":"Articles","previous_headings":"","what":"Features and bugs","title":"Search and Process NPI Numbers","text":"ideas features make name handling easier, find bug, best approach either report add !","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/articles/validate_and_remove_invalid_npi.html","id":"overview","dir":"Articles","previous_headings":"","what":"Overview","title":"Gather Physician Data Starting With NPI Numbers","text":"validate_and_remove_invalid_npi function designed help process datasets containing National Provider Identifier (NPI) numbers search_by_taxonomy. validates format NPIs using npi package removes rows missing invalid NPIs. vignette guide usage.","code":""},{"path":[]},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/articles/validate_and_remove_invalid_npi.html","id":"installation","dir":"Articles","previous_headings":"Overview > Step 1","what":"Installation","title":"Gather Physician Data Starting With NPI Numbers","text":"can harness power search_by_taxonomy function, essential ensure tyler package installed. can effortlessly install using following command:","code":"library(tyler)"},{"path":[]},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/articles/validate_and_remove_invalid_npi.html","id":"understanding-national-provider-identifier","dir":"Articles","previous_headings":"Example Usage","what":"Understanding National Provider Identifier","title":"Gather Physician Data Starting With NPI Numbers","text":"valid National Provider Identifier (NPI) number United States meet certain criteria considered legitimate. key characteristics make NPI number valid: Length: NPI number consists ten digits. shorter longer ten digits. Numeric Digits: characters NPI must numeric digits (0-9). letters, symbols, special characters allowed. Luhn Algorithm: Luhn algorithm commonly used validate credit card numbers, applied NPI numbers. NPIs supposedly checksummed using Luhn algorithm. summary, valid NPI number ten numeric digits additional characters. validate NPI numbers programmatically, can check length confirm contain numeric digits (0-9). However, ’s important note specific format validation rules NPI numbers defined National Plan Provider Enumeration System (NPPES).","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/articles/validate_and_remove_invalid_npi.html","id":"step-2-prepare-your-data","dir":"Articles","previous_headings":"Example Usage","what":"Step 2: Prepare Your Data","title":"Gather Physician Data Starting With NPI Numbers","text":"can provide data either dataframe CSV file argument input_data. data dataframe, simply pass input_data parameter. data CSV file, pass file path input_data parameter.","code":"# Example using a dataframe data_df <- data.frame(npi = c(\"1234567890\", \"9876543210\", \"invalid_npi\")) valid_df <- validate_and_remove_invalid_npi(input_data)  # Example using a CSV file input_data <- \"path/to/your/file.csv\" valid_df <- validate_and_remove_invalid_npi(input_data)"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/articles/validate_and_remove_invalid_npi.html","id":"step-3-data-validation","dir":"Articles","previous_headings":"Example Usage","what":"Step 3: Data Validation","title":"Gather Physician Data Starting With NPI Numbers","text":"function validate NPIs data. performs following checks: Removes rows missing NPIs. Removes rows empty NPIs. Ensures NPIs valid format (numeric 10 characters length). Invalid NPIs removed, new column named “npi_is_valid” added indicate NPI validity.","code":"# A tibble: 7,494 × 7    sub1  first_name last_name          npi state         city             npi_is_valid    <chr> <chr>      <chr>            <dbl> <chr>         <chr>            <lgl>         1 MFM   Ryan       Schlueter   1053601807 Georgia       Atlanta          TRUE          2 FPM   Laura      Martin      1528351640 Florida       Miramar          TRUE          3 REI   Lauren     Bishop      1063703494 New York      New York         TRUE          4 MFM   Jamie      Szczepanski 1376862383 New York      Buffalo          TRUE"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/articles/validate_and_remove_invalid_npi.html","id":"step-4-get-the-valid-data","dir":"Articles","previous_headings":"Example Usage","what":"Step 4: Get the Valid Data","title":"Gather Physician Data Starting With NPI Numbers","text":"function return dataframe containing valid NPI numbers.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/articles/validate_and_remove_invalid_npi.html","id":"step-5-validating-npi-numbers-is-needed-before-searching-by-npi-number-in-the-cms-databases-","dir":"Articles","previous_headings":"Example Usage","what":"Step 5: Validating NPI numbers is needed before searching by NPI number in the CMS databases.","title":"Gather Physician Data Starting With NPI Numbers","text":"error can break results error handling beyond knowledge base now. use case use validate_and_remove_invalid_npi function searching physician demographics (medical school, etc) National Downloadable File CMS (https://data.cms.gov/provider-data/dataset/mj5m-pzi6). database update monthly know data fresh validate_and_remove_invalid_npi makes clean. Fresh clean! step can confidently feed NPI numbers provider::clinicians function without fear NPI number error. Specifically use case. see CSV get read provider::clinicians searched. output people results skips people results.","code":"df_updated <- NULL  retrieve_clinician_data <- function(input_data) {   library(provider)   library(dplyr)   library(purrr)   library(readr)   library(tidyr)   library(lubridate)   library(memoise)   library(zipcodeR)    # Load libraries   #remotes::install_github(\"andrewallenbruce/provider\")    if (is.data.frame(input_data)) {     # Input is a dataframe     df <- input_data   } else if (is.character(input_data)) {     # Input is a file path to a CSV     df <- readr::read_csv(input_data)   } else {     stop(\"Input must be a dataframe or a file path to a CSV.\")   }    # Clean the NPI numbers   df <- validate_and_remove_invalid_npi(df) # Function to retrieve clinician data for a single NPI   get_clinician_data <- function(npi) {     if (!is.numeric(npi) || nchar(npi) != 10) {       cat(\"Invalid NPI:\", npi, \"\\n\")       return(NULL)  # Skip this NPI     }      clinician_info <- provider::clinicians(npi = npi)     if (is.null(clinician_info)) {       cat(\"No results for NPI:\", npi, \"\\n\")     } else {       return(clinician_info)     }     Sys.sleep(1)   }    #df <- df %>% head(5) #test    # Loop through the \"npi\" column and get clinician data   df_updated <- df %>%     dplyr::mutate(row_number = row_number()) %>%     dplyr::mutate(clinician_data = purrr::map(npi, get_clinician_data)) %>%     tidyr::unnest(clinician_data, names_sep = \"_\") %>%     dplyr::distinct(npi, .keep_all = TRUE)    return(df_updated) } # Call the retrieve_clinician_data function with an NPI value input_data <- (\"~/Dropbox (Personal)/workforce/subspecialists_only.csv\") clinician_data <- retrieve_clinician_data(input_data)  Rows: 7498 Columns: 9                                                                                                                                         ── Column specification ────────────────────────────────────────────────────────────────────────────────────────────────── Delimiter: \",\" chr (8): sub1, first_name, last_name, state, name.x, city, GenderPhysicianCompare, Zip CodePhysicianCompare dbl (1): npi  ℹ Use `spec()` to retrieve the full column specification for this data. ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. ✖ No results for npi = 1063703494 No results for NPI: 1063703494  ✖ No results for npi = 1104052125 No results for NPI: 1104052125  ✖ No results for npi = 1972745586 No results for NPI: 1972745586  ✖ No results for npi = 1427386804 No results for NPI: 1427386804  ✖ No results for npi = 1942586581 No results for NPI: 1942586581"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/articles/validate_and_remove_invalid_npi.html","id":"conclusion","dir":"Articles","previous_headings":"","what":"Conclusion","title":"Gather Physician Data Starting With NPI Numbers","text":"validate_and_remove_invalid_npi function handy tool cleaning validating datasets NPI numbers. following steps outlined vignette, can ensure data contains valid NPIs analysis processing.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/articles/validate_and_remove_invalid_npi.html","id":"features-and-bugs","dir":"Articles","previous_headings":"","what":"Features and bugs","title":"Gather Physician Data Starting With NPI Numbers","text":"ideas features make name handling easier, find bug, best approach either report add !","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Tyler Muffly. Maintainer.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Muffly T (2025). tyler: Common Functions Mystery Caller Audit Studies Evaluating Patient Access Care. R package version 1.2.0, https://mufflyt.github.io/tyler/mysteryshopper.","code":"@Manual{,   title = {tyler: Common Functions for Mystery Caller or Audit Studies Evaluating Patient Access to Care},   author = {Tyler Muffly},   year = {2025},   note = {R package version 1.2.0},   url = {https://mufflyt.github.io/tyler/mysteryshopper}, }"},{"path":[]},{"path":[]},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/index.html","id":"and-pull-requests-httpsgithubcommufflyttylerpulls","dir":"","previous_headings":"","what":"and pull requests (https://github.com/mufflyt/tyler/pulls).","title":"Common Functions for Mystery Caller or Audit Studies Evaluating Patient Access to Care","text":"tyler package provides suite tools conducting mystery caller studies facilitating workforce distribution research obstetrics gynecology (OBGYN) professionals. streamlines process retrieving analyzing National Provider Identifier (NPI) data, demographic information, healthcare access data, also offering resources examining OBGYN residency programs. Key Features - Mystery Caller Studies: Tools analyze patient access healthcare searching processing NPI numbers based names criteria. - OBGYN Workforce Distribution: Functions datasets designed support workforce research, including detailed information OBGYN residency programs United States.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Common Functions for Mystery Caller or Audit Studies Evaluating Patient Access to Care","text":"can install development version tyler GitHub : See package vignette fuller introduction suggestions use tyler() function efficiently.","code":"# install.packages(\"devtools\") devtools::install_github(\"mufflyt/tyler\")"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/index.html","id":"tyler-package-data-overview","dir":"","previous_headings":"","what":"Tyler Package Data Overview","title":"Common Functions for Mystery Caller or Audit Studies Evaluating Patient Access to Care","text":"document describes key datasets included tyler package, focusing ACOG districts, physicians, taxonomy codes used healthcare provider identification.","code":""},{"path":[]},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/index.html","id":"data-tyleracgme","dir":"","previous_headings":"","what":"DATA: tyler::acgme","title":"Common Functions for Mystery Caller or Audit Studies Evaluating Patient Access to Care","text":"dataset tyler::acgme provides detailed information OBGYN residency programs accredited Accreditation Council Graduate Medical Education (ACGME). dataset includes fields program name, location, accreditation date, program director, affiliated hospitals. valuable resource mapping analyzing OBGYN residencies across U.S. Dataframe OBGYN residency programs scraped https://apps.acgme.org/ads/Public/Programs/Search. Name, city, state, accreditation date, program director name, website, rotations, affiliated hospitals included. ‘tyler::acgme’ - dataframe every OBGYN residency ACGME web site. data can used map obgyn residencies, etc.","code":"obgyn_residencies <- tyler::acgme  # View the first few rows head(obgyn_residencies) # A tibble: 318 × 142    program_name       address zip   city  state sponsoring_instituti…¹ sponsoring_instituti…² phone original_accreditati…³    <chr>              <chr>   <chr> <chr> <chr> <chr>                  <chr>                  <chr> <chr>                   1 University of Ala… \"Unive… 35249 Birm… Alab… 010498                 University of Alabama… (205… September 01, 1949      2 USA Health Program \"Unive… 36604 Mobi… Alab… 010406                 USA Health             (251… August 01, 1960         3 University of Ari… \"Banne… 85006 Phoe… Ariz… 038179                 University of Arizona… (602… May 07, 1951      # Example: Filter for residency programs in California ca_residencies <- dplyr::filter(obgyn_residencies, state == \"CA\") print(ca_residencies)"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/index.html","id":"data-tyleracog_districts","dir":"","previous_headings":"","what":"DATA: ‘tyler::ACOG_Districts’","title":"Common Functions for Mystery Caller or Audit Studies Evaluating Patient Access to Care","text":"American College Obstetricians Gynecologists (ACOG) professional organization representing obstetricians gynecologists United States. ACOG divides membership various geographical regions known “ACOG Districts.” single-state ACOG Districts (e.g., California, Texas, Florida) also need use US Census Bureau subdivisions. Subdivisions important census statistical purposes help organize categorize population data local level. dataset includes: - State names: Full name U.S. state. - ACOG Districts: corresponding ACOG district state. - Subregions: U.S. Census Bureau subregions help organize population data. - State abbreviations: official two-letter postal abbreviations state. dataset useful research geographic distribution OBGYN professionals affiliations ACOG districts.","code":"acog_districts <- tyler::ACOG_Districts head(tyler::ACOG_Districts) # A tibble: 52 × 4    State                ACOG_District Subregion     State_Abbreviations    <chr>                <chr>         <chr>         <chr>                1 Alabama              District VII  District VII  AL                   2 Alaska               District VIII District VIII AK                   3 Arizona              District VIII District VIII AZ                   4 Arkansas             District VII  District VII  AR                   5 California           District IX   District IX   CA                   6 Colorado             District VIII District VIII CO                   7 Connecticut          District I    District I    CT                   8 Delaware             District IV   District IV   DE                   9 District of Columbia District IV   District IV   DC                  10 Florida              District XII  District XII  FL"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/index.html","id":"data-tylerphysicians","dir":"","previous_headings":"","what":"DATA: tyler::physicians","title":"Common Functions for Mystery Caller or Audit Studies Evaluating Patient Access to Care","text":"dataset contains details OBGYN subspecialists, including names, specialties, geographic coordinates. Physicians.rds file, located tyler/inst/extdata, stores internal dataset. dataset includes: - NPI: National Provider Identifier, unique identifier healthcare providers U.S. - Name: Physician’s full name. - Subspecialty: Physician’s specific area expertise within OBGYN. - Latitude/Longitude: Geographic coordinates physician’s practice.","code":"tyler::physicians # A tibble: 4,659 × 5           NPI name                        subspecialty                                        lat   long         <dbl> <chr>                       <chr>                                             <dbl>  <dbl>  1 1922051358 Katherine Boyd              Female Pelvic Medicine and Reconstructive Surgery  42.6  -82.9  2 1750344388 Thomas Byrne                Maternal-Fetal Medicine                            35.2 -102.   3 1548520133 Bobby Garcia                Female Pelvic Medicine and Reconstructive Surgery  40.8  -73.9"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/index.html","id":"data-tylertaxonomy","dir":"","previous_headings":"","what":"DATA: tyler::taxonomy","title":"Common Functions for Mystery Caller or Audit Studies Evaluating Patient Access to Care","text":"Physician Taxonomy Codes NPPES (National Plan Provider Enumeration System) database essential components healthcare system United States. codes play crucial role identifying categorizing healthcare providers various purposes, including billing, insurance, regulatory compliance. tyler::taxonomy dataset dataframe containing NUCC taxonomy codes used NPPES data files. taxonomy code consists unique ten-character identifier helps classify healthcare providers type area expertise. dataset includes OBGYN taxonomy codes, Version 23.1 7/1/2023. can find details NUCC website.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/index.html","id":"example","dir":"","previous_headings":"DATA: tyler::taxonomy","what":"Example:","title":"Common Functions for Mystery Caller or Audit Studies Evaluating Patient Access to Care","text":"","code":"obgyn_taxonomy <- tyler::taxonomy %>%    filter(str_detect(Classification, fixed(\"GYN\", ignore_case = TRUE))) %>%    select(Code, Specialization)  obgyn_taxonomy # A tibble of OBGYN-related taxonomy codes    Code       Specialization                                       <chr>      <chr>                                              1 207V00000X Obstetrics & Gynecology                                                 2 207VC0300X Complex Family Planning                            3 207VC0200X Critical Care Medicine                             4 207VF0040X Female Pelvic Medicine and Reconstructive Surgery  5 207VX0201X Gynecologic Oncology                               6 207VG0400X Gynecology                                         7 207VH0002X Hospice and Palliative Medicine                    8 207VM0101X Maternal & Fetal Medicine                          9 207VB0002X Obesity Medicine                                  10 207VX0000X Obstetrics                                        11 207VE0102X Reproductive Endocrinology"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/index.html","id":"searching-for-data-tylersearch_by_taxonomy","dir":"","previous_headings":"","what":"SEARCHING FOR DATA: tyler::search_by_taxonomy","title":"Common Functions for Mystery Caller or Audit Studies Evaluating Patient Access to Care","text":"function searches NPI Database healthcare providers based taxonomy description. search_by_taxonomy function wrapper npi::npi_search accessing registry’s Version 2.1 API. Many thanks author maintainers npi package amazing work.helps confirm outside data subspecialist provider counts fill gaps providers board-certified practicing (board-eligible). data can matched databases. Please see Exploratory/workforce/subspecialists_only code . nice thing search results come NPI.","code":"# This will allow us to get subspecialty names and NPI numbers go_data <- search_by_taxonomy(\"Gynecologic Oncology\") fpmrs_data <- search_by_taxonomy(\"Female Pelvic Medicine and Reconstructive Surgery\") rei_data <- search_by_taxonomy(\"Reproductive Endocrinology\") mfm_data <- search_by_taxonomy(\"Maternal & Fetal Medicine\")  # Merge all data frames into one       all_taxonomy_search_data <- bind_rows(         go_data,         fpmrs_data,         rei_data,         mfm_data) %>%         dplyr::distinct(npi, .keep_all = TRUE)  dim(all_taxonomy_search_data) glimpse(all_taxonomy_search_data) # 1200 records requested # Requesting records 0-200... # Requesting records 200-400..."},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/index.html","id":"searching-for-data-tylersearch_and_process_npi","dir":"","previous_headings":"","what":"SEARCHING FOR DATA: tyler::search_and_process_npi","title":"Common Functions for Mystery Caller or Audit Studies Evaluating Patient Access to Care","text":"National Provider Identifier Search: Search first names, last names, individuals enumeration_type = \"ind\", physicians (\"MD\", \"\") United States NPPES. NPI numbers provide standardized way identify track healthcare providers, including physicians, across United States. Government agencies, Centers Medicare & Medicaid Services (CMS), use NPI-based data plan allocate healthcare resources, including provider reimbursements, medical services, workforce distribution.","code":"search_and_process_npi <- function(input_file,                                    enumeration_type = \"ind\",                                    limit = 5L,                                    country_code = \"US\",                                    filter_credentials = c(\"MD\", \"DO\"))  input_file <- \"/Users/tylermuffly/Dropbox (Personal)/Nomogram/nomogram/data/nppes_search/Lo_R_Author.csv\" output_result <- search_and_process_npi(input_file)"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/index.html","id":"searching-for-data-tylervalidate_and_remove_invalid_npi","dir":"","previous_headings":"","what":"SEARCHING FOR DATA: tyler::validate_and_remove_invalid_npi","title":"Common Functions for Mystery Caller or Audit Studies Evaluating Patient Access to Care","text":"cleans NPI numbers goes tyler::retrieve_clinician_data one incorrect NPI number inserted screws entire search. Saves find csv file.","code":"input_csv_path <- \"~/Dropbox (Personal)/workforce/subspecialists_only.csv\"  # Replace with the path to your CSV file valid_df <- validate_and_remove_invalid_npi(input_csv_path) Search result saved as: data/search_results_1053601807_20231119192903.csv                                 Search result saved as: data/search_results_1528351640_20231119192911.csv                                 ✖ No results for npi = 1063703494 No results for NPI: 1063703494"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/index.html","id":"searching-for-data-tylerretrieve_clinician_data","dir":"","previous_headings":"","what":"SEARCHING FOR DATA: tyler::retrieve_clinician_data","title":"Common Functions for Mystery Caller or Audit Studies Evaluating Patient Access to Care","text":"function retrieves clinician data based validated NPI numbers, using validate_and_remove_invalid_npi filter NPIs. logs successful searches, saves results CSV files, flags NPIs data found. results timestamped filenames, ensuring search history maintained. function vital efficiently gathering clinician data external sources storing future use. retrieve_clinician_data function retrieves clinician information Medicare Care Compare system. Previously, data accessed via Physician Compare, sunsetted December 2020. dataset can found CMS Provider Data. Physician Compare sunset December 1, 2020 replaced : https://www.medicare.gov/care-compare/?redirect=true&providerType=Physician. entire data set https://data.cms.gov/provider-data/dataset/mj5m-pzi6. cool library called provider super helpful accessing .","code":"# Call the retrieve_clinician_data function with an NPI value input_csv_path <- (\"~/Dropbox (Personal)/workforce/subspecialists_only.csv\") clinician_data <- tyler::retrieve_clinician_data(input_csv_path) ✖ No results for npi = 1093151441 NULL # A tibble: 3 × 17   npi     pac   enid  first last  gender school grad_year specialty facility_name pac_org members_org address_org city_org   <chr>   <chr> <chr> <chr> <chr> <fct>  <chr>      <int> <chr>     <chr>         <chr>         <int> <chr>       <chr>    1 119406… 3476… I202… JACL… DENE… Female NEW Y…      2013 OBSTETRI… SPECTRUM HEA… 458756…        1551 25 MICHIGA… GRAND R… 2 119406… 3476… I202… JACL… DENE… Female NEW Y…      2013 OBSTETRI… SPECTRUM HEA… 458756…        1551 4444 KALAM… KENTWOOD 3 119406… 3476… I202… JACL… DENE… Female NEW Y…      2013 OBSTETRI… SPECTRUM HEA… 458756…        1551 4069 LAKE … GRAND R… # ℹ 3 more variables: state_org <ord>, zip_org <chr>, phone_org <chr>"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/index.html","id":"searching-for-data-tylergenderize_physicians","dir":"","previous_headings":"","what":"SEARCHING FOR DATA: tyler::genderize_physicians","title":"Common Functions for Mystery Caller or Audit Studies Evaluating Patient Access to Care","text":"wrapper around gender package help fill gender physician names. requires csv column called first_name. lot gender data found via Physician Compare past.","code":"tyler::genderize_physicians <- function(input_csv)"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/index.html","id":"searching-for-data-tylergeocode_unique_addresses","dir":"","previous_headings":"","what":"SEARCHING FOR DATA: tyler::geocode_unique_addresses","title":"Common Functions for Mystery Caller or Audit Studies Evaluating Patient Access to Care","text":"Takes csv file addresses prints lat long separate columns. need google_maps_api_key. Geocoding process converting human-readable addresses place names geographic coordinates (latitude longitude) can used locate places map. Google Geocoding API service provided Google allows developers perform geocoding reverse geocoding, process converting coordinates back human-readable addresses.","code":"output_data <-      tyler::geocode_unique_addresses(file_path = \"/Users/tylermuffly/Dropbox (Personal)/Tannous/data/address_for_geocoding.csv\",      google_maps_api_key = \"????\",      output_file_path = \"/Users/tylermuffly/Dropbox (Personal)/Tannous/data/geocoded_unique_addresses.csv\")"},{"path":[]},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/index.html","id":"creating-mystery-caller-dataphase-1-tylercity_state_sample_specialists","dir":"","previous_headings":"","what":"Creating Mystery Caller Data/Phase 1: tyler::city_state_sample_specialists","title":"Common Functions for Mystery Caller or Audit Studies Evaluating Patient Access to Care","text":"script samples specialists based city state data performs analyses based geographic location.","code":"# Example: Sampling specialists based on city and state data <- data.frame(city = c(\"Denver\", \"Chicago\"), state = c(\"CO\", \"IL\"), specialists = c(5, 3)) city_state_sample_specialists(data)  # Example with stratified sampling city_state_sample_specialists(data, stratified = TRUE)"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/index.html","id":"creating-mystery-caller-dataphase-1-tylercity_state_assign_scenarios","dir":"","previous_headings":"","what":"Creating Mystery Caller Data/Phase 1: tyler::city_state_assign_scenarios","title":"Common Functions for Mystery Caller or Audit Studies Evaluating Patient Access to Care","text":"script assigns city state data different scenarios, mapping geographic information scenario datasets.","code":"# Example: Assigning city and state to scenarios data <- data.frame(city = c(\"Denver\", \"Chicago\"), state = c(\"CO\", \"IL\")) city_state_assign_scenarios(data)  # Example with multiple scenarios scenarios <- list(scenario1 = data, scenario2 = data) city_state_assign_scenarios(scenarios)"},{"path":[]},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/index.html","id":"tylerpoisson_formula_maker","dir":"","previous_headings":"","what":"tyler::poisson_formula_maker","title":"Common Functions for Mystery Caller or Audit Studies Evaluating Patient Access to Care","text":"poisson_formula_maker function constructs formula Poisson regression model based specified predictor variables. typically used running Poisson models, fit_poisson_models, streamline model fitting count-based data like waiting times.","code":"# Example: Create a Poisson regression formula poisson_formula <- poisson_formula_maker(predictor_vars = c(\"age\", \"gender\", \"insurance\"))  # View the formula print(poisson_formula)"},{"path":[]},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/index.html","id":"tylergenerate_latex_equation","dir":"","previous_headings":"","what":"tyler::generate_latex_equation","title":"Common Functions for Mystery Caller or Audit Studies Evaluating Patient Access to Care","text":"function generates LaTeX-formatted equation input model formula. commonly used fitting statistical models like regression present final equation document report. function complements functions like tyler::linear_regression_summary_sentence tyler::logistic_regression, generate human-readable summaries, allowing text formula outputs.","code":"# Example: Generate LaTeX equation from a linear model model <- lm(mpg ~ cyl + disp, data = mtcars) latex_equation <- generate_latex_equation(model)  # View the LaTeX equation print(latex_equation)"},{"path":[]},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/index.html","id":"tylergenerate_overall_table","dir":"","previous_headings":"","what":"tyler::generate_overall_table","title":"Common Functions for Mystery Caller or Audit Studies Evaluating Patient Access to Care","text":"function generates summary table demographics based Table 1 data. supports multiple file formats, including RDS, CSV, XLS, logs key step, inputs, data transformations, file paths. can select specific columns apply custom label translations. ensures output directory exists saves generated table PDF. Error handling ensures function validates data logs issues occur execution.","code":"# Example: Generating an overall table generate_overall_table(input_file_path = \"data/Table1.rds\", output_directory = \"output_tables\")  # Example with selected columns generate_overall_table(input_file_path = \"data/Table1.csv\", output_directory = \"output_tables\", selected_columns = c(\"age\", \"gender\"))  # Example with label translations label_translations <- list(age = \"Age (years)\", gender = \"Gender\") generate_overall_table(input_file_path = \"data/Table1.xlsx\", output_directory = \"output_tables\", label_translations = label_translations)"},{"path":[]},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/index.html","id":"tylercount_unique_physicians","dir":"","previous_headings":"","what":"tyler::count_unique_physicians","title":"Common Functions for Mystery Caller or Audit Studies Evaluating Patient Access to Care","text":"script counts number unique physicians dataset based unique identifier NPI.","code":"# Example: Counting unique physicians data <- data.frame(NPI = c(\"12345\", \"67890\", \"12345\", \"54321\")) count_unique_physicians(data)  # Example with a custom identifier column count_unique_physicians(data, id_column = \"NPI\")"},{"path":[]},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/index.html","id":"tylercalculate_descriptive_stats","dir":"","previous_headings":"","what":"tyler::calculate_descriptive_stats","title":"Common Functions for Mystery Caller or Audit Studies Evaluating Patient Access to Care","text":"function computes descriptive statistics, means, medians, standard deviations datasets, covering categorical numerical variables. can customize calculate statistics selected columns. logs progress saves results structured format, making highly flexible analyzing datasets. function key quickly summarizing large datasets systematically.","code":"# Example: Calculating descriptive statistics data <- data.frame(age = c(23, 35, 40, 29, 50), gender = c(\"M\", \"F\", \"M\", \"F\", \"M\")) calculate_descriptive_stats(data)  # Example with selected columns calculate_descriptive_stats(data, selected_columns = c(\"age\"))"},{"path":[]},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/index.html","id":"tylercalc_percentages","dir":"","previous_headings":"","what":"tyler::calc_percentages","title":"Common Functions for Mystery Caller or Audit Studies Evaluating Patient Access to Care","text":"script calculates percentages given dataset. can calculate percentage category categorical variables optionally handle missing data.","code":"# Example: Calculating percentages data <- data.frame(category = c(\"A\", \"B\", \"A\", \"C\", \"B\", \"A\")) calc_percentages(data)  # Example with missing data handling calc_percentages(data, handle_missing = TRUE)"},{"path":[]},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/index.html","id":"tylercalculate_distribution","dir":"","previous_headings":"","what":"tyler::calculate_distribution","title":"Common Functions for Mystery Caller or Audit Studies Evaluating Patient Access to Care","text":"script calculates distribution values numerical categorical variables dataset.","code":"# Example: Calculating distribution data <- data.frame(value = c(1, 2, 2, 3, 3, 3, 4)) calculate_distribution(data)  # Example with categorical variables data <- data.frame(category = c(\"A\", \"B\", \"A\", \"C\", \"B\")) calculate_distribution(data, variable_type = \"categorical\")"},{"path":[]},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/index.html","id":"tylercalculate_proportion","dir":"","previous_headings":"","what":"tyler::calculate_proportion","title":"Common Functions for Mystery Caller or Audit Studies Evaluating Patient Access to Care","text":"script calculates proportion specific event category dataset.","code":"# Example: Calculating proportion data <- data.frame(category = c(\"A\", \"B\", \"A\", \"C\", \"B\")) calculate_proportion(data, event = \"A\")  # Example with a custom threshold calculate_proportion(data, event = \"B\", threshold = 0.2)"},{"path":[]},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/index.html","id":"tylercheck_normality","dir":"","previous_headings":"","what":"tyler::check_normality","title":"Common Functions for Mystery Caller or Audit Studies Evaluating Patient Access to Care","text":"script checks normality numeric dataset using statistical tests graphical methods QQ plots.","code":"# Example: Checking normality of a dataset data <- data.frame(value = c(10, 12, 15, 13, 14, 15, 18)) check_normality(data)  # Example with a specific significance level check_normality(data, significance_level = 0.05)"},{"path":[]},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/index.html","id":"tylerpoisson_wait_time_stats","dir":"","previous_headings":"","what":"tyler::poisson_wait_time_stats","title":"Common Functions for Mystery Caller or Audit Studies Evaluating Patient Access to Care","text":"function analyzes wait time statistics using Poisson model. designed model count-based data, like number appointments waiting times. complements poisson_formula_maker fit_poisson_models, helps understanding distribution determinants wait times.","code":"# Example: Calculate Poisson wait time statistics wait_time_stats <- poisson_wait_time_stats(df = appointments_data, target_variable = \"wait_time\")  # View the wait time statistics print(wait_time_stats)"},{"path":[]},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/index.html","id":"tylercreate_and_plot_interaction","dir":"","previous_headings":"","what":"tyler::create_and_plot_interaction","title":"Common Functions for Mystery Caller or Audit Studies Evaluating Patient Access to Care","text":"script creates interaction models variables plots results.","code":"# Example: Creating an interaction plot data <- data.frame(var1 = c(1, 2, 3, 4), var2 = c(5, 6, 7, 8)) create_and_plot_interaction(data, var1 = \"var1\", var2 = \"var2\")  # Example with customized plot settings create_and_plot_interaction(data, var1 = \"var1\", var2 = \"var2\", plot_title = \"Interaction Plot\")"},{"path":[]},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/index.html","id":"tylercreate_forest_plot","dir":"","previous_headings":"","what":"tyler::create_forest_plot","title":"Common Functions for Mystery Caller or Audit Studies Evaluating Patient Access to Care","text":"create_forest_plot function creates forest plot significant predictors, displaying coefficients confidence intervals. used fitting statistical models, Poisson logistic regression, visualize key predictors effects. function often paired model-fitting functions like fit_poisson_models fit_mixed_model_with_logging.","code":"# Example: Creating a forest plot for significant predictors df <- data.frame(predictor = c(\"age\", \"gender\", \"income\"), estimate = c(0.2, -0.5, 0.3), lower = c(0.1, -0.7, 0.2), upper = c(0.3, -0.3, 0.5)) create_forest_plot(df, \"target_variable\", significant_vars = df)"},{"path":[]},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/index.html","id":"tylercreate_insurance_by_insurance_scatter_plot","dir":"","previous_headings":"","what":"tyler::create_insurance_by_insurance_scatter_plot","title":"Common Functions for Mystery Caller or Audit Studies Evaluating Patient Access to Care","text":"create_insurance_by_insurance_scatter_plot function creates scatter plot comparing waiting times two insurance types. complements data cleaning processing functions prepare appointment data visualization, determine_direction. plot useful visually comparing performance insurance providers terms wait times.","code":"# Example: Creating an interaction plot data <- data.frame(var1 = c(1, 2, 3, 4), var2 = c(5, 6, 7, 8)) create_and_plot_interaction(data, var1 = \"var1\", var2 = \"var2\")  # Example with customized plot settings create_and_plot_interaction(data, var1 = \"var1\", var2 = \"var2\", plot_title = \"Interaction Plot\")"},{"path":[]},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/index.html","id":"tylercreate_line_plot","dir":"","previous_headings":"","what":"tyler::create_line_plot","title":"Common Functions for Mystery Caller or Audit Studies Evaluating Patient Access to Care","text":"create_line_plot function generates line plots visualizing trends time continuous variables. commonly used calculating descriptive statistics analyzing trends across time-based data. works well summarized grouped data functions like calculate_descriptive_stats.","code":"# Example: Creating a line plot create_line_plot(df, x = \"year\", y = \"appointments\", group = \"insurance\")"},{"path":[]},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/index.html","id":"tylercreate_scatter_plot","dir":"","previous_headings":"","what":"tyler::create_scatter_plot","title":"Common Functions for Mystery Caller or Audit Studies Evaluating Patient Access to Care","text":"function creates scatter plots, allowing comparison two continuous variables, optionally linear regression line. useful exploratory data analysis visualizing relationships variables. function complements descriptive statistics correlation analysis functions.","code":"# Example: Creating a scatter plot create_scatter_plot(df, x = \"income\", y = \"appointment_days\", add_regression = TRUE)"},{"path":[]},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/index.html","id":"tylercreate_and_plot_interaction-1","dir":"","previous_headings":"","what":"tyler::create_and_plot_interaction","title":"Common Functions for Mystery Caller or Audit Studies Evaluating Patient Access to Care","text":"script creates interaction models variables plots results.","code":"# Example: Creating an interaction plot data <- data.frame(var1 = c(1, 2, 3, 4), var2 = c(5, 6, 7, 8)) create_and_plot_interaction(data, var1 = \"var1\", var2 = \"var2\")  # Example with customized plot settings create_and_plot_interaction(data, var1 = \"var1\", var2 = \"var2\", plot_title = \"Interaction Plot\")"},{"path":[]},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/index.html","id":"tylerlinear_regression_summary_sentence","dir":"","previous_headings":"","what":"tyler::linear_regression_summary_sentence","title":"Common Functions for Mystery Caller or Audit Studies Evaluating Patient Access to Care","text":"function generates summary sentence linear regression results, making easier present findings clear concise manner. typically used fitting linear regression model complements functions like generate_latex_equation providing textual formulaic summary results.","code":"# Example: Generate summary sentence for linear regression model <- lm(mpg ~ wt + hp, data = mtcars) summary_sentence <- linear_regression_summary_sentence(model)  # View the summary sentence print(summary_sentence)"},{"path":[]},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/index.html","id":"tylerlogistic_regression","dir":"","previous_headings":"","what":"tyler::logistic_regression","title":"Common Functions for Mystery Caller or Audit Studies Evaluating Patient Access to Care","text":"function generates summary sentence linear regression results, making easier present findings clear concise manner. typically used fitting linear regression model complements functions like generate_latex_equation providing textual formulaic summary results.","code":"# Example: Generate summary sentence for linear regression model <- lm(mpg ~ wt + hp, data = mtcars) summary_sentence <- linear_regression_summary_sentence(model)  # View the summary sentence print(summary_sentence)"},{"path":[]},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/index.html","id":"tylermaxtable","dir":"","previous_headings":"","what":"tyler::MaxTable","title":"Common Functions for Mystery Caller or Audit Studies Evaluating Patient Access to Care","text":"tyler::MaxTable function creates summary table highlights maximum values key metrics across categories. often used conjunction descriptive analysis functions, generate_overall_table, provide deeper insights maximum performance metrics.","code":"# Example: Generate a MaxTable for the dataset max_table <- MaxTable(df = mtcars, group_variable = \"cyl\", value_variable = \"mpg\")  # View the MaxTable print(max_table)"},{"path":[]},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/index.html","id":"tylermintable","dir":"","previous_headings":"","what":"tyler::MinTable","title":"Common Functions for Mystery Caller or Audit Studies Evaluating Patient Access to Care","text":"MinTable function creates summary table highlighting minimum values key metrics across different categories. often used alongside MaxTable provide complete range insights showing minimum performance outcomes within group. especially useful comparative studies.","code":"# Example: Generate a MinTable for the dataset min_table <- MinTable(df = mtcars, group_variable = \"cyl\", value_variable = \"mpg\")  # View the MinTable print(min_table)"},{"path":[]},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/index.html","id":"tylermost_common_gender_training_academic","dir":"","previous_headings":"","what":"tyler::most_common_gender_training_academic","title":"Common Functions for Mystery Caller or Audit Studies Evaluating Patient Access to Care","text":"function identifies common gender training type among academic physicians. complements demographic analysis functions like physician_age useful studies focused characteristics healthcare providers, particularly academic settings.","code":"# Example: Identify the most common gender and training type among academic physicians common_gender_training <- most_common_gender_training_academic(df = physicians_data)  # View the results print(common_gender_training)"},{"path":[]},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/index.html","id":"tylerphysician_age","dir":"","previous_headings":"","what":"tyler::physician_age","title":"Common Functions for Mystery Caller or Audit Studies Evaluating Patient Access to Care","text":"physician_age function calculates age physicians based birth year similar data. core function used demographic analyses often paired functions like most_common_gender_training_academic provide complete understanding physician workforce.","code":"Example: Calculate physician age physician_ages <- physician_age(df = physicians_data, birth_year_col = \"birth_year\")  # View the ages print(physician_ages)"},{"path":[]},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/index.html","id":"tylerplot_and_save_emmeans","dir":"","previous_headings":"","what":"tyler::plot_and_save_emmeans","title":"Common Functions for Mystery Caller or Audit Studies Evaluating Patient Access to Care","text":"function creates saves plots estimated marginal means (EMMeans) fitted model. often used running statistical models, Poisson mixed-effects models, visualize group differences. function complements fit_poisson_models fit_mixed_model_with_logging.","code":"# Example: Plot and save EMMeans from a fitted model emmeans_plot <- plot_and_save_emmeans(model = fitted_model, variables = c(\"age\", \"gender\"), output_dir = \"plots/\")  # View the plot print(emmeans_plot)"},{"path":[]},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/index.html","id":"tylercreate_and_plot_interaction-2","dir":"","previous_headings":"","what":"tyler::create_and_plot_interaction","title":"Common Functions for Mystery Caller or Audit Studies Evaluating Patient Access to Care","text":"script creates interaction models variables plots results.","code":"# Example: Creating an interaction plot data <- data.frame(var1 = c(1, 2, 3, 4), var2 = c(5, 6, 7, 8)) create_and_plot_interaction(data, var1 = \"var1\", var2 = \"var2\")  # Example with customized plot settings create_and_plot_interaction(data, var1 = \"var1\", var2 = \"var2\", plot_title = \"Interaction Plot\")"},{"path":[]},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/index.html","id":"tylercreate_and_plot_interaction-3","dir":"","previous_headings":"","what":"tyler::create_and_plot_interaction","title":"Common Functions for Mystery Caller or Audit Studies Evaluating Patient Access to Care","text":"script creates interaction models variables plots results.","code":"# Example: Creating an interaction plot data <- data.frame(var1 = c(1, 2, 3, 4), var2 = c(5, 6, 7, 8)) create_and_plot_interaction(data, var1 = \"var1\", var2 = \"var2\")  # Example with customized plot settings create_and_plot_interaction(data, var1 = \"var1\", var2 = \"var2\", plot_title = \"Interaction Plot\")"},{"path":[]},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/index.html","id":"tylercreate_and_plot_interaction-4","dir":"","previous_headings":"","what":"tyler::create_and_plot_interaction","title":"Common Functions for Mystery Caller or Audit Studies Evaluating Patient Access to Care","text":"script creates interaction models variables plots results.","code":"# Example: Creating an interaction plot data <- data.frame(var1 = c(1, 2, 3, 4), var2 = c(5, 6, 7, 8)) create_and_plot_interaction(data, var1 = \"var1\", var2 = \"var2\")  # Example with customized plot settings create_and_plot_interaction(data, var1 = \"var1\", var2 = \"var2\", plot_title = \"Interaction Plot\")"},{"path":[]},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/index.html","id":"tylerinstall_missing_packages","dir":"","previous_headings":"","what":"tyler::install_missing_packages","title":"Common Functions for Mystery Caller or Audit Studies Evaluating Patient Access to Care","text":"utility function checks missing R packages installs necessary. often used start analysis script ensure required packages installed. function complements function relies external packages, ensuring smooth workflow without interruptions.","code":"# Example: Install missing packages required_packages <- c(\"ggplot2\", \"dplyr\", \"readr\") install_missing_packages(required_packages)"},{"path":[]},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/index.html","id":"tylerload_data","dir":"","previous_headings":"","what":"tyler::load_data","title":"Common Functions for Mystery Caller or Audit Studies Evaluating Patient Access to Care","text":"function loads data various file formats (e.g., CSV, RDS, Excel) prepares analysis. one first steps analysis workflow, providing clean data subsequent steps like model fitting visualization. complements functions rely dataset loaded memory.","code":"# Example: Load data from a CSV file data <- load_data(\"data/my_data.csv\")  # Example: Load data from an RDS file data <- load_data(\"data/my_data.rds\")"},{"path":[]},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/index.html","id":"tylertm_write2pdf","dir":"","previous_headings":"","what":"tyler::tm_write2pdf","title":"Common Functions for Mystery Caller or Audit Studies Evaluating Patient Access to Care","text":"function saves arsenal-generated table object PDF file. logs PDF saved ensures PDF written without unnecessary output. function streamlines process converting arsenal tables PDF files, retaining markdown elements ensuring efficient saving multiple summaries.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/index.html","id":"contributing","dir":"","previous_headings":"","what":"Contributing","title":"Common Functions for Mystery Caller or Audit Studies Evaluating Patient Access to Care","text":"welcome contributions! ’d like help improve tyler package, feel free submit issues pull requests.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/index.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Common Functions for Mystery Caller or Audit Studies Evaluating Patient Access to Care","text":"use package, appreciate citation.","code":"citation(\"tyler\")"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/index.html","id":"code-of-conduct","dir":"","previous_headings":"","what":"Code of conduct","title":"Common Functions for Mystery Caller or Audit Studies Evaluating Patient Access to Care","text":"Please note project released Contributor Code Conduct. participating project agree abide terms.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/ACOG_Districts.html","id":null,"dir":"Reference","previous_headings":"","what":"ACOG Districts Data — ACOG_Districts","title":"ACOG Districts Data — ACOG_Districts","text":"dataset provides mapping U.S. states respective districts defined American College Obstetricians Gynecologists (ACOG). also includes state abbreviations subregion details additional geographic context.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/ACOG_Districts.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"ACOG Districts Data — ACOG_Districts","text":"","code":"ACOG_Districts"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/ACOG_Districts.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"ACOG Districts Data — ACOG_Districts","text":"tibble 52 rows 4 variables: State name U.S. state (e.g., \"Alabama\", \"California\"). ACOG_District district designation assigned ACOG (e.g., \"District VII\"). Subregion subregion state within district (e.g., \"District VII\"). State_Abbreviations two-letter postal abbreviation state (e.g., \"AL\", \"CA\").","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/ACOG_Districts.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"ACOG Districts Data — ACOG_Districts","text":"Derived official ACOG district mappings documentation.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/ACOG_Districts.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"ACOG Districts Data — ACOG_Districts","text":"dataset useful mapping regional analyses ACOG districts. Districts defined align organization's geographic administrative structure. Subregions often match ACOG districts can provide additional context needed.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/ACOG_Districts.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"ACOG Districts Data — ACOG_Districts","text":"","code":"# Load the dataset data(ACOG_Districts)  # View the first few rows head(ACOG_Districts) #> # A tibble: 6 × 4 #>   State      ACOG_District Subregion     State_Abbreviations #>   <chr>      <chr>         <chr>         <chr>               #> 1 Alabama    District VII  District VII  AL                  #> 2 Alaska     District VIII District VIII AK                  #> 3 Arizona    District VIII District VIII AZ                  #> 4 Arkansas   District VII  District VII  AR                  #> 5 California District IX   District IX   CA                  #> 6 Colorado   District VIII District VIII CO                   # Summarize the number of states in each ACOG district table(ACOG_Districts$ACOG_District) #>  #>    District I   District II  District III   District IV   District IX  #>             6             1             2             9             1  #>    District V   District VI  District VII District VIII   District XI  #>             4             7             8            12             1  #>  District XII  #>             1   # Filter for states in District VIII subset(ACOG_Districts, ACOG_District == \"District VIII\") #> # A tibble: 12 × 4 #>    State      ACOG_District Subregion     State_Abbreviations #>    <chr>      <chr>         <chr>         <chr>               #>  1 Alaska     District VIII District VIII AK                  #>  2 Arizona    District VIII District VIII AZ                  #>  3 Colorado   District VIII District VIII CO                  #>  4 Hawaii     District VIII District VIII HI                  #>  5 Idaho      District VIII District VIII ID                  #>  6 Montana    District VIII District VIII MT                  #>  7 Nevada     District VIII District VIII NV                  #>  8 New Mexico District VIII District VIII NM                  #>  9 Oregon     District VIII District VIII OR                  #> 10 Utah       District VIII District VIII UT                  #> 11 Washington District VIII District VIII WA                  #> 12 Wyoming    District VIII District VIII WY"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/MaxTable.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate the Maximum Value(s) and Corresponding Level(s) of a Factor Variable — MaxTable","title":"Calculate the Maximum Value(s) and Corresponding Level(s) of a Factor Variable — MaxTable","text":"function returns level(s) corresponding maximum value(s) factor variable.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/MaxTable.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate the Maximum Value(s) and Corresponding Level(s) of a Factor Variable — MaxTable","text":"","code":"MaxTable(InVec, mult = FALSE)"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/MaxTable.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate the Maximum Value(s) and Corresponding Level(s) of a Factor Variable — MaxTable","text":"InVec Input vector, expected factor variable convertible factor. mult Logical value indicating whether return multiple maximum values just first one. Default FALSE.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/MaxTable.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate the Maximum Value(s) and Corresponding Level(s) of a Factor Variable — MaxTable","text":"mult FALSE, returns level corresponding maximum value factor variable. mult TRUE, returns character vector containing levels maximum value.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/MaxTable.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate the Maximum Value(s) and Corresponding Level(s) of a Factor Variable — MaxTable","text":"","code":"vec <- factor(c(\"A\", \"B\", \"A\", \"C\", \"B\", \"B\")) MaxTable(vec) # Returns \"A\" #> [1] \"B\" MaxTable(vec, mult = TRUE) # Returns c(\"A\", \"B\") #> [1] \"B\""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/MinTable.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate the Minimum Value(s) and Corresponding Level(s) of a Factor Variable — MinTable","title":"Calculate the Minimum Value(s) and Corresponding Level(s) of a Factor Variable — MinTable","text":"function returns level(s) corresponding minimum value(s) factor variable.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/MinTable.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate the Minimum Value(s) and Corresponding Level(s) of a Factor Variable — MinTable","text":"","code":"MinTable(InVec, mult = FALSE)"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/MinTable.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate the Minimum Value(s) and Corresponding Level(s) of a Factor Variable — MinTable","text":"InVec Input vector, expected factor variable convertible factor. mult Logical value indicating whether return multiple minimum values just first one. Default FALSE.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/MinTable.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate the Minimum Value(s) and Corresponding Level(s) of a Factor Variable — MinTable","text":"mult FALSE, returns level corresponding minimum value factor variable. mult TRUE, returns character vector containing levels minimum value.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/MinTable.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate the Minimum Value(s) and Corresponding Level(s) of a Factor Variable — MinTable","text":"","code":"vec <- factor(c(\"A\", \"B\", \"A\", \"C\", \"B\", \"B\")) MinTable(vec) # Returns \"C\" #> [1] \"C\" MinTable(vec, mult = TRUE) # Returns \"C\" #> [1] \"C\""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/acgme.html","id":null,"dir":"Reference","previous_headings":"","what":"ACGME OBGYN Residency Program Data — acgme","title":"ACGME OBGYN Residency Program Data — acgme","text":"dataset provides comprehensive information Obstetrics Gynecology (OBGYN) residency programs accredited Accreditation Council Graduate Medical Education (ACGME). includes program details addresses, accreditation status, program leadership, participating sites, rotation details.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/acgme.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"ACGME OBGYN Residency Program Data — acgme","text":"","code":"acgme"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/acgme.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"ACGME OBGYN Residency Program Data — acgme","text":"tibble 318 rows 142 variables: program_name name OBGYN residency program. address program's mailing address. zip program's ZIP code. city city program located. state state program located. sponsoring_institution_code code sponsoring institution. sponsoring_institution_name name sponsoring institution. phone main contact phone number program. original_accreditation_date date program first received accreditation. accreditation_status current accreditation status (e.g., \"Continued Accreditation\"). director_name name program director. director_date_appointed date program director appointed. coordinator_name_1 name program coordinator. coordinator_phone_1 phone number program coordinator. coordinator_email_1 email address program coordinator. participation_site_code_X code participating site X (X ranges 1 18). participation_site_name_X name participating site X (X ranges 1 18). rotation_required_X Indicates rotation required site X (X ranges 1 18, values \"Yes\" \"\"). rotation_months_yY_X number months allocated rotations site X year Y (X ranges 1 18 Y ranges 1 4).","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/acgme.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"ACGME OBGYN Residency Program Data — acgme","text":"Data obtained ACGME website: https://apps.acgme.org/ads/Public/Programs/Search","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/acgme.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"ACGME OBGYN Residency Program Data — acgme","text":"dataset particularly useful understanding structure requirements OBGYN residency programs across United States. Rotations detailed site year, allowing comprehensive planning analysis. Data includes program leadership details facilitate communication networking.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/acgme.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"ACGME OBGYN Residency Program Data — acgme","text":"","code":"# Load the ACGME OBGYN Residency Data data(acgme)  # View the first few rows of the dataset head(acgme) #> # A tibble: 6 × 142 #>   program_name                  address zip   city  state sponsoring_instituti…¹ #>   <chr>                         <chr>   <chr> <chr> <chr> <chr>                  #> 1 University of Alabama Medica… \"Unive… 35249 Birm… Alab… 010498                 #> 2 USA Health Program            \"Unive… 36604 Mobi… Alab… 010406                 #> 3 University of Arizona Colleg… \"Banne… 85006 Phoe… Ariz… 038179                 #> 4 University of Arizona Colleg… \"Unive… 85724 Tucs… Ariz… 030509                 #> 5 Creighton University School … \"Creig… 85008 Phoe… Ariz… 309502                 #> 6 University of Arkansas for M… \"Unive… 72205 Litt… Arka… 049501                 #> # ℹ abbreviated name: ¹​sponsoring_institution_code #> # ℹ 136 more variables: sponsoring_institution_name <chr>, phone <chr>, #> #   original_accreditation_date <chr>, accreditation_status <chr>, #> #   director_name <chr>, director_date_appointed <chr>, #> #   coordinator_name_1 <chr>, coordinator_phone_1 <chr>, #> #   coordinator_email_1 <chr>, participation_site_code_1 <chr>, #> #   participation_site_name_1 <chr>, rotation_required_1 <chr>, …  # Summarize the dataset summary(acgme) #>  program_name         address              zip                city           #>  Length:318         Length:318         Length:318         Length:318         #>  Class :character   Class :character   Class :character   Class :character   #>  Mode  :character   Mode  :character   Mode  :character   Mode  :character   #>                                                                              #>                                                                              #>                                                                              #>                                                                              #>     state           sponsoring_institution_code sponsoring_institution_name #>  Length:318         Length:318                  Length:318                  #>  Class :character   Class :character            Class :character            #>  Mode  :character   Mode  :character            Mode  :character            #>                                                                             #>                                                                             #>                                                                             #>                                                                             #>     phone           original_accreditation_date accreditation_status #>  Length:318         Length:318                  Length:318           #>  Class :character   Class :character            Class :character     #>  Mode  :character   Mode  :character            Mode  :character     #>                                                                      #>                                                                      #>                                                                      #>                                                                      #>  director_name      director_date_appointed coordinator_name_1 #>  Length:318         Length:318              Length:318         #>  Class :character   Class :character        Class :character   #>  Mode  :character   Mode  :character        Mode  :character   #>                                                                #>                                                                #>                                                                #>                                                                #>  coordinator_phone_1 coordinator_email_1 participation_site_code_1 #>  Length:318          Length:318          Length:318                #>  Class :character    Class :character    Class :character          #>  Mode  :character    Mode  :character    Mode  :character          #>                                                                    #>                                                                    #>                                                                    #>                                                                    #>  participation_site_name_1 rotation_required_1 rotation_months_y1_1 #>  Length:318                Length:318          Min.   : 0.000       #>  Class :character          Class :character    1st Qu.: 9.425       #>  Mode  :character          Mode  :character    Median :11.750       #>                                                Mean   :10.277       #>                                                3rd Qu.:12.000       #>                                                Max.   :13.000       #>                                                                     #>  rotation_months_y2_1 rotation_months_y3_1 rotation_months_y4_1 #>  Min.   : 0.000       Min.   : 0.000       Min.   : 0.000       #>  1st Qu.: 8.000       1st Qu.: 7.000       1st Qu.: 8.000       #>  Median :10.550       Median : 9.000       Median :10.500       #>  Mean   : 9.581       Mean   : 8.895       Mean   : 9.696       #>  3rd Qu.:12.000       3rd Qu.:11.000       3rd Qu.:12.000       #>  Max.   :13.000       Max.   :13.000       Max.   :13.000       #>                                                                 #>  participation_site_code_2 participation_site_name_2 rotation_required_2 #>  Length:318                Length:318                Length:318          #>  Class :character          Class :character          Class :character    #>  Mode  :character          Mode  :character          Mode  :character    #>                                                                          #>                                                                          #>                                                                          #>                                                                          #>  rotation_months_y1_2 rotation_months_y2_2 rotation_months_y3_2 #>  Min.   : 0.000       Min.   : 0.0         Min.   : 0.000       #>  1st Qu.: 0.000       1st Qu.: 0.0         1st Qu.: 0.500       #>  Median : 0.200       Median : 1.0         Median : 1.200       #>  Mean   : 1.494       Mean   : 1.9         Mean   : 2.066       #>  3rd Qu.: 2.000       3rd Qu.: 3.0         3rd Qu.: 3.000       #>  Max.   :13.000       Max.   :12.0         Max.   :12.000       #>  NA's   :39           NA's   :39           NA's   :39           #>  rotation_months_y4_2 participation_site_code_3 participation_site_name_3 #>  Min.   : 0.000       Length:318                Length:318                #>  1st Qu.: 0.000       Class :character          Class :character          #>  Median : 1.000       Mode  :character          Mode  :character          #>  Mean   : 1.719                                                           #>  3rd Qu.: 2.000                                                           #>  Max.   :12.000                                                           #>  NA's   :39                                                               #>  rotation_required_3 rotation_months_y1_3 rotation_months_y2_3 #>  Length:318          Min.   : 0.0000      Min.   : 0.000       #>  Class :character    1st Qu.: 0.0000      1st Qu.: 0.000       #>  Mode  :character    Median : 0.0000      Median : 0.300       #>                      Mean   : 0.7106      Mean   : 1.009       #>                      3rd Qu.: 1.0000      3rd Qu.: 1.500       #>                      Max.   :12.0000      Max.   :10.000       #>                      NA's   :91           NA's   :91           #>  rotation_months_y3_3 rotation_months_y4_3 participation_site_code_4 #>  Min.   :0.000        Min.   : 0.000       Length:318                #>  1st Qu.:0.000        1st Qu.: 0.000       Class :character          #>  Median :1.000        Median : 0.000       Mode  :character          #>  Mean   :1.298        Mean   : 1.041                                 #>  3rd Qu.:2.000        3rd Qu.: 1.500                                 #>  Max.   :9.000        Max.   :10.000                                 #>  NA's   :91           NA's   :91                                     #>  participation_site_name_4 rotation_required_4 rotation_months_y1_4 #>  Length:318                Length:318          Min.   :0.0000       #>  Class :character          Class :character    1st Qu.:0.0000       #>  Mode  :character          Mode  :character    Median :0.0000       #>                                                Mean   :0.3675       #>                                                3rd Qu.:0.1000       #>                                                Max.   :5.0000       #>                                                NA's   :149          #>  rotation_months_y2_4 rotation_months_y3_4 rotation_months_y4_4 #>  Min.   :0.0000       Min.   :0.0000       Min.   : 0.0000      #>  1st Qu.:0.0000       1st Qu.:0.0000       1st Qu.: 0.0000      #>  Median :0.0000       Median :0.5000       Median : 0.0000      #>  Mean   :0.6509       Mean   :0.8882       Mean   : 0.7787      #>  3rd Qu.:1.0000       3rd Qu.:1.0000       3rd Qu.: 1.0000      #>  Max.   :5.0000       Max.   :6.0000       Max.   :12.0000      #>  NA's   :149          NA's   :149          NA's   :149          #>  participation_site_code_5 participation_site_name_5 rotation_required_5 #>  Length:318                Length:318                Length:318          #>  Class :character          Class :character          Class :character    #>  Mode  :character          Mode  :character          Mode  :character    #>                                                                          #>                                                                          #>                                                                          #>                                                                          #>  rotation_months_y1_5 rotation_months_y2_5 rotation_months_y3_5 #>  Min.   : 0.0000      Min.   : 0.0000      Min.   : 0.0000      #>  1st Qu.: 0.0000      1st Qu.: 0.0000      1st Qu.: 0.0000      #>  Median : 0.0000      Median : 0.0000      Median : 0.5000      #>  Mean   : 0.2991      Mean   : 0.6487      Mean   : 0.9584      #>  3rd Qu.: 0.0000      3rd Qu.: 1.0000      3rd Qu.: 1.0000      #>  Max.   :12.0000      Max.   :12.0000      Max.   :12.0000      #>  NA's   :205          NA's   :205          NA's   :205          #>  rotation_months_y4_5 participation_site_code_6 rotation_required_6 #>  Min.   : 0.0000      Length:318                Length:318          #>  1st Qu.: 0.0000      Class :character          Class :character    #>  Median : 0.1000      Mode  :character          Mode  :character    #>  Mean   : 0.6912                                                    #>  3rd Qu.: 1.0000                                                    #>  Max.   :12.0000                                                    #>  NA's   :205                                                        #>  rotation_months_y1_6 rotation_months_y2_6 rotation_months_y3_6 #>  Min.   :0.000        Min.   :0.0000       Min.   :0.0000       #>  1st Qu.:0.000        1st Qu.:0.0000       1st Qu.:0.0000       #>  Median :0.000        Median :0.0000       Median :0.1000       #>  Mean   :0.175        Mean   :0.4789       Mean   :0.7421       #>  3rd Qu.:0.000        3rd Qu.:0.6000       3rd Qu.:1.0000       #>  Max.   :2.500        Max.   :5.0000       Max.   :6.0000       #>  NA's   :242          NA's   :242          NA's   :242          #>  rotation_months_y4_6 participation_site_code_7 participation_site_name_7 #>  Min.   :0.0000       Length:318                Length:318                #>  1st Qu.:0.0000       Class :character          Class :character          #>  Median :0.3000       Mode  :character          Mode  :character          #>  Mean   :0.7474                                                           #>  3rd Qu.:1.0000                                                           #>  Max.   :7.0000                                                           #>  NA's   :242                                                              #>  rotation_required_7 rotation_months_y1_7 rotation_months_y2_7 #>  Length:318          Min.   :0.0000       Min.   :0.0000       #>  Class :character    1st Qu.:0.0000       1st Qu.:0.0000       #>  Mode  :character    Median :0.0000       Median :0.0000       #>                      Mean   :0.1907       Mean   :0.4628       #>                      3rd Qu.:0.0000       3rd Qu.:0.5000       #>                      Max.   :4.0000       Max.   :4.5000       #>                      NA's   :275          NA's   :275          #>  rotation_months_y3_7 rotation_months_y4_7 participation_site_code_8 #>  Min.   :0.0000       Min.   :0.0000       Length:318                #>  1st Qu.:0.0000       1st Qu.:0.0000       Class :character          #>  Median :0.5000       Median :0.2000       Mode  :character          #>  Mean   :0.8605       Mean   :0.7814                                 #>  3rd Qu.:1.0000       3rd Qu.:1.0000                                 #>  Max.   :4.5000       Max.   :7.0000                                 #>  NA's   :275          NA's   :275                                    #>  participation_site_name_8 rotation_required_8 rotation_months_y1_8 #>  Length:318                Length:318          Min.   :0.0          #>  Class :character          Class :character    1st Qu.:0.0          #>  Mode  :character          Mode  :character    Median :0.0          #>                                                Mean   :0.3          #>                                                3rd Qu.:0.0          #>                                                Max.   :3.2          #>                                                NA's   :297          #>  rotation_months_y2_8 rotation_months_y3_8 rotation_months_y4_8 #>  Min.   :0.0000       Min.   :0.0000       Min.   :0.000        #>  1st Qu.:0.0000       1st Qu.:0.0000       1st Qu.:0.000        #>  Median :0.0000       Median :0.5000       Median :0.500        #>  Mean   :0.4857       Mean   :0.5524       Mean   :0.819        #>  3rd Qu.:1.0000       3rd Qu.:1.0000       3rd Qu.:1.000        #>  Max.   :3.0000       Max.   :2.0000       Max.   :4.000        #>  NA's   :297          NA's   :297          NA's   :297          #>  participation_site_code_9 participation_site_name_9 rotation_required_9 #>  Length:318                Length:318                Length:318          #>  Class :character          Class :character          Class :character    #>  Mode  :character          Mode  :character          Mode  :character    #>                                                                          #>                                                                          #>                                                                          #>                                                                          #>  rotation_months_y1_9 rotation_months_y2_9 rotation_months_y3_9 #>  Min.   :0.00000      Min.   :0.0000       Min.   :0.0000       #>  1st Qu.:0.00000      1st Qu.:0.0000       1st Qu.:0.0000       #>  Median :0.00000      Median :0.0000       Median :0.5000       #>  Mean   :0.06923      Mean   :0.2692       Mean   :0.5154       #>  3rd Qu.:0.00000      3rd Qu.:0.4000       3rd Qu.:1.0000       #>  Max.   :0.90000      Max.   :1.0000       Max.   :1.0000       #>  NA's   :305          NA's   :305          NA's   :305          #>  rotation_months_y4_9 participation_site_code_10 participation_site_name_10 #>  Min.   :0.0000       Length:318                 Length:318                 #>  1st Qu.:0.1000       Class :character           Class :character           #>  Median :1.0000       Mode  :character           Mode  :character           #>  Mean   :0.7769                                                             #>  3rd Qu.:1.0000                                                             #>  Max.   :3.0000                                                             #>  NA's   :305                                                                #>  rotation_required_10 rotation_months_y1_10 rotation_months_y2_10 #>  Length:318           Min.   :0.0000        Min.   :0.0000        #>  Class :character     1st Qu.:0.0000        1st Qu.:0.0000        #>  Mode  :character     Median :0.0000        Median :0.0000        #>                       Mean   :0.1111        Mean   :0.2333        #>                       3rd Qu.:0.0000        3rd Qu.:0.1000        #>                       Max.   :1.0000        Max.   :1.0000        #>                       NA's   :309           NA's   :309           #>  rotation_months_y3_10 rotation_months_y4_10 participation_site_code_11 #>  Min.   :0.0000        Min.   :0.0000        Length:318                 #>  1st Qu.:0.1000        1st Qu.:0.0000        Class :character           #>  Median :0.7000        Median :1.0000        Mode  :character           #>  Mean   :0.5889        Mean   :0.6778                                   #>  3rd Qu.:1.0000        3rd Qu.:1.0000                                   #>  Max.   :1.0000        Max.   :2.0000                                   #>  NA's   :309           NA's   :309                                      #>  participation_site_name_11 rotation_required_11 rotation_months_y1_11 #>  Length:318                 Length:318           Min.   :0             #>  Class :character           Class :character     1st Qu.:0             #>  Mode  :character           Mode  :character     Median :0             #>                                                  Mean   :0             #>                                                  3rd Qu.:0             #>                                                  Max.   :0             #>                                                  NA's   :313           #>  rotation_months_y2_11 rotation_months_y3_11 rotation_months_y4_11 #>  Min.   :0.0           Min.   :0.00          Min.   :0.0           #>  1st Qu.:0.0           1st Qu.:0.10          1st Qu.:0.0           #>  Median :1.0           Median :0.70          Median :0.0           #>  Mean   :0.6           Mean   :0.56          Mean   :0.4           #>  3rd Qu.:1.0           3rd Qu.:1.00          3rd Qu.:1.0           #>  Max.   :1.0           Max.   :1.00          Max.   :1.0           #>  NA's   :313           NA's   :313           NA's   :313           #>  participation_site_code_12 participation_site_name_12 rotation_required_12 #>  Length:318                 Length:318                 Length:318           #>  Class :character           Class :character           Class :character     #>  Mode  :character           Mode  :character           Mode  :character     #>                                                                             #>                                                                             #>                                                                             #>                                                                             #>  rotation_months_y1_12 rotation_months_y2_12 rotation_months_y3_12 #>  Min.   : 0.100        Min.   : 0.000        Min.   : 0.000        #>  1st Qu.: 0.775        1st Qu.: 0.075        1st Qu.: 0.075        #>  Median : 6.000        Median : 5.050        Median : 5.050        #>  Mean   : 5.775        Mean   : 5.025        Mean   : 5.025        #>  3rd Qu.:11.000        3rd Qu.:10.000        3rd Qu.:10.000        #>  Max.   :11.000        Max.   :10.000        Max.   :10.000        #>  NA's   :314           NA's   :314           NA's   :314           #>  rotation_months_y4_12 participation_site_code_13 participation_site_name_13 #>  Min.   : 0.000        Length:318                 Length:318                 #>  1st Qu.: 0.075        Class :character           Class :character           #>  Median : 6.050        Mode  :character           Mode  :character           #>  Mean   : 6.025                                                              #>  3rd Qu.:12.000                                                              #>  Max.   :12.000                                                              #>  NA's   :314                                                                 #>  rotation_required_13 rotation_months_y1_13 rotation_months_y2_13 #>  Length:318           Min.   :0             Min.   :0.0           #>  Class :character     1st Qu.:0             1st Qu.:0.1           #>  Mode  :character     Median :0             Median :0.2           #>                       Mean   :0             Mean   :0.2           #>                       3rd Qu.:0             3rd Qu.:0.3           #>                       Max.   :0             Max.   :0.4           #>                       NA's   :316           NA's   :316           #>  rotation_months_y3_13 rotation_months_y4_13 participation_site_code_14 #>  Min.   :0.000         Min.   :0.000         Length:318                 #>  1st Qu.:0.025         1st Qu.:0.025         Class :character           #>  Median :0.050         Median :0.050         Mode  :character           #>  Mean   :0.050         Mean   :0.050                                    #>  3rd Qu.:0.075         3rd Qu.:0.075                                    #>  Max.   :0.100         Max.   :0.100                                    #>  NA's   :316           NA's   :316                                      #>  participation_site_name_14 rotation_required_14 rotation_months_y1_14 #>  Length:318                 Length:318           Min.   :0             #>  Class :character           Class :character     1st Qu.:0             #>  Mode  :character           Mode  :character     Median :0             #>                                                  Mean   :0             #>                                                  3rd Qu.:0             #>                                                  Max.   :0             #>                                                  NA's   :317           #>  rotation_months_y2_14 rotation_months_y3_14 rotation_months_y4_14 #>  Min.   :0             Min.   :0.1           Min.   :0             #>  1st Qu.:0             1st Qu.:0.1           1st Qu.:0             #>  Median :0             Median :0.1           Median :0             #>  Mean   :0             Mean   :0.1           Mean   :0             #>  3rd Qu.:0             3rd Qu.:0.1           3rd Qu.:0             #>  Max.   :0             Max.   :0.1           Max.   :0             #>  NA's   :317           NA's   :317           NA's   :317           #>  participation_site_code_15 participation_site_name_15 rotation_required_15 #>  Length:318                 Length:318                 Length:318           #>  Class :character           Class :character           Class :character     #>  Mode  :character           Mode  :character           Mode  :character     #>                                                                             #>                                                                             #>                                                                             #>                                                                             #>  rotation_months_y1_15 rotation_months_y2_15 rotation_months_y3_15 #>  Min.   :0.1           Min.   :0             Min.   :0             #>  1st Qu.:0.1           1st Qu.:0             1st Qu.:0             #>  Median :0.1           Median :0             Median :0             #>  Mean   :0.1           Mean   :0             Mean   :0             #>  3rd Qu.:0.1           3rd Qu.:0             3rd Qu.:0             #>  Max.   :0.1           Max.   :0             Max.   :0             #>  NA's   :317           NA's   :317           NA's   :317           #>  rotation_months_y4_15 participation_site_code_16 participation_site_name_16 #>  Min.   :0             Length:318                 Length:318                 #>  1st Qu.:0             Class :character           Class :character           #>  Median :0             Mode  :character           Mode  :character           #>  Mean   :0                                                                   #>  3rd Qu.:0                                                                   #>  Max.   :0                                                                   #>  NA's   :317                                                                 #>  rotation_required_16 rotation_months_y1_16 rotation_months_y2_16 #>  Length:318           Min.   :0             Min.   :0             #>  Class :character     1st Qu.:0             1st Qu.:0             #>  Mode  :character     Median :0             Median :0             #>                       Mean   :0             Mean   :0             #>                       3rd Qu.:0             3rd Qu.:0             #>                       Max.   :0             Max.   :0             #>                       NA's   :317           NA's   :317           #>  rotation_months_y3_16 rotation_months_y4_16 participation_site_code_17 #>  Min.   :0             Min.   :0             Length:318                 #>  1st Qu.:0             1st Qu.:0             Class :character           #>  Median :0             Median :0             Mode  :character           #>  Mean   :0             Mean   :0                                        #>  3rd Qu.:0             3rd Qu.:0                                        #>  Max.   :0             Max.   :0                                        #>  NA's   :317           NA's   :317                                      #>  participation_site_name_17 rotation_required_17 rotation_months_y1_17 #>  Length:318                 Length:318           Min.   :0             #>  Class :character           Class :character     1st Qu.:0             #>  Mode  :character           Mode  :character     Median :0             #>                                                  Mean   :0             #>                                                  3rd Qu.:0             #>                                                  Max.   :0             #>                                                  NA's   :317           #>  rotation_months_y2_17 rotation_months_y3_17 rotation_months_y4_17 #>  Min.   :0             Min.   :0             Min.   :0             #>  1st Qu.:0             1st Qu.:0             1st Qu.:0             #>  Median :0             Median :0             Median :0             #>  Mean   :0             Mean   :0             Mean   :0             #>  3rd Qu.:0             3rd Qu.:0             3rd Qu.:0             #>  Max.   :0             Max.   :0             Max.   :0             #>  NA's   :317           NA's   :317           NA's   :317           #>  participation_site_code_18 participation_site_name_18 rotation_required_18 #>  Length:318                 Length:318                 Length:318           #>  Class :character           Class :character           Class :character     #>  Mode  :character           Mode  :character           Mode  :character     #>                                                                             #>                                                                             #>                                                                             #>                                                                             #>  rotation_months_y1_18 rotation_months_y2_18 rotation_months_y3_18 #>  Min.   :0             Min.   :0             Min.   :0.6           #>  1st Qu.:0             1st Qu.:0             1st Qu.:0.6           #>  Median :0             Median :0             Median :0.6           #>  Mean   :0             Mean   :0             Mean   :0.6           #>  3rd Qu.:0             3rd Qu.:0             3rd Qu.:0.6           #>  Max.   :0             Max.   :0             Max.   :0.6           #>  NA's   :317           NA's   :317           NA's   :317           #>  rotation_months_y4_18   website           program_code       #>  Min.   :0.3           Length:318         Min.   :2.200e+09   #>  1st Qu.:0.3           Class :character   1st Qu.:2.202e+09   #>  Median :0.3           Mode  :character   Median :2.203e+09   #>  Mean   :0.3                              Mean   :2.203e+09   #>  3rd Qu.:0.3                              3rd Qu.:2.204e+09   #>  Max.   :0.3                              Max.   :2.206e+09   #>  NA's   :317                                                   # Analyze the number of programs by state table(acgme$state) #>  #>              Alabama              Arizona             Arkansas  #>                    2                    3                    1  #>           California             Colorado          Connecticut  #>                   27                    2                    6  #>             Delaware District of Columbia              Florida  #>                    1                    4                   14  #>              Georgia               Hawaii             Illinois  #>                    7                    2                   15  #>              Indiana                 Iowa               Kansas  #>                    2                    1                    3  #>             Kentucky            Louisiana                Maine  #>                    3                    5                    1  #>             Maryland        Massachusetts             Michigan  #>                    7                    6                   24  #>            Minnesota          Mississippi             Missouri  #>                    2                    1                    5  #>             Nebraska               Nevada        New Hampshire  #>                    2                    2                    1  #>           New Jersey           New Mexico             New York  #>                   16                    1                   42  #>       North Carolina                 Ohio             Oklahoma  #>                    9                   16                    5  #>               Oregon         Pennsylvania          Puerto Rico  #>                    1                   21                    3  #>         Rhode Island       South Carolina            Tennessee  #>                    1                    4                    8  #>                Texas                 Utah              Vermont  #>                   24                    1                    1  #>             Virginia           Washington        West Virginia  #>                    7                    3                    3  #>            Wisconsin  #>                    3   # Filter programs in California subset(acgme, state == \"California\") #> # A tibble: 27 × 142 #>    program_name                 address zip   city  state sponsoring_instituti…¹ #>    <chr>                        <chr>   <chr> <chr> <chr> <chr>                  #>  1 HCA Healthcare Riverside  P… \"River… 92501 Rive… Cali… 059514                 #>  2 University of California Ri… \"River… 92501 Rive… Cali… 059511                 #>  3 Arrowhead Regional Medical … \"400 N… 92324 Colt… Cali… 050207                 #>  4 Marian Regional Medical Cen… \"1400 … 93454 Sant… Cali… 059593                 #>  5 UHS Southern California Med… \"25500… 25500 Murr… Cali… 059802                 #>  6 Naval Medical Center (San D… \"Naval… 34730 San … Cali… 050386                 #>  7 University of Southern Cali… \"LAC+U… 90033 Los … Cali… 058116                 #>  8 Kaiser Permanente Southern … \"Kaise… 90027 Los … Cali… 058072                 #>  9 Kaiser Permanente Northern … \"Kaise… 94611 Oakl… Cali… 058090                 #> 10 Kaiser Permanente Northern … \"Kaise… 94115 San … Cali… 058090                 #> # ℹ 17 more rows #> # ℹ abbreviated name: ¹​sponsoring_institution_code #> # ℹ 136 more variables: sponsoring_institution_name <chr>, phone <chr>, #> #   original_accreditation_date <chr>, accreditation_status <chr>, #> #   director_name <chr>, director_date_appointed <chr>, #> #   coordinator_name_1 <chr>, coordinator_phone_1 <chr>, #> #   coordinator_email_1 <chr>, participation_site_code_1 <chr>, …"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/arsenal_tables_write2word.html","id":null,"dir":"Reference","previous_headings":"","what":"Write Arsenal Table Object to Word Document with Error Handling and Logging — arsenal_tables_write2word","title":"Write Arsenal Table Object to Word Document with Error Handling and Logging — arsenal_tables_write2word","text":"function exports Arsenal table object Word document ease review sharing, logging step handling errors.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/arsenal_tables_write2word.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Write Arsenal Table Object to Word Document with Error Handling and Logging — arsenal_tables_write2word","text":"","code":"arsenal_tables_write2word(object, filename)"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/arsenal_tables_write2word.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Write Arsenal Table Object to Word Document with Error Handling and Logging — arsenal_tables_write2word","text":"object Arsenal table object export, typically created using arsenal::tableby. filename string representing filename (without extension) output Word document.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/arsenal_tables_write2word.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Write Arsenal Table Object to Word Document with Error Handling and Logging — arsenal_tables_write2word","text":"None. Outputs Word document specified location.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/arsenal_tables_write2word.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Write Arsenal Table Object to Word Document with Error Handling and Logging — arsenal_tables_write2word","text":"","code":"if (FALSE) { # \\dontrun{ # Example 1: Export a table to Word arsenal_tables_write2word(my_table, \"physician_summary\")  # Example 2: Saving with a custom filename arsenal_tables_write2word(my_table, \"custom_output\")  # Example 3: Exporting a different Arsenal table object another_table <- arsenal::tableby(~ var1 + var2, data = sample_data) arsenal_tables_write2word(another_table, \"analysis_output\") } # }"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/calcpercentages.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate the Percentage of the Most Common Value in a Categorical Variable — calcpercentages","title":"Calculate the Percentage of the Most Common Value in a Categorical Variable — calcpercentages","text":"function calculates percentage frequent value specified categorical variable within data frame. identifies common value, count, proportion relative total number observations.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/calcpercentages.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate the Percentage of the Most Common Value in a Categorical Variable — calcpercentages","text":"","code":"calcpercentages(df, variable)"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/calcpercentages.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate the Percentage of the Most Common Value in a Categorical Variable — calcpercentages","text":"df data frame containing categorical variable analyze. variable character string specifying name categorical variable df.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/calcpercentages.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate the Percentage of the Most Common Value in a Categorical Variable — calcpercentages","text":"data frame following columns: variable common value specified variable. n count common value. percentage percentage total count represented common value.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/calcpercentages.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Calculate the Percentage of the Most Common Value in a Categorical Variable — calcpercentages","text":"function first converts specified variable character type factor. counts occurrences unique value variable, identifies frequent value, calculates percentage total. ties common value, one returned.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/calcpercentages.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate the Percentage of the Most Common Value in a Categorical Variable — calcpercentages","text":"","code":"# Example 1: Basic usage with a simple dataset df <- data.frame(category = c(\"A\", \"B\", \"A\", \"C\", \"A\", \"B\", \"B\", \"A\")) result <- calcpercentages(df, \"category\") print(result) #>   \"category\" n percentage #> 1   category 8        100  # Example 2: Dataset with ties for the most common value df_tie <- data.frame(category = c(\"A\", \"B\", \"A\", \"B\", \"C\", \"C\", \"C\", \"A\", \"B\")) result <- calcpercentages(df_tie, \"category\") print(result) #>   \"category\" n percentage #> 1   category 9        100  # Example 3: Dataset with missing values df_na <- data.frame(category = c(\"A\", NA, \"A\", \"C\", \"A\", \"B\", \"B\", NA)) result <- calcpercentages(df_na, \"category\") print(result) #>   \"category\" n percentage #> 1   category 8        100"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/calculate_descriptive_stats.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate Descriptive Statistics with Robust Logging — calculate_descriptive_stats","title":"Calculate Descriptive Statistics with Robust Logging — calculate_descriptive_stats","text":"function calculates median, 25th percentile (Q1), 75th percentile (Q3) specified column dataframe. function includes detailed logging inputs, outputs, data transformation.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/calculate_descriptive_stats.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate Descriptive Statistics with Robust Logging — calculate_descriptive_stats","text":"","code":"calculate_descriptive_stats(df, column, verbose = TRUE)"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/calculate_descriptive_stats.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate Descriptive Statistics with Robust Logging — calculate_descriptive_stats","text":"df dataframe containing data. column string representing column name calculate descriptive statistics. verbose boolean indicating whether print detailed logs. Default TRUE.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/calculate_descriptive_stats.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate Descriptive Statistics with Robust Logging — calculate_descriptive_stats","text":"list containing median, 25th percentile (Q1), 75th percentile (Q3) specified column.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/calculate_descriptive_stats.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate Descriptive Statistics with Robust Logging — calculate_descriptive_stats","text":"","code":"# Example: Calculate descriptive statistics for a column with logging stats <- calculate_descriptive_stats(df, \"business_days_until_appointment\", verbose = TRUE) #> Error: The `df` argument must be a data frame."},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/calculate_distribution.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate Demographic Distribution with Robust Logging — calculate_distribution","title":"Calculate Demographic Distribution with Robust Logging — calculate_distribution","text":"function calculates distribution categorical variable within data frame, including counts percentages. also logs inputs, outputs, transformations transparency debugging purposes.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/calculate_distribution.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate Demographic Distribution with Robust Logging — calculate_distribution","text":"","code":"calculate_distribution(df, column)"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/calculate_distribution.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate Demographic Distribution with Robust Logging — calculate_distribution","text":"df data frame containing data. column string representing name column distribution calculated.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/calculate_distribution.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate Demographic Distribution with Robust Logging — calculate_distribution","text":"data frame count, total, percentage level specified column.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/calculate_distribution.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate Demographic Distribution with Robust Logging — calculate_distribution","text":"","code":"df <- data.frame(gender = c(\"Male\", \"Female\", \"Female\", \"Male\", \"Male\", \"Female\", NA)) result <- calculate_distribution(df, \"gender\") #> Starting calculate_distribution... #> Input Data Frame: #>   gender #> 1   Male #> 2 Female #> 3 Female #> 4   Male #> 5   Male #> 6 Female #> Column to Calculate Distribution For: gender  #> Filtered Data Frame (NA removed): #>   gender #> 1   Male #> 2 Female #> 3 Female #> 4   Male #> 5   Male #> 6 Female #> Final Distribution Result: #> # A tibble: 1 × 4 #>   gender count total percent #>   <chr>  <int> <int>   <dbl> #> 1 Female     3     6      50 print(result) #> # A tibble: 1 × 4 #>   gender count total percent #>   <chr>  <int> <int>   <dbl> #> 1 Female     3     6      50"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/calculate_proportion.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate the Proportion of Each Level in a Categorical Variable with Logging — calculate_proportion","title":"Calculate the Proportion of Each Level in a Categorical Variable with Logging — calculate_proportion","text":"function calculates proportion level specified categorical variable within data frame. returns data frame counts percentages level, logging process.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/calculate_proportion.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate the Proportion of Each Level in a Categorical Variable with Logging — calculate_proportion","text":"","code":"calculate_proportion(df, variable_name, log_file = \"calculate_proportion.log\")"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/calculate_proportion.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate the Proportion of Each Level in a Categorical Variable with Logging — calculate_proportion","text":"df data frame containing categorical variable. variable_name name categorical variable proportions calculated, passed unquoted expression. log_file path log file logs saved.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/calculate_proportion.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate the Proportion of Each Level in a Categorical Variable with Logging — calculate_proportion","text":"data frame two columns: n (count level) percent (percentage total count represented level).","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/calculate_proportion.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Calculate the Proportion of Each Level in a Categorical Variable with Logging — calculate_proportion","text":"function counts occurrences unique value specified variable calculates percentage value represents total count. percentages rounded two decimal places.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/check_normality.html","id":null,"dir":"Reference","previous_headings":"","what":"Check Normality and Summarize Data — check_normality","title":"Check Normality and Summarize Data — check_normality","text":"function checks normality specified variable dataframe using Shapiro-Wilk test provides summary statistics (mean standard deviation normal, median IQR normal).","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/check_normality.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check Normality and Summarize Data — check_normality","text":"","code":"check_normality(data, variable)"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/check_normality.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check Normality and Summarize Data — check_normality","text":"data dataframe containing data. variable string specifying column name variable checked summarized.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/check_normality.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check Normality and Summarize Data — check_normality","text":"list containing summary statistics (mean standard deviation normal, median IQR normal).","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/check_normality.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check Normality and Summarize Data — check_normality","text":"","code":"# Example usage with a dataframe 'df' and outcome variable 'business_days_until_appointment' check_normality(df, \"business_days_until_appointment\") #> Error: Error: 'data' must be a data frame."},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/clean_npi_entries.html","id":null,"dir":"Reference","previous_headings":"","what":"Clean NPI Entries Function — clean_npi_entries","title":"Clean NPI Entries Function — clean_npi_entries","text":"function cleans NPI search results normalizing credentials, applying filters taxonomies, summarizing entries NPI. includes console logging key steps.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/clean_npi_entries.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Clean NPI Entries Function — clean_npi_entries","text":"","code":"clean_npi_entries(   npi_entries,   basic_credentials = c(\"MD\", \"DO\"),   taxonomy_filter = \"Obstetrics & Gynecology\" )"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/clean_npi_entries.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Clean NPI Entries Function — clean_npi_entries","text":"npi_entries dataframe containing NPI search results. basic_credentials character vector credentials filter (default c(\"MD\", \"\")). taxonomy_filter string filtering taxonomies (default \"Obstetrics & Gynecology\").","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/clean_npi_entries.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Clean NPI Entries Function — clean_npi_entries","text":"cleaned dataframe summarized NPI entries.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/clean_npi_entries.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Clean NPI Entries Function — clean_npi_entries","text":"","code":"# Example 1: Basic cleaning of NPI entries with default parameters clean_npi_entries(npi_results) #> Error: 'is.data.frame' is not an exported object from 'namespace:assertthat'  # Example 2: Cleaning NPI entries, filtering for a specific taxonomy clean_npi_entries(npi_results, taxonomy_filter = \"Anesthesiology\") #> Error: 'is.data.frame' is not an exported object from 'namespace:assertthat'  # Example 3: Cleaning NPI entries, specifying different credentials clean_npi_entries(npi_results, basic_credentials = c(\"PA\", \"NP\")) #> Error: 'is.data.frame' is not an exported object from 'namespace:assertthat'"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/clean_phase_2_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Clean and Process Phase 2 Data — clean_phase_2_data","title":"Clean and Process Phase 2 Data — clean_phase_2_data","text":"function reads data file data frame, cleans column names, applies renaming based specified criteria facilitate data analysis. function logs step process, including data loading, column cleaning, renaming transparency.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/clean_phase_2_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Clean and Process Phase 2 Data — clean_phase_2_data","text":"","code":"clean_phase_2_data(   data_or_path,   required_strings,   standard_names,   output_csv_path = NULL )"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/clean_phase_2_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Clean and Process Phase 2 Data — clean_phase_2_data","text":"data_or_path Path data file data frame. required_strings Vector substrings search column names. standard_names Vector new names apply matched columns. output_csv_path Optional. provided, cleaned data saved path.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/clean_phase_2_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Clean and Process Phase 2 Data — clean_phase_2_data","text":"data frame processed data.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/clean_phase_2_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Clean and Process Phase 2 Data — clean_phase_2_data","text":"","code":"# Example 1: Cleaning data from a CSV file input_path <- \"path_to_your_data.csv\" required_strings <- c(\"physician_information\", \"able_to_contact_office\") standard_names <- c(\"physician_info\", \"contact_office\") cleaned_data <- clean_phase_2_data(input_path, required_strings, standard_names) #> Error: Error: If 'data_or_path' is a string, it must be a valid, readable file path.  # Example 2: Directly using a data frame df <- data.frame(DocInfo = 1:5, ContactData = 6:10) required_strings <- c(\"doc_info\", \"contact_data\") standard_names <- c(\"doctor_info\", \"patient_contact_info\") cleaned_df <- clean_phase_2_data(df, required_strings, standard_names) #> --- Starting data cleaning process --- #> Input data or path:   #> Error in cat(\"Input data or path: \", data_or_path, \"\\n\"): argument 2 (type 'list') cannot be handled by 'cat' print(cleaned_df)  # Should show updated column names #> Error: object 'cleaned_df' not found"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/convert_list_to_df_expanded.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert a List of Column Names to an Expanded Data Frame — convert_list_to_df_expanded","title":"Convert a List of Column Names to an Expanded Data Frame — convert_list_to_df_expanded","text":"helper function converts named list column names, grouped table, expanded data frame column name placed separate column.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/convert_list_to_df_expanded.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert a List of Column Names to an Expanded Data Frame — convert_list_to_df_expanded","text":"","code":"convert_list_to_df_expanded(column_list)"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/convert_list_to_df_expanded.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert a List of Column Names to an Expanded Data Frame — convert_list_to_df_expanded","text":"column_list named list element contains column names table.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/convert_list_to_df_expanded.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert a List of Column Names to an Expanded Data Frame — convert_list_to_df_expanded","text":"data frame table name corresponding columns.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/convert_list_to_df_expanded.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert a List of Column Names to an Expanded Data Frame — convert_list_to_df_expanded","text":"","code":"# Example 1: Convert a list of column names to an expanded data frame test_list <- list(table1 = c(\"col1\", \"col2\"), table2 = c(\"col1\", \"col2\", \"col3\")) expanded_df <- convert_list_to_df_expanded(test_list) #> Error: 'is.named' is not an exported object from 'namespace:assertthat' print(expanded_df) #> Error: object 'expanded_df' not found  # Example 2: Handling missing columns in some tables test_list <- list(table1 = c(\"col1\", \"col2\"), table2 = c(\"col1\")) expanded_df <- convert_list_to_df_expanded(test_list) #> Error: 'is.named' is not an exported object from 'namespace:assertthat' print(expanded_df) #> Error: object 'expanded_df' not found  # Example 3: Convert an empty list empty_list <- list() expanded_df_empty <- convert_list_to_df_expanded(empty_list) #> Error: 'is.named' is not an exported object from 'namespace:assertthat' print(expanded_df_empty)  # Should return an empty data frame #> Error: object 'expanded_df_empty' not found"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/count_physicians_by_group.html","id":null,"dir":"Reference","previous_headings":"","what":"Count Physicians by State or Subdivision with Logging — count_physicians_by_group","title":"Count Physicians by State or Subdivision with Logging — count_physicians_by_group","text":"function counts physicians grouped either state U.S. Census subdivision, using us_census_bureau_regions_df dataset. logs inputs, transformations, outputs. results can optionally saved CSV file.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/count_physicians_by_group.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Count Physicians by State or Subdivision with Logging — count_physicians_by_group","text":"","code":"count_physicians_by_group(   data,   state_name_column = \"state_code\",   phone_column = \"phone_number\",   first_name_column = \"first\",   last_name_column = \"last\",   group_by = \"state\",   output_to_csv = NULL )"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/count_physicians_by_group.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Count Physicians by State or Subdivision with Logging — count_physicians_by_group","text":"data dataframe containing physician data, including state, phone, name columns. state_name_column string specifying column name state information dataset. Default \"state_code\". phone_column string specifying column name phone numbers dataset. Default \"phone_number\". first_name_column string specifying column name physicians' first names. Default \"first\". last_name_column string specifying column name physicians' last names. Default \"last\". group_by string specifying group counts. Options \"state\" state-level counts \"subdivision\" U.S. Census subdivision counts. Default \"state\". output_to_csv string specifying file path save counts CSV file. NULL, file saved. Default NULL.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/count_physicians_by_group.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Count Physicians by State or Subdivision with Logging — count_physicians_by_group","text":"dataframe counts physicians grouped state subdivision.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/count_physicians_by_group.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Count Physicians by State or Subdivision with Logging — count_physicians_by_group","text":"","code":"# Example 1: Count physicians by state state_counts <- count_physicians_by_group(   data = physicians_data,   state_name_column = \"state_code\",   phone_column = \"phone\",   first_name_column = \"first_name\",   last_name_column = \"last_name\",   group_by = \"state\" ) #> Error: Failed to evaluate glue component {nrow(data)} #> Caused by error: #> ! object 'physicians_data' not found  # Example 2: Count physicians by U.S. Census subdivision subdivision_counts <- count_physicians_by_group(   data = physicians_data,   state_name_column = \"state_code\",   phone_column = \"phone\",   first_name_column = \"first_name\",   last_name_column = \"last_name\",   group_by = \"subdivision\" ) #> Error: Failed to evaluate glue component {nrow(data)} #> Caused by error: #> ! object 'physicians_data' not found  # Example 3: Save counts to a CSV file count_physicians_by_group(   data = physicians_data,   group_by = \"state\",   output_to_csv = \"state_counts.csv\" ) #> Error: Failed to evaluate glue component {nrow(data)} #> Caused by error: #> ! object 'physicians_data' not found"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/count_unique_physicians.html","id":null,"dir":"Reference","previous_headings":"","what":"Count Unique Physicians Based on Insurance Type and Exclusion Reason — count_unique_physicians","title":"Count Unique Physicians Based on Insurance Type and Exclusion Reason — count_unique_physicians","text":"function filters dataframe physician data based insurance type, reason exclusion, appointment availability, counts number unique physicians meet criteria.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/count_unique_physicians.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Count Unique Physicians Based on Insurance Type and Exclusion Reason — count_unique_physicians","text":"","code":"count_unique_physicians(   df,   insurance_type,   reason_for_exclusion = NULL,   verbose = TRUE )"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/count_unique_physicians.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Count Unique Physicians Based on Insurance Type and Exclusion Reason — count_unique_physicians","text":"df dataframe containing physician data. Must include columns 'insurance', 'reason_for_exclusions', 'business_days_until_appointment', 'phone'. insurance_type string specifying insurance type filter (e.g., \"Medicaid\"). reason_for_exclusion string specifying reason exclusion filter . Default NULL, includes rows regardless exclusion reason. verbose boolean indicating whether print detailed logs. Default TRUE.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/count_unique_physicians.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Count Unique Physicians Based on Insurance Type and Exclusion Reason — count_unique_physicians","text":"integer representing number unique physicians meet specified criteria.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/count_unique_physicians.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Count Unique Physicians Based on Insurance Type and Exclusion Reason — count_unique_physicians","text":"","code":"# Example 1: Counting unique physicians with specific insurance and reason for exclusion df <- data.frame(   insurance = c(\"Medicaid\", \"Medicaid\", \"Blue Cross/Blue Shield\", \"Medicaid\"),   reason_for_exclusions = c(     \"Able to contact\", \"Not available\", \"Able to contact\", \"Able to contact\"   ),   business_days_until_appointment = c(5, 0, 10, 3),   phone = c(\"123-456-7890\", \"123-456-7890\", \"098-765-4321\", \"234-567-8901\") ) unique_count <- count_unique_physicians(   df,   insurance_type = \"Medicaid\",   reason_for_exclusion = \"Able to contact\" ) #> Starting count_unique_physicians function... #> Insurance Type: Medicaid #> Reason for Exclusion: Able to contact #> Filtered rows by insurance type: 3 remaining. #> Filtered rows by reason for exclusion: 2 remaining. #> Filtered rows with positive business days until appointment: 2 remaining. #> Number of unique physicians: 2 #> Function count_unique_physicians completed successfully. print(unique_count)  # Expected output: 1 #> [1] 2  # Example 2: Counting unique physicians without specifying a reason for exclusion df2 <- data.frame(   insurance = c(\"Blue Cross/Blue Shield\", \"Blue Cross/Blue Shield\", \"Medicaid\"),   reason_for_exclusions = c(\"Able to contact\", \"Not available\", \"Able to contact\"),   business_days_until_appointment = c(3, 5, 1),   phone = c(\"321-654-0987\", \"321-654-0987\", \"654-321-0987\") ) unique_count2 <- count_unique_physicians(   df2,   insurance_type = \"Blue Cross/Blue Shield\" ) #> Starting count_unique_physicians function... #> Insurance Type: Blue Cross/Blue Shield #> No specific reason for exclusion is provided. #> Filtered rows by insurance type: 2 remaining. #> Filtered rows with positive business days until appointment: 2 remaining. #> Number of unique physicians: 1 #> Function count_unique_physicians completed successfully. print(unique_count2)  # Expected output: 1 #> [1] 1  # Example 3: Using verbose logging to see detailed steps df3 <- data.frame(   insurance = c(\"Medicaid\", \"Medicaid\", \"Medicaid\", \"Medicaid\"),   reason_for_exclusions = c(     \"Able to contact\", \"Able to contact\", \"Not available\", \"Able to contact\"   ),   business_days_until_appointment = c(2, 1, 0, 4),   phone = c(\"111-222-3333\", \"111-222-3333\", \"222-333-4444\", \"333-444-5555\") ) unique_count3 <- count_unique_physicians(   df3,   insurance_type = \"Medicaid\",   verbose = TRUE ) #> Starting count_unique_physicians function... #> Insurance Type: Medicaid #> No specific reason for exclusion is provided. #> Filtered rows by insurance type: 4 remaining. #> Filtered rows with positive business days until appointment: 3 remaining. #> Number of unique physicians: 2 #> Function count_unique_physicians completed successfully. print(unique_count3)  # Expected output: 2 #> [1] 2"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/create_and_plot_interaction.html","id":null,"dir":"Reference","previous_headings":"","what":"Create and Plot Interaction Effects in GLMM — create_and_plot_interaction","title":"Create and Plot Interaction Effects in GLMM — create_and_plot_interaction","text":"function reads data specified file, fits generalized linear mixed model (GLMM) specified interaction term, creates plot visualize interaction effects. plot saved specified directory.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/create_and_plot_interaction.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create and Plot Interaction Effects in GLMM — create_and_plot_interaction","text":"","code":"create_and_plot_interaction(   data_path,   response_variable,   variable_of_interest,   interaction_variable,   random_intercept,   output_path,   resolution = 100 )"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/create_and_plot_interaction.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create and Plot Interaction Effects in GLMM — create_and_plot_interaction","text":"data_path character string specifying path .rds file containing dataset. response_variable character string specifying name response variable dataset. variable_of_interest character string specifying first categorical predictor variable interaction. interaction_variable character string specifying second categorical predictor variable interaction. random_intercept character string specifying variable used random intercept model (e.g., \"city\"). output_path character string specifying directory interaction plot saved. resolution integer specifying resolution (DPI) saving plot. Defaults 100.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/create_and_plot_interaction.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create and Plot Interaction Effects in GLMM — create_and_plot_interaction","text":"list containing fitted GLMM (model) summarized data used effects plot (effects_plot_data).","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/create_and_plot_interaction.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create and Plot Interaction Effects in GLMM — create_and_plot_interaction","text":"","code":"if (FALSE) { # \\dontrun{ result <- create_and_plot_interaction(   data_path = \"data/phase2_analysis.rds\",   response_variable = \"business_days_until_appointment\",   variable_of_interest = \"appointment_center\",   interaction_variable = \"gender\",   random_intercept = \"city\",   output_path = \"results/figures\",   resolution = 100 ) } # }"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/create_bar_plot.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a Bar Plot with Total Sample Size in the Title — create_bar_plot","title":"Create a Bar Plot with Total Sample Size in the Title — create_bar_plot","text":"function generates bar plot based categorical variable facets plot grouping variable. plot title automatically includes total sample size (N). function also supports custom axis labels, returns plot object manipulation saving.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/create_bar_plot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a Bar Plot with Total Sample Size in the Title — create_bar_plot","text":"","code":"create_bar_plot(   input_data,   category_var,   grouping_var,   title = NULL,   x_axis_label = NULL,   y_axis_label = \"Count\",   output_directory = \"output\",   filename_prefix = \"bar_plot\",   verbose = TRUE )"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/create_bar_plot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a Bar Plot with Total Sample Size in the Title — create_bar_plot","text":"input_data dataframe containing data plotted. category_var string representing column name categorical variable x-axis (e.g., insurance type). grouping_var string representing column name facet wrap (grouping variable). title string specifying title plot. Default NULL, function generate title based category_var grouping_var. x_axis_label string specifying label x-axis. Default NULL, function use column name x-axis variable. y_axis_label string specifying label y-axis. Default \"Count\". output_directory string representing directory plot files saved. Default \"output\". filename_prefix string used prefix generated plot filenames. Default \"bar_plot\". verbose boolean indicating whether print messages saved plot locations. Default TRUE.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/create_bar_plot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a Bar Plot with Total Sample Size in the Title — create_bar_plot","text":"function returns plot object manipulation saving.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/create_bar_plot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a Bar Plot with Total Sample Size in the Title — create_bar_plot","text":"","code":"# Example 1: Basic usage with a categorical and facet variable create_bar_plot(   input_data = my_data,   category_var = \"insurance_type\",   grouping_var = \"region\",   title = \"Insurance Type Distribution by Region\",   x_axis_label = \"Insurance Type\",   y_axis_label = \"Number of Observations\" ) #> Error: object 'my_data' not found"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/create_density_plot.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a Density Plot for Mystery Caller Studies with Optional Transformations — create_density_plot","title":"Create a Density Plot for Mystery Caller Studies with Optional Transformations — create_density_plot","text":"function generates density plot designed mystery caller studies, allowing visualization waiting times similar outcomes across different categories, insurance types. function supports transformations x-axis custom labels.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/create_density_plot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a Density Plot for Mystery Caller Studies with Optional Transformations — create_density_plot","text":"","code":"create_density_plot(   data,   x_var,   fill_var,   x_transform = \"none\",   dpi = 100,   output_dir = \"output\",   file_prefix = \"density_plot\",   x_label = NULL,   y_label = \"Density\",   plot_title = NULL,   verbose = TRUE )"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/create_density_plot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a Density Plot for Mystery Caller Studies with Optional Transformations — create_density_plot","text":"data dataframe containing data plotted. Must contain variables specified x_var fill_var. x_var string representing column name x-axis variable. numeric variable (e.g., waiting time days). fill_var string representing column name fill variable. categorical factor variable (e.g., insurance type). x_transform string specifying transformation x-axis: \"log\" log transformation (log1p), \"sqrt\" square root transformation, \"none\" transformation. Default \"none\". dpi integer specifying resolution saved plot dots per inch (DPI). Default 100. output_dir string representing directory plot files saved. Default \"output\". file_prefix string used prefix generated plot filenames. filenames timestamp appended ensure uniqueness. Default \"density_plot\". x_label string specifying label x-axis. Default NULL (uses x_var). y_label string specifying label y-axis. Default \"Density\". plot_title string specifying title plot. Default NULL (title). verbose boolean indicating whether print messages saved plot locations. Default TRUE.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/create_density_plot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a Density Plot for Mystery Caller Studies with Optional Transformations — create_density_plot","text":"function displays plot saves specified directory.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/create_density_plot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a Density Plot for Mystery Caller Studies with Optional Transformations — create_density_plot","text":"","code":"# Example 1: Basic density plot with log transformation create_density_plot(     data = df3,     x_var = \"business_days_until_appointment\",     fill_var = \"insurance\",     x_transform = \"log\",     dpi = 100,     output_dir = \"figures\",     file_prefix = \"waiting_time_density\",     x_label = \"Log (Waiting Times in Days)\",     y_label = \"Density\",     plot_title = \"Density Plot of Waiting Times by Insurance\" ) #> Error: object 'df3' not found"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/create_dot_plot.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a Dot Plot with Error Bars for Mystery Caller Studies with Logging and Error Handling — create_dot_plot","title":"Create a Dot Plot with Error Bars for Mystery Caller Studies with Logging and Error Handling — create_dot_plot","text":"function generates dot plot visualizing median values error bars across different categories, insurance types. includes error handling, meaningful variable names, default behaviors ease use. Extensive logging tracks inputs, transformations, outputs.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/create_dot_plot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a Dot Plot with Error Bars for Mystery Caller Studies with Logging and Error Handling — create_dot_plot","text":"","code":"create_dot_plot(   dataset,   category_var,   value_var = \"median_days\",   lower_bound_var = \"q1\",   upper_bound_var = \"q3\",   dpi = 100,   output_directory = \"output\",   filename_prefix = \"dot_plot\",   x_label = NULL,   y_label = NULL,   plot_title = NULL,   verbose = TRUE )"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/create_dot_plot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a Dot Plot with Error Bars for Mystery Caller Studies with Logging and Error Handling — create_dot_plot","text":"dataset dataframe containing data plotted. Must contain variables specified category_var, value_var, lower_bound_var, upper_bound_var. category_var string representing column name categorical variable x-axis (e.g., insurance type). value_var string representing column name numeric variable y-axis (e.g., median days). lower_bound_var string representing column name lower bound error bars (e.g., first quartile). upper_bound_var string representing column name upper bound error bars (e.g., third quartile). dpi integer specifying resolution saved plot dots per inch (DPI). Default 100. output_directory string representing directory plot files saved. Default \"output\". filename_prefix string used prefix generated plot filenames. filenames timestamp appended uniqueness. x_label string specifying label x-axis. Default NULL (uses category_var). y_label string specifying label y-axis. Default NULL (uses value_var). plot_title string specifying title plot. Default NULL (title). verbose boolean indicating whether print messages saved plot locations. Default TRUE.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/create_dot_plot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a Dot Plot with Error Bars for Mystery Caller Studies with Logging and Error Handling — create_dot_plot","text":"function displays plot saves specified directory.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/create_dot_plot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a Dot Plot with Error Bars for Mystery Caller Studies with Logging and Error Handling — create_dot_plot","text":"","code":"create_dot_plot(     dataset = df_plot,     category_var = \"insurance\",     value_var = \"median_days\",     lower_bound_var = \"q1\",     upper_bound_var = \"q3\",     dpi = 100,     output_directory = \"output/plots\",     filename_prefix = \"insurance_vs_days\",     x_label = \"Insurance\",     y_label = \"Median Business Days\",     plot_title = \"Comparison of Business Days by Insurance\" ) #> Error: 'is.data.frame' is not an exported object from 'namespace:assertthat'"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/create_forest_plot.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a Forest Plot for Significant Predictors with Logging — create_forest_plot","title":"Create a Forest Plot for Significant Predictors with Logging — create_forest_plot","text":"function generates forest plot displaying significant predictors' coefficients confidence intervals Poisson regression model. logs step process, providing insights predictors included, coefficients, confidence intervals. forest plot highlights direction significance effects analyzed variables.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/create_forest_plot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a Forest Plot for Significant Predictors with Logging — create_forest_plot","text":"","code":"create_forest_plot(df, target_variable, significant_vars)"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/create_forest_plot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a Forest Plot for Significant Predictors with Logging — create_forest_plot","text":"df data frame containing dataset used regression analysis. target_variable string representing target variable (dependent variable) regression model. significant_vars data frame containing significant predictors variable names (Variable), coefficients (Coefficient), confidence intervals (Lower_CI, Upper_CI).","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/create_forest_plot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a Forest Plot for Significant Predictors with Logging — create_forest_plot","text":"ggplot object representing forest plot coefficients confidence intervals significant predictor.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/create_forest_plot.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create a Forest Plot for Significant Predictors with Logging — create_forest_plot","text":"function loops significant predictors fit individual Poisson regression models predictor target variable. extracts coefficients confidence intervals, compiles results, visualizes forest plot. vertical dashed red line x = 0 indicates effect.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/create_forest_plot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a Forest Plot for Significant Predictors with Logging — create_forest_plot","text":"","code":"# Example: Creating a forest plot for significant predictors forest_plot <- create_forest_plot(   df = data,   target_variable = \"accepts_medicaid\",   significant_vars = significant_predictors ) #> Error: 'is.data.frame' is not an exported object from 'namespace:assertthat' print(forest_plot) #> Error: object 'forest_plot' not found"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/create_formula.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a Dynamic Formula for Mixed Effects Models — create_formula","title":"Create a Dynamic Formula for Mixed Effects Models — create_formula","text":"Dynamically generates formula mixed-effects models excluding specified columns quoting variables special characters. Handles fixed-effects mixed-effects models making grouping variable optional. function creates formula Poisson model based provided data, response variable, optional random effect.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/create_formula.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a Dynamic Formula for Mixed Effects Models — create_formula","text":"","code":"create_formula(data, response_var, random_effect = NULL)  create_formula(data, response_var, random_effect = NULL)"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/create_formula.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a Dynamic Formula for Mixed Effects Models — create_formula","text":"data dataframe containing predictor response variables. response_var name response variable dataframe. random_effect Optional. name random effect variable formula. dataset dataframe containing variables formula. outcome_var character string specifying outcome variable. Defaults \"business_days_until_appointment\". group_var character string specifying grouping variable. NULL, creates fixed-effects formula. Defaults NULL. exclude_columns character vector column names exclude formula. Defaults pre-defined list.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/create_formula.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a Dynamic Formula for Mixed Effects Models — create_formula","text":"formula object representing specified model. formula object suitable modeling R.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/create_formula.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a Dynamic Formula for Mixed Effects Models — create_formula","text":"","code":"# Example 1: Default behavior with pre-defined exclude_columns dataset <- data.frame(   business_days_until_appointment = rpois(100, lambda = 5),   NPI = sample(letters, 100, replace = TRUE),   age = rnorm(100, mean = 50, sd = 10),   gender = sample(c(\"Male\", \"Female\"), 100, replace = TRUE) ) create_formula(dataset) #> Error in create_formula(dataset): argument \"response_var\" is missing, with no default  # Example 2: Custom outcome and grouping variables dataset <- data.frame(   wait_time = rpois(100, lambda = 7),   provider_id = sample(letters, 100, replace = TRUE),   income = rnorm(100, mean = 60000, sd = 15000),   region = sample(c(\"Urban\", \"Rural\"), 100, replace = TRUE) ) create_formula(dataset, outcome_var = \"wait_time\", group_var = \"provider_id\") #> Error in create_formula(dataset, outcome_var = \"wait_time\", group_var = \"provider_id\"): unused arguments (outcome_var = \"wait_time\", group_var = \"provider_id\")  # Example 3: Specifying additional columns to exclude dataset <- data.frame(   business_days_until_appointment = rpois(100, lambda = 3),   NPI = sample(letters, 100, replace = TRUE),   specialty = sample(c(\"Cardiology\", \"Dermatology\"), 100, replace = TRUE),   phone_number = sample(1000000000:1999999999, 100) ) create_formula(dataset, exclude_columns = c(\"phone_number\", \"specialty\")) #> Error in create_formula(dataset, exclude_columns = c(\"phone_number\", \"specialty\")): unused argument (exclude_columns = c(\"phone_number\", \"specialty\")) # Example usage: response_variable <- \"days\" random_effect_term <- \"name\"  # Change this to the desired random effect variable df3_filtered <- data.frame(days = c(5, 10, 15), age = c(30, 40, 50), name = c(\"A\", \"B\", \"C\")) formula <- create_formula(df3_filtered, response_variable, random_effect_term) #> Creating formula with response variable: days  #> Predictor variables identified: age, name  #> Predictor variables after formatting: `age`, `name`  #> Initial formula string: days ~ `age` + `name`  #> Formula string with random effect: days ~ `age` + `name` + (1 | name )  #> Final formula object created: #> days ~ age + name + (1 | name) #> <environment: 0x5646e32402b8> formula #> days ~ age + name + (1 | name) #> <environment: 0x5646e32402b8>"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/create_insurance_by_insurance_scatter_plot.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a Scatter Plot Comparing Waiting Times Between Two Insurance Types — create_insurance_by_insurance_scatter_plot","title":"Create a Scatter Plot Comparing Waiting Times Between Two Insurance Types — create_insurance_by_insurance_scatter_plot","text":"function creates scatter plot comparing waiting times (days) appointment two different insurance types. plot saved TIFF PNG file specified output directory. function allows customization plot aesthetics, including axis labels, point size, alpha transparency. includes options adding linear fit confidence intervals logs process console.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/create_insurance_by_insurance_scatter_plot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a Scatter Plot Comparing Waiting Times Between Two Insurance Types — create_insurance_by_insurance_scatter_plot","text":"","code":"create_insurance_by_insurance_scatter_plot(   df,   unique_variable,   insurance1 = \"medicaid\",   insurance2 = \"blue cross/blue shield\",   output_directory = \"output\",   dpi = 100,   height = 8,   width = 11,   x_label = \"Time in days to appointment\\nBlue Cross Blue Shield (Log Scale)\",   y_label = \"Time in days to appointment\\nMedicaid (Log Scale)\",   plot_title = \"Comparison of Waiting Times: Medicaid vs Blue Cross Blue Shield\",   point_size = 3,   point_alpha = 0.6,   add_confidence_interval = TRUE )"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/create_insurance_by_insurance_scatter_plot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a Scatter Plot Comparing Waiting Times Between Two Insurance Types — create_insurance_by_insurance_scatter_plot","text":"df data frame containing data plotted. Must include insurance, business_days_until_appointment, variable specified unique_variable. unique_variable string representing column name uniquely identifies entity data (e.g., \"phone\" \"npi\"). insurance1 string representing first insurance type compared. Default \"medicaid\". insurance2 string representing second insurance type compared. Default \"blue cross/blue shield\". output_directory string specifying directory plot files saved. Default \"output\". dpi integer specifying resolution saved plot files dots per inch (DPI). Default 100. height numeric value specifying height saved plot files inches. Default 8 inches. width numeric value specifying width saved plot files inches. Default 11 inches. x_label string representing label x-axis. Default \"Time days appointment Cross Blue Shield (Log Scale)\". y_label string representing label y-axis. Default \"Time days appointment (Log Scale)\". plot_title string representing title plot. Default \"Comparison Waiting Times: Medicaid vs Blue Cross Blue Shield\". point_size numeric value specifying size points scatter plot. Default 3. point_alpha numeric value 0 1 specifying transparency level points scatter plot. Default 0.6. add_confidence_interval logical value indicating whether add confidence interval around linear fit line. Default TRUE.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/create_insurance_by_insurance_scatter_plot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a Scatter Plot Comparing Waiting Times Between Two Insurance Types — create_insurance_by_insurance_scatter_plot","text":"ggplot2 scatter plot object.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/create_insurance_by_insurance_scatter_plot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a Scatter Plot Comparing Waiting Times Between Two Insurance Types — create_insurance_by_insurance_scatter_plot","text":"","code":"# Example 1: Default settings scatterplot <- create_insurance_by_insurance_scatter_plot(   df = df3,  # Input data frame   unique_variable = \"phone\"  # Unique identifier variable ) #> Error: object 'df3' not found print(scatterplot) #> Error: object 'scatterplot' not found  # Example 2: Customized axis labels and output directory scatterplot <- create_insurance_by_insurance_scatter_plot(   df = df3,  # Input data frame   unique_variable = \"npi\",  # Unique identifier variable   insurance1 = \"medicaid\",  # First insurance type   insurance2 = \"blue cross/blue shield\",  # Second insurance type   x_label = \"Log Time to Appointment (BCBS)\",  # Custom x-axis label   y_label = \"Log Time to Appointment (Medicaid)\",  # Custom y-axis label   plot_title = \"Custom Waiting Times Comparison\",  # Custom plot title   output_directory = \"custom_figures\"  # Custom output directory ) #> Error: object 'df3' not found print(scatterplot) #> Error: object 'scatterplot' not found  # Example 3: High-resolution plot with adjusted aesthetics scatterplot <- create_insurance_by_insurance_scatter_plot(   df = df3,  # Input data frame   unique_variable = \"phone\",  # Unique identifier variable   dpi = 300,  # High resolution   point_size = 4,  # Larger point size   point_alpha = 0.8,  # Less transparency   height = 10,  # Custom height   width = 15  # Custom width ) #> Error: object 'df3' not found print(scatterplot) #> Error: object 'scatterplot' not found"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/create_line_plot.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a Line Plot with Optional Transformations and Grouping — create_line_plot","title":"Create a Line Plot with Optional Transformations and Grouping — create_line_plot","text":"function creates line plot using ggplot2 options transforming y-axis, grouping lines, saving plot specified resolution. plot can saved TIFF PNG formats automatic filename generation.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/create_line_plot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a Line Plot with Optional Transformations and Grouping — create_line_plot","text":"","code":"create_line_plot(   data,   x_var,   y_var,   y_transform = \"none\",   dpi = 100,   output_dir = \"output\",   file_prefix = \"line_plot\",   use_geom_line = FALSE,   geom_line_group = NULL,   point_color = \"viridis\",   line_color = \"red\",   verbose = TRUE )"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/create_line_plot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a Line Plot with Optional Transformations and Grouping — create_line_plot","text":"data dataframe containing data plotted. Must include variables specified x_var y_var. x_var string representing column name x-axis variable. categorical factor variable. y_var string representing column name y-axis variable. numeric variable. y_transform string specifying transformation y-axis: \"log\" log transformation (log1p), \"sqrt\" square root transformation, \"none\" transformation. Default \"none\". dpi integer specifying resolution saved plot dots per inch (DPI). Default 100. output_dir string representing directory plot files saved. Default \"output\". file_prefix string used prefix generated plot filenames. filenames timestamp appended ensure uniqueness. Default \"line_plot\". use_geom_line boolean indicating whether include lines connecting points grouped data. Default FALSE. geom_line_group string representing column name group lines use_geom_line TRUE. categorical factor variable. point_color string specifying color points. Default \"viridis\", uses viridis color palette. line_color string specifying color summary line (median). Default \"red\". verbose boolean indicating whether print messages saved plot locations. Default TRUE.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/create_line_plot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a Line Plot with Optional Transformations and Grouping — create_line_plot","text":"function saves plot specified directory returns ggplot object.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/create_line_plot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a Line Plot with Optional Transformations and Grouping — create_line_plot","text":"","code":"# Example 1: Basic line plot with no transformations create_line_plot(   data = iris,   x_var = \"Species\",   y_var = \"Sepal.Length\",   y_transform = \"none\",   dpi = 100,   output_dir = \"output\",   file_prefix = \"iris_sepal_length\" ) #> Created output directory: output #> Plots saved to: output/iris_sepal_length_20250103_035339.tiff and output/iris_sepal_length_20250103_035339.png   # Example 2: Line plot with log transformation and grouped lines create_line_plot(   data = mtcars,   x_var = \"cyl\",   y_var = \"mpg\",   y_transform = \"log\",   dpi = 150,   output_dir = \"plots\",   file_prefix = \"mtcars_log_mpg\",   use_geom_line = TRUE,   geom_line_group = \"gear\" ) #> Created output directory: plots #> Plots saved to: plots/mtcars_log_mpg_20250103_035340.tiff and plots/mtcars_log_mpg_20250103_035340.png   # Example 3: Line plot with square root transformation and customized aesthetics create_line_plot(   data = mtcars,   x_var = \"gear\",   y_var = \"hp\",   y_transform = \"sqrt\",   dpi = 300,   output_dir = \"custom_plots\",   file_prefix = \"mtcars_sqrt_hp\",   point_color = \"blue\",   line_color = \"green\",   verbose = TRUE ) #> Created output directory: custom_plots #> Plots saved to: custom_plots/mtcars_sqrt_hp_20250103_035340.tiff and custom_plots/mtcars_sqrt_hp_20250103_035340.png"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/create_region_map.html","id":null,"dir":"Reference","previous_headings":"","what":"Main function to create a map of U.S. States by Region, Division, or Custom Districts — create_region_map","title":"Main function to create a map of U.S. States by Region, Division, or Custom Districts — create_region_map","text":"function generates map U.S. states, coloring regions, divisions, ACOG districts, ENT Board Governors Regions. Users can customize grouping use (ACOG Districts, ENT_Board_of_Governors_Regions, US Census Subdivisions).","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/create_region_map.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Main function to create a map of U.S. States by Region, Division, or Custom Districts — create_region_map","text":"","code":"create_region_map(   remove_ak_hi = TRUE,   districts_per_group = \"acog_districts\",   save_path = NULL,   alpha_level = 0.4,   title = \"U.S. States by Region/Division or Custom Districts\",   subtitle = NULL )"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/create_region_map.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Main function to create a map of U.S. States by Region, Division, or Custom Districts — create_region_map","text":"remove_ak_hi Logical, whether exclude Alaska Hawaii map. Default TRUE. districts_per_group Character, grouping use regions. Options : \"acog_districts\", \"ENT_Board_of_Governors_Regions\", \"US_Census_Subdivisions\". save_path Character, optional file path save map image. NULL, map saved. Default NULL. alpha_level Numeric, transparency level map's fill color, 0 fully transparent 1 fully opaque. Default 0.2. title Character, title map. Default \"U.S. States Region/Division Custom Districts\". subtitle Character, optional subtitle map.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/create_region_map.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Main function to create a map of U.S. States by Region, Division, or Custom Districts — create_region_map","text":"ggplot map object representing U.S. states colored region/division, ACOG districts, ENT_Board_of_Governors_Regions.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/create_region_map.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Main function to create a map of U.S. States by Region, Division, or Custom Districts — create_region_map","text":"","code":"# Example 1: Create a map of U.S. states by region/division, # Excluding Alaska data(us_census_bureau_regions_df) regions_map <- us_census_bureau_regions_df %>%   dplyr::filter(State != \"Alaska\") %>%   ggplot2::ggplot(ggplot2::aes(fill = Region)) +   ggplot2::geom_map(map = us_map, ggplot2::aes(map_id = State.Code)) +   ggplot2::labs(title = \"Map of U.S. Regions (Excluding Alaska)\") #> Error: object 'us_map' not found print(regions_map) #> Error: object 'regions_map' not found"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/create_scatter_plot.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a Scatter Plot for Mystery Caller Studies with Optional Transformations, Jitter, and Custom Labels — create_scatter_plot","title":"Create a Scatter Plot for Mystery Caller Studies with Optional Transformations, Jitter, and Custom Labels — create_scatter_plot","text":"function generates scatter plot designed mystery caller studies, allowing visualization waiting times similar outcomes across different categories, insurance types. function supports transformations y-axis, custom jitter, colors category x-axis using viridis color palette. plot automatically displayed saved specified resolution.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/create_scatter_plot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a Scatter Plot for Mystery Caller Studies with Optional Transformations, Jitter, and Custom Labels — create_scatter_plot","text":"","code":"create_scatter_plot(   data,   x_var,   y_var,   y_transform = \"none\",   dpi = 100,   output_dir = \"output\",   file_prefix = \"scatter_plot\",   jitter_width = 0.2,   jitter_height = 0,   point_alpha = 0.6,   x_label = NULL,   y_label = NULL,   plot_title = NULL,   verbose = TRUE )"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/create_scatter_plot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a Scatter Plot for Mystery Caller Studies with Optional Transformations, Jitter, and Custom Labels — create_scatter_plot","text":"data dataframe containing data plotted. Must contain variables specified x_var y_var. x_var string representing column name x-axis variable. categorical factor variable (e.g., insurance type). y_var string representing column name y-axis variable. numeric variable (e.g., waiting time days). y_transform string specifying transformation y-axis: \"log\" log transformation (log1p), \"sqrt\" square root transformation, \"none\" transformation. Default \"none\". dpi integer specifying resolution saved plot dots per inch (DPI). Default 100. output_dir string representing directory plot files saved. Default \"output\". file_prefix string used prefix generated plot filenames. filenames timestamp appended ensure uniqueness. Default \"scatter_plot\". jitter_width numeric value specifying width jitter along x-axis. Default 0.2. jitter_height numeric value specifying height jitter along y-axis. Default 0. point_alpha numeric value specifying transparency level points. Default 0.6. x_label string specifying label x-axis. Default NULL (uses x_var). y_label string specifying label y-axis. Default NULL (uses y_var transformed version). plot_title string specifying title plot. Default NULL (title). verbose boolean indicating whether print messages saved plot locations. Default TRUE.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/create_scatter_plot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a Scatter Plot for Mystery Caller Studies with Optional Transformations, Jitter, and Custom Labels — create_scatter_plot","text":"function displays plot saves specified directory.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/create_scatter_plot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a Scatter Plot for Mystery Caller Studies with Optional Transformations, Jitter, and Custom Labels — create_scatter_plot","text":"","code":"# Example 1: Basic scatter plot with log transformation create_scatter_plot(     data = df3,     x_var = \"insurance\",     y_var = \"business_days_until_appointment\",     y_transform = \"log\",  # Log transformation     dpi = 100,     output_dir = \"ortho_sports_med/Figures\",     file_prefix = \"ortho_sports_vs_insurance\",     x_label = \"Insurance\",     y_label = \"Log (Waiting Times in Days)\",     plot_title = \"Scatter Plot of Waiting Times by Insurance\" ) #> Error: object 'df3' not found  # Example 2: Scatter plot with square root transformation and custom jitter create_scatter_plot(     data = df3,     x_var = \"insurance\",     y_var = \"business_days_until_appointment\",     y_transform = \"sqrt\",  # Square root transformation     dpi = 150,     output_dir = \"ortho_sports_med/Figures\",     file_prefix = \"ortho_sports_vs_insurance_sqrt\",     jitter_width = 0.3,     jitter_height = 0.1,     x_label = \"Insurance\",     y_label = \"Square Root (Waiting Times in Days)\",     plot_title = \"Square Root Transformed Scatter Plot\" ) #> Error: object 'df3' not found  # Example 3: Scatter plot without any transformation and increased transparency create_scatter_plot(     data = df3,     x_var = \"insurance\",     y_var = \"business_days_until_appointment\",     y_transform = \"none\",  # No transformation     dpi = 200,     output_dir = \"ortho_sports_med/Figures\",     file_prefix = \"ortho_sports_vs_insurance_none\",     point_alpha = 0.8,     x_label = \"Insurance\",     y_label = \"Waiting Times in Days\",     plot_title = \"Scatter Plot Without Transformation\" ) #> Error: object 'df3' not found"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/determine_direction.html","id":null,"dir":"Reference","previous_headings":"","what":"Determine the Direction of Effects for Significant Variables with Logging and Error Handling — determine_direction","title":"Determine the Direction of Effects for Significant Variables with Logging and Error Handling — determine_direction","text":"function determines whether effect significant predictor positive (\"Higher\") negative (\"Lower\"). logs process, including inputs, outputs, step analysis.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/determine_direction.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Determine the Direction of Effects for Significant Variables with Logging and Error Handling — determine_direction","text":"","code":"determine_direction(data, target_var, significant_vars)"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/determine_direction.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Determine the Direction of Effects for Significant Variables with Logging and Error Handling — determine_direction","text":"data data frame containing dataset. target_var string representing name target variable (e.g., outcome dependent variable). significant_vars data frame containing significant predictors column \"Variable\" p-values.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/determine_direction.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Determine the Direction of Effects for Significant Variables with Logging and Error Handling — determine_direction","text":"data frame additional column \"Direction\" indicating whether significant predictor associated \"Higher\" \"Lower\" effect.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/determine_direction.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Determine the Direction of Effects for Significant Variables with Logging and Error Handling — determine_direction","text":"","code":"# Example 1: Determine the direction of effects with a basic dataset df <- data.frame(   age = rnorm(100, mean = 50, sd = 10),   gender = factor(sample(c(\"Male\", \"Female\"), 100, replace = TRUE)),   accepts_medicaid = rbinom(100, 1, 0.5) ) significant_vars <- data.frame(Variable = c(\"age\", \"gender\")) determine_direction(df, \"accepts_medicaid\", significant_vars) #> Starting the determine_direction function... #> Target Variable: accepts_medicaid  #> Significant Variables Data Frame: #>   Variable #> 1      age #> 2   gender #> Step 1: Processing significant variables and fitting Poisson models... #> Processing variable: age  #> Direction for variable age : Lower (Coefficient = -0.002751343 ) #> Processing variable: gender  #> Direction for variable gender : Higher (Coefficient = 0.02710193 ) #> Step 2: Adding the direction column to the significant_vars data frame... #> Final significant variables with directions: #>   Variable Direction #> 1      age     Lower #> 2   gender    Higher #> determine_direction function completed successfully. Returning the result... #>   Variable Direction #> 1      age     Lower #> 2   gender    Higher  # Example 2: A dataset with multiple continuous predictors df2 <- data.frame(   income = rnorm(100, mean = 60000, sd = 15000),   education_years = rnorm(100, mean = 16, sd = 2),   accepts_insurance = rbinom(100, 1, 0.6) ) significant_vars2 <- data.frame(Variable = c(\"income\", \"education_years\")) determine_direction(df2, \"accepts_insurance\", significant_vars2) #> Starting the determine_direction function... #> Target Variable: accepts_insurance  #> Significant Variables Data Frame: #>          Variable #> 1          income #> 2 education_years #> Step 1: Processing significant variables and fitting Poisson models... #> Processing variable: income  #> Direction for variable income : Lower (Coefficient = -8.614225e-06 ) #> Processing variable: education_years  #> Direction for variable education_years : Lower (Coefficient = -0.0514654 ) #> Step 2: Adding the direction column to the significant_vars data frame... #> Final significant variables with directions: #>          Variable Direction #> 1          income     Lower #> 2 education_years     Lower #> determine_direction function completed successfully. Returning the result... #>          Variable Direction #> 1          income     Lower #> 2 education_years     Lower  # Example 3: Handling a dataset with categorical and continuous predictors df3 <- data.frame(   years_experience = rnorm(100, mean = 10, sd = 5),   specialty = factor(sample(c(\"Cardiology\", \"Neurology\"), 100, replace = TRUE)),   accepts_medicare = rbinom(100, 1, 0.7) ) significant_vars3 <- data.frame(Variable = c(\"years_experience\", \"specialty\")) determine_direction(df3, \"accepts_medicare\", significant_vars3) #> Starting the determine_direction function... #> Target Variable: accepts_medicare  #> Significant Variables Data Frame: #>           Variable #> 1 years_experience #> 2        specialty #> Step 1: Processing significant variables and fitting Poisson models... #> Processing variable: years_experience  #> Direction for variable years_experience : Higher (Coefficient = 0.005577632 ) #> Processing variable: specialty  #> Direction for variable specialty : Higher (Coefficient = 0.02993891 ) #> Step 2: Adding the direction column to the significant_vars data frame... #> Final significant variables with directions: #>           Variable Direction #> 1 years_experience    Higher #> 2        specialty    Higher #> determine_direction function completed successfully. Returning the result... #>           Variable Direction #> 1 years_experience    Higher #> 2        specialty    Higher"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/fit_poisson_models.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit Poisson Models for Analyzing Wait Times — fit_poisson_models","title":"Fit Poisson Models for Analyzing Wait Times — fit_poisson_models","text":"function fits Poisson regression models analyze effect predictors target variable, wait times appointments. returns summary predictors significance levels (p-values).","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/fit_poisson_models.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit Poisson Models for Analyzing Wait Times — fit_poisson_models","text":"","code":"fit_poisson_models(data, target_var, predictors)"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/fit_poisson_models.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit Poisson Models for Analyzing Wait Times — fit_poisson_models","text":"data dataframe containing variables analysis. target_var string specifying name target variable (e.g., \"wait_time\"). predictors character vector predictor variable names include models.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/fit_poisson_models.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit Poisson Models for Analyzing Wait Times — fit_poisson_models","text":"tibble containing predictors, p-values, formatted p-values.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/fit_poisson_models.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fit Poisson Models for Analyzing Wait Times — fit_poisson_models","text":"","code":"# Example: Fitting Poisson models with wait time data wait_data <- data.frame(   wait_time = rpois(100, lambda = 5),   insurance_type = sample(c(\"Medicaid\", \"Private\"), 100, replace = TRUE),   physician_id = sample(1:10, 100, replace = TRUE),   caller_scenario = sample(c(\"Vaginitis\", \"UTI\", \"Pregnancy Test\"), 100, replace = TRUE) )  fit_results <- fit_poisson_models(   data = wait_data,   target_var = \"wait_time\",   predictors = c(\"insurance_type\", \"caller_scenario\") ) #> INFO [2025-01-03 03:53:42] Fitting Poisson models for target variable 'wait_time' #> INFO [2025-01-03 03:53:42] Predictors: insurance_type, caller_scenario #> INFO [2025-01-03 03:53:42] Processing predictor: insurance_type #> INFO [2025-01-03 03:53:42] Model formula: wait_time ~ insurance_type #> INFO [2025-01-03 03:53:42] P-Value for 'insurance_type': 0.582675699802975 #> INFO [2025-01-03 03:53:42] Processing predictor: caller_scenario #> INFO [2025-01-03 03:53:42] Model formula: wait_time ~ caller_scenario #> INFO [2025-01-03 03:53:42] P-Value for 'caller_scenario': 0.813297814518396 #> INFO [2025-01-03 03:53:42] Finished fitting Poisson models. Returning results.  print(fit_results) #> # A tibble: 2 × 3 #>   Predictor       P_Value Formatted_P_Value #>   <chr>             <dbl> <chr>             #> 1 insurance_type    0.583 0.58              #> 2 caller_scenario   0.813 0.81"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/format_pct.html","id":null,"dir":"Reference","previous_headings":"","what":"Format a Numeric Value as a Percentage — format_pct","title":"Format a Numeric Value as a Percentage — format_pct","text":"function formats numeric value vector percentage specified number decimal places.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/format_pct.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Format a Numeric Value as a Percentage — format_pct","text":"","code":"format_pct(x, my_digits = 1)"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/format_pct.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Format a Numeric Value as a Percentage — format_pct","text":"x numeric value vector format percentage. my_digits integer specifying number decimal places include formatted percentage. default 1.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/format_pct.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Format a Numeric Value as a Percentage — format_pct","text":"character vector representing formatted percentage(s) specified number decimal places.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/format_pct.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Format a Numeric Value as a Percentage — format_pct","text":"function converts numeric values percentage format desired number decimal places. especially useful ensuring consistent formatting reports, tables, visualizations.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/format_pct.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Format a Numeric Value as a Percentage — format_pct","text":"","code":"# Example 1: Format a single numeric value with default decimal places single_value <- format_pct(0.12345) print(single_value)  # Output: \"12.3%\" #> [1] \"12.3%\"  # Example 2: Format a vector of numeric values with 2 decimal places values <- c(0.12345, 0.6789, 0.54321) formatted_values <- format_pct(values, my_digits = 2) print(formatted_values)  # Output: \"12.35%\", \"67.89%\", \"54.32%\" #> [1] \"12.35%\" \"67.89%\" \"54.32%\"  # Example 3: Format a single value with no decimal places no_decimal <- format_pct(0.5, my_digits = 0) print(no_decimal)  # Output: \"50%\" #> [1] \"50%\"  # Example 4: Format a vector of proportions with varying decimal places proportions <- c(0.1, 0.25, 0.33333, 0.9) formatted_proportions <- format_pct(proportions, my_digits = 3) print(formatted_proportions)  # Output: \"10.000%\", \"25.000%\", \"33.333%\", \"90.000%\" #> [1] \"10.000%\" \"25.000%\" \"33.333%\" \"90.000%\""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/generate_interaction_sentences.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate Interaction Sentences for Model Interpretation — generate_interaction_sentences","title":"Generate Interaction Sentences for Model Interpretation — generate_interaction_sentences","text":"function generates interpretative sentences interaction terms regression model (Poisson logistic), detailing combinations predictors impact outcomes wait times.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/generate_interaction_sentences.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate Interaction Sentences for Model Interpretation — generate_interaction_sentences","text":"","code":"generate_interaction_sentences(   interaction_model,   variable1,   variable2,   model_summary = NULL,   confidence_level = 0.95,   log_transform = TRUE,   output_format = \"text\" )"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/generate_interaction_sentences.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate Interaction Sentences for Model Interpretation — generate_interaction_sentences","text":"interaction_model fitted regression model object (e.g., glm lmer). variable1 first variable interaction (character string). variable2 second variable interaction (character string). model_summary optional model summary object. provided, calculated interaction_model. confidence_level confidence level reporting intervals. Default 0.95. log_transform Logical. TRUE, log-transformed estimates used. Default TRUE. output_format format output sentences. Options \"text\" (default) \"markdown\".","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/generate_interaction_sentences.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate Interaction Sentences for Model Interpretation — generate_interaction_sentences","text":"list strings, interpreting interaction term model.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/generate_interaction_sentences.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Generate Interaction Sentences for Model Interpretation — generate_interaction_sentences","text":"function uses estimated marginal means compute interpret interaction effects. Sentences include confidence intervals p-values available.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/generate_interaction_sentences.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate Interaction Sentences for Model Interpretation — generate_interaction_sentences","text":"","code":"# Example: Generate interaction sentences for a Poisson model interaction_model <- glm(wait_time ~ insurance_type * scenario,                          data = poisson_data, family = poisson) #> Error in eval(mf, parent.frame()): object 'poisson_data' not found  interaction_sentences <- generate_interaction_sentences(   interaction_model = interaction_model,   variable1 = \"insurance_type\",   variable2 = \"scenario\",   output_format = \"text\" ) #> INFO [2025-01-03 03:53:42] Starting generate_interaction_sentences... #> INFO [2025-01-03 03:53:42] Variables: insurance_type, scenario #> INFO [2025-01-03 03:53:42] Confidence level: 0.95, Log transform: TRUE #> INFO [2025-01-03 03:53:42] Output format: text #> Error: object 'interaction_model' not found print(interaction_sentences) #> Error: object 'interaction_sentences' not found"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/generate_latex_equation.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate LaTeX Equation with Logging — generate_latex_equation","title":"Generate LaTeX Equation with Logging — generate_latex_equation","text":"function generates LaTeX equation incorporates provided \"patient_scenario_label\". function logs input, processes input string escaping LaTeX characters, constructs LaTeX equation. logs operations can output console log file (provided).","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/generate_latex_equation.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate LaTeX Equation with Logging — generate_latex_equation","text":"","code":"generate_latex_equation(   patient_scenario_label = \"Default Patient Scenario\",   log_file = NULL )"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/generate_latex_equation.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate LaTeX Equation with Logging — generate_latex_equation","text":"patient_scenario_label string representing text (typically \"Patient Scenario\") inserted LaTeX equation. Default \"Default Patient Scenario\". log_file string representing full path file logs written. NULL (default), logs printed console.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/generate_latex_equation.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate LaTeX Equation with Logging — generate_latex_equation","text":"LaTeX code string, ready inserted RMarkdown LaTeX document.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/generate_latex_equation.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Generate LaTeX Equation with Logging — generate_latex_equation","text":"function generates dynamic LaTeX code using provided patient_scenario_label, ensuring special LaTeX characters (underscores) escaped properly. logs entire process, including input validation, transformations, final output. patient_scenario_label provided, default value used.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/generate_latex_equation.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate LaTeX Equation with Logging — generate_latex_equation","text":"","code":"# Example 1: Basic usage with logging to the console if (FALSE) { # \\dontrun{ generate_latex_equation(\"Patient Scenario\") } # }  # Example 2: Handle underscores in the patient_scenario_label if (FALSE) { # \\dontrun{ generate_latex_equation(\"Patient_Scenario_With_Underscores\") } # }  # Example 3: Logging the process to a file if (FALSE) { # \\dontrun{ log_file_path <- \"latex_generation_log.txt\" generate_latex_equation(\"Patient Scenario\", log_file = log_file_path) } # }"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/get_census_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Retrieve Census Data for State Block Groups — get_census_data","title":"Retrieve Census Data for State Block Groups — get_census_data","text":"function retrieves Census data state block groups looping specified list state FIPS codes. data fetched using Census API specified vintage year aggregated single dataframe.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/get_census_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Retrieve Census Data for State Block Groups — get_census_data","text":"","code":"get_census_data(state_fips_codes, vintage_year = 2022)"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/get_census_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Retrieve Census Data for State Block Groups — get_census_data","text":"state_fips_codes character vector state FIPS codes Census data retrieved. FIPS codes must two-character strings representing U.S. states (e.g., \"01\" Alabama). vintage_year integer specifying vintage year Census data. Default 2022.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/get_census_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Retrieve Census Data for State Block Groups — get_census_data","text":"dataframe containing Census data specified state block groups, including metadata.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/get_census_data.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Retrieve Census Data for State Block Groups — get_census_data","text":"function uses censusapi package query Census data via American Community Survey (ACS) API. Data retrieved block groups across specified states aggregated single dataframe. Users must provide valid Census API key via key argument environment variables.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/get_census_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Retrieve Census Data for State Block Groups — get_census_data","text":"","code":"# Example 1: Retrieve Census data for two states with the default vintage year if (FALSE) { # \\dontrun{ state_fips_codes <- c(\"01\", \"02\") # Alabama and Alaska census_data <- get_census_data(state_fips_codes) head(census_data) } # }  # Example 2: Retrieve Census data for multiple states with a different vintage year if (FALSE) { # \\dontrun{ state_fips_codes <- c(\"04\", \"05\", \"06\") # Arizona, Arkansas, California census_data <- get_census_data(state_fips_codes, vintage_year = 2021) print(dim(census_data)) # Display dimensions of the retrieved data } # }  # Example 3: Retrieve Census data for a subset of states and save it to a CSV file if (FALSE) { # \\dontrun{ state_fips_codes <- c(\"01\", \"02\", \"04\", \"05\", \"06\", \"08\", \"09\") census_data <- get_census_data(state_fips_codes) write.csv(census_data, file = \"census_data_block_groups.csv\", row.names = FALSE) } # }"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/honeycomb_generate_maps.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate Hexagon Maps by ACOG District with Logging and Error Handling — honeycomb_generate_maps","title":"Generate Hexagon Maps by ACOG District with Logging and Error Handling — honeycomb_generate_maps","text":"function generates hexagon maps ACOG districts, using physician location data. provides extensive logging, error handling, defaults sample data inputs provided.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/honeycomb_generate_maps.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate Hexagon Maps by ACOG District with Logging and Error Handling — honeycomb_generate_maps","text":"","code":"honeycomb_generate_maps(   physician_locations_sf = NULL,   acog_districts_sf = NULL,   trait_map = \"all\",   honeycomb_map = \"all\",   hex_grid_size = c(0.3, 0.3),   target_district = NULL )"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/honeycomb_generate_maps.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate Hexagon Maps by ACOG District with Logging and Error Handling — honeycomb_generate_maps","text":"physician_locations_sf Simple Features (sf) object containing physician data coordinates. NULL, default sample data used. acog_districts_sf Simple Features (sf) object containing grouped ACOG districts. NULL, default ACOG districts used. trait_map string specifying trait map (default \"\"). honeycomb_map string specifying honey map (default \"\"). hex_grid_size numeric vector length 2 specifying grid size hexagon map (default c(0.3, 0.3)). target_district string NULL specify specific district generating map (default NULL, processes districts).","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/honeycomb_generate_maps.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate Hexagon Maps by ACOG District with Logging and Error Handling — honeycomb_generate_maps","text":"list ggplot objects generated maps specified districts. ggplot object hexagon map showing physician distribution.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/hrr.html","id":null,"dir":"Reference","previous_headings":"","what":"Get Hospital Referral Region Shapefile — hrr","title":"Get Hospital Referral Region Shapefile — hrr","text":"function loads hospital referral region shapefile optionally removes Hawaii Alaska.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/hrr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get Hospital Referral Region Shapefile — hrr","text":"","code":"hrr(remove_HI_AK = TRUE)"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/hrr.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get Hospital Referral Region Shapefile — hrr","text":"remove_HI_AK Logical, Hawaii Alaska removed? Default TRUE.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/hrr.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get Hospital Referral Region Shapefile — hrr","text":"sf object containing hospital referral region data.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/hrr_generate_maps.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate Hexagon Maps for Hospital Referral Regions (HRR) — hrr_generate_maps","title":"Generate Hexagon Maps for Hospital Referral Regions (HRR) — hrr_generate_maps","text":"function generates hexagon maps hospital referral regions.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/hrr_generate_maps.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate Hexagon Maps for Hospital Referral Regions (HRR) — hrr_generate_maps","text":"","code":"hrr_generate_maps(physician_sf, trait_map = \"all\", honey_map = \"all\")"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/hrr_generate_maps.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate Hexagon Maps for Hospital Referral Regions (HRR) — hrr_generate_maps","text":"physician_sf sf object containing physician data coordinates. trait_map string specifying trait map (default \"\"). honey_map string specifying honey map (default \"\").","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/hrr_generate_maps.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate Hexagon Maps for Hospital Referral Regions (HRR) — hrr_generate_maps","text":"ggplot object generated map.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/install_missing_packages.html","id":null,"dir":"Reference","previous_headings":"","what":"Install Missing CRAN Packages with Version Reporting — install_missing_packages","title":"Install Missing CRAN Packages with Version Reporting — install_missing_packages","text":"function checks presence specified CRAN packages user's system. package already installed, automatically installs dependencies. packages already installed, function logs version numbers console.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/install_missing_packages.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Install Missing CRAN Packages with Version Reporting — install_missing_packages","text":"","code":"install_missing_packages(cran_pkgs)"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/install_missing_packages.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Install Missing CRAN Packages with Version Reporting — install_missing_packages","text":"cran_pkgs character vector containing names CRAN packages verify install missing. element name package available CRAN.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/install_missing_packages.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Install Missing CRAN Packages with Version Reporting — install_missing_packages","text":"utility function designed ensure necessary CRAN packages installed project. uses installed.packages check existing packages install.packages install missing packages. already-installed packages, function retrieves displays version number installed package metadata. function automatically handles package dependencies installation passing dependencies = TRUE install.packages.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/install_missing_packages.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Install Missing CRAN Packages with Version Reporting — install_missing_packages","text":"function requires active internet connection download install packages CRAN. Ensure R environment write permissions library path.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/install_missing_packages.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Install Missing CRAN Packages with Version Reporting — install_missing_packages","text":"","code":"if (FALSE) { # \\dontrun{ # Example 1: Ensure ggplot2 and dplyr are installed install_missing_packages(c(\"ggplot2\", \"dplyr\"))  # Example 2: Install a set of commonly used packages for data wrangling and visualization install_missing_packages(c(\"tidyr\", \"readr\", \"ggplot2\", \"dplyr\"))  # Example 3: Check for and install machine learning packages install_missing_packages(c(\"caret\", \"randomForest\", \"xgboost\"))  # Example 4: Use this function to ensure all required packages for a project are installed required_packages <- c(\"ggplot2\", \"dplyr\", \"tidyr\", \"readr\", \"caret\", \"randomForest\") install_missing_packages(required_packages) } # }"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/linear_regression_race_drive_time_generate_summary_sentence.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate Summary Sentence for Linear Regression on Race and Drive Time with Raw Proportions — linear_regression_race_drive_time_generate_summary_sentence","title":"Generate Summary Sentence for Linear Regression on Race and Drive Time with Raw Proportions — linear_regression_race_drive_time_generate_summary_sentence","text":"function generates summary sentence using linear regression analyze trend proportion women without access gynecologic oncologist time specified race driving time. includes raw proportions first last years dataset.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/linear_regression_race_drive_time_generate_summary_sentence.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate Summary Sentence for Linear Regression on Race and Drive Time with Raw Proportions — linear_regression_race_drive_time_generate_summary_sentence","text":"","code":"linear_regression_race_drive_time_generate_summary_sentence(   tabulated_data,   driving_time_minutes = 180,   race = \"American Indian/Alaska Native\" )"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/linear_regression_race_drive_time_generate_summary_sentence.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate Summary Sentence for Linear Regression on Race and Drive Time with Raw Proportions — linear_regression_race_drive_time_generate_summary_sentence","text":"tabulated_data data frame containing data analyze. Must include columns Driving Time (minutes), Year, columns race proportions like White_prop, Black_prop, etc. driving_time_minutes numeric value specifying driving time minutes filter data. Default 180. race character string specifying race generate summary sentence. Supported values \"White\", \"Black\", \"American Indian/Alaska Native\", \"Asian\", \"Native Hawaiian Pacific Islander\", \"\" generate sentences supported races. Default \"American Indian/Alaska Native\".","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/linear_regression_race_drive_time_generate_summary_sentence.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate Summary Sentence for Linear Regression on Race and Drive Time with Raw Proportions — linear_regression_race_drive_time_generate_summary_sentence","text":"character string containing summary sentence, list summary sentences race = \"\".","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/linear_regression_race_drive_time_generate_summary_sentence.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate Summary Sentence for Linear Regression on Race and Drive Time with Raw Proportions — linear_regression_race_drive_time_generate_summary_sentence","text":"","code":"# Example usage summary_sentence <- linear_regression_race_drive_time_generate_summary_sentence(   tabulated_data = tabulated_all_years_numeric,   driving_time_minutes = 180,   race = \"White\" ) #> Function linear_regression_race_drive_time_generate_summary_sentence called with inputs: #> Driving Time (minutes): 180 #> Race: White #> Race column used for analysis: White_prop #> Error: object 'tabulated_all_years_numeric' not found print(summary_sentence) #> Error: object 'summary_sentence' not found"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/load_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Load and Process Data from an RDS File with Robust Logging — load_data","title":"Load and Process Data from an RDS File with Robust Logging — load_data","text":"function loads data RDS file, renames 'ID' column 'id_number', logs every step process.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/load_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Load and Process Data from an RDS File with Robust Logging — load_data","text":"","code":"load_data(data_dir, file_name, verbose = TRUE)"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/load_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Load and Process Data from an RDS File with Robust Logging — load_data","text":"data_dir string specifying directory RDS file located. file_name string specifying name RDS file load. verbose boolean indicating whether print detailed logs. Default TRUE.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/load_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Load and Process Data from an RDS File with Robust Logging — load_data","text":"data frame 'ID' column renamed 'id_number'.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/load_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Load and Process Data from an RDS File with Robust Logging — load_data","text":"","code":"# Example: Load data from a specified directory with logging df <- load_data(data_dir = \"data\", file_name = \"Phase_2.rds\", verbose = TRUE) #> Function load_data called with the following inputs: #>   data_dir: data  #>   file_name: Phase_2.rds  #>   Constructed file path: data/Phase_2.rds  #> Error in load_data(data_dir = \"data\", file_name = \"Phase_2.rds\", verbose = TRUE): File not found at path: data/Phase_2.rds"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/logistic_regression.html","id":null,"dir":"Reference","previous_headings":"","what":"Perform Logistic Regression on Multiple Predictors with Logging — logistic_regression","title":"Perform Logistic Regression on Multiple Predictors with Logging — logistic_regression","text":"function performs logistic regression multiple predictor variables specified target variable. logs process, including inputs, data transformations, results. function filters predictors based given significance level.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/logistic_regression.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Perform Logistic Regression on Multiple Predictors with Logging — logistic_regression","text":"","code":"logistic_regression(df, target_variable, predictor_vars, significance_level)"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/logistic_regression.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Perform Logistic Regression on Multiple Predictors with Logging — logistic_regression","text":"df data frame containing target predictor variables. target_variable string representing name target variable. predictor_vars vector strings representing names predictor variables. significance_level numeric value specifying significance level filtering predictors.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/logistic_regression.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Perform Logistic Regression on Multiple Predictors with Logging — logistic_regression","text":"data frame containing significant predictors p-values formatted p-values.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/logistic_regression.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Perform Logistic Regression on Multiple Predictors with Logging — logistic_regression","text":"","code":"# Assuming df is your data frame target_variable <- \"cleaned_does_the_physician_accept_medicaid_numeric\" predictor_vars <- setdiff(   names(df),   c(     target_variable,     \"does_the_physician_accept_medicaid\",     \"cleaned_does_the_physician_accept_medicaid\"   ) ) significance_logistic_regression <- 0.2  significant_vars <- logistic_regression(   df,   target_variable,   predictor_vars,   significance_level = significance_logistic_regression ) #> Starting logistic_regression... #> Target Variable: cleaned_does_the_physician_accept_medicaid_numeric  #> Predictor Variables:   #> Significance Level: 0.2  #> Significant Predictors: #> [1] Variable          P_Value           Formatted_P_Value #> <0 rows> (or 0-length row.names) print(significant_vars) #> [1] Variable          P_Value           Formatted_P_Value #> <0 rows> (or 0-length row.names)"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/map_physicians_by_group.html","id":null,"dir":"Reference","previous_headings":"","what":"Map Physicians by State or Subdivision — map_physicians_by_group","title":"Map Physicians by State or Subdivision — map_physicians_by_group","text":"function generates choropleth map based physician counts saves map PNG file.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/map_physicians_by_group.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Map Physicians by State or Subdivision — map_physicians_by_group","text":"","code":"map_physicians_by_group(   state_counts,   output_file_prefix = \"choropleth_map\",   group_by = \"state\" )"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/map_physicians_by_group.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Map Physicians by State or Subdivision — map_physicians_by_group","text":"state_counts tibble containing counts physicians per state subdivision. output_file_prefix prefix output PNG file choropleth map (default \"choropleth_map\"). group_by string indicating whether counts grouped \"state\" \"subdivision\" (default \"state\").","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/map_physicians_by_group.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Map Physicians by State or Subdivision — map_physicians_by_group","text":"ggplot2 object representing choropleth map.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/map_physicians_by_group.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Map Physicians by State or Subdivision — map_physicians_by_group","text":"","code":"# Example 1: Map physicians by state state_counts <- count_physicians_by_group(taxonomy_and_aaos_data) #> Error: Failed to evaluate glue component {nrow(data)} #> Caused by error: #> ! object 'taxonomy_and_aaos_data' not found map_physicians_by_group(state_counts) #> Error: object 'state_counts' not found  # Example 2: Map physicians by U.S. Census Bureau subdivision subdivision_counts <- count_physicians_by_group(taxonomy_and_aaos_data, group_by = \"subdivision\") #> Error: Failed to evaluate glue component {nrow(data)} #> Caused by error: #> ! object 'taxonomy_and_aaos_data' not found map_physicians_by_group(subdivision_counts, group_by = \"subdivision\") #> Error: object 'subdivision_counts' not found"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/nppes_get_data_for_one_year.html","id":null,"dir":"Reference","previous_headings":"","what":"Process NPPES Data for One Year with Chunked Processing — nppes_get_data_for_one_year","title":"Process NPPES Data for One Year with Chunked Processing — nppes_get_data_for_one_year","text":"function processes single year's NPPES (National Plan Provider Enumeration System) data, filtering specified taxonomy codes saving cleaned data CSV file. data processed chunks handle large datasets efficiently, optional functionality allows saving sample columns Excel file inspection.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/nppes_get_data_for_one_year.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process NPPES Data for One Year with Chunked Processing — nppes_get_data_for_one_year","text":"","code":"nppes_get_data_for_one_year(   npi_file_path,   output_csv_path,   duckdb_file_path =     \"/Volumes/Video Projects Muffly 1/nppes_historical_downloads/my_duckdb.duckdb\",   taxonomy_codes_1 = c(\"207V00000X\", \"207VB0002X\", \"207VC0300X\", \"207VC0200X\",     \"207VX0201X\", \"207VG0400X\", \"207VH0002X\", \"207VM0101X\", \"207VX0000X\", \"207VE0102X\",     \"207VF0040X\"),   taxonomy_codes_2 = c(\"207V00000X\", \"207VB0002X\", \"207VC0300X\", \"207VC0200X\",     \"207VX0201X\", \"207VG0400X\", \"207VH0002X\", \"207VM0101X\", \"207VX0000X\", \"207VE0102X\",     \"207VF0040X\"),   save_column_in_each_nppes_year = FALSE,   excel_file_path = NULL )  nppes_get_data_for_one_year(   npi_file_path,   output_csv_path,   duckdb_file_path =     \"/Volumes/Video Projects Muffly 1/nppes_historical_downloads/my_duckdb.duckdb\",   taxonomy_codes_1 = c(\"207V00000X\", \"207VB0002X\", \"207VC0300X\", \"207VC0200X\",     \"207VX0201X\", \"207VG0400X\", \"207VH0002X\", \"207VM0101X\", \"207VX0000X\", \"207VE0102X\",     \"207VF0040X\"),   taxonomy_codes_2 = c(\"207V00000X\", \"207VB0002X\", \"207VC0300X\", \"207VC0200X\",     \"207VX0201X\", \"207VG0400X\", \"207VH0002X\", \"207VM0101X\", \"207VX0000X\", \"207VE0102X\",     \"207VF0040X\"),   save_column_in_each_nppes_year = FALSE,   excel_file_path = NULL )"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/nppes_get_data_for_one_year.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process NPPES Data for One Year with Chunked Processing — nppes_get_data_for_one_year","text":"npi_file_path character string specifying path raw NPPES data CSV file. output_csv_path character string specifying full file path cleaned data saved. duckdb_file_path character string specifying path DuckDB database file. Default \"/Volumes/Video Projects Muffly 1/nppes_historical_downloads/my_duckdb.duckdb\". taxonomy_codes_1 character vector taxonomy codes used filter rows based Healthcare Provider Taxonomy Code_1. taxonomy_codes_2 character vector taxonomy codes used filter rows based Healthcare Provider Taxonomy Code_2. save_column_in_each_nppes_year logical value indicating whether save sample data Excel file inspection. Default FALSE. excel_file_path character string specifying path save Excel file save_column_in_each_nppes_year TRUE. Default NULL.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/nppes_get_data_for_one_year.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Process NPPES Data for One Year with Chunked Processing — nppes_get_data_for_one_year","text":"data frame containing cleaned NPPES data one year, saved specified file path. dataframe containing cleaned NPPES data one year. data also saved specified CSV file.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/nppes_get_data_for_one_year.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Process NPPES Data for One Year with Chunked Processing — nppes_get_data_for_one_year","text":"function processes large NPPES datasets leveraging DuckDB efficient chunk-wise processing. data filtered based taxonomy codes cleaned appended output CSV file. function optionally saves sample data Excel file inspection.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/nppes_get_data_for_one_year.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Process NPPES Data for One Year with Chunked Processing — nppes_get_data_for_one_year","text":"","code":"# Example 1: Process NPPES data for one year and save to CSV if (FALSE) { # \\dontrun{ nppes_get_data_for_one_year(   npi_file_path = \"nppes_raw_2022.csv\",   output_csv_path = \"nppes_cleaned_2022.csv\" ) } # }  # Example 2: Process NPPES data and filter by taxonomy codes if (FALSE) { # \\dontrun{ nppes_get_data_for_one_year(   npi_file_path = \"nppes_raw_2022.csv\",   output_csv_path = \"nppes_cleaned_filtered_2022.csv\",   taxonomy_codes_1 = c(\"207V00000X\", \"207VG0400X\"),   taxonomy_codes_2 = c(\"207V00000X\", \"207VG0400X\") ) } # }  # Example 3: Save sample data to Excel for inspection if (FALSE) { # \\dontrun{ nppes_get_data_for_one_year(   npi_file_path = \"nppes_raw_2022.csv\",   output_csv_path = \"nppes_cleaned_2022.csv\",   save_column_in_each_nppes_year = TRUE,   excel_file_path = \"nppes_sample_2022.xlsx\" ) } # }"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/phase0_city_state_assign_scenarios.html","id":null,"dir":"Reference","previous_headings":"","what":"Assign Cases to Professionals by City and State — phase0_city_state_assign_scenarios","title":"Assign Cases to Professionals by City and State — phase0_city_state_assign_scenarios","text":"phase0_city_state_assign_scenarios function designed assign cases professionals based specialty location (city state). function particularly useful managing scenarios professionals, physicians healthcare workers, need assigned cases administrative analytical purposes.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/phase0_city_state_assign_scenarios.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Assign Cases to Professionals by City and State — phase0_city_state_assign_scenarios","text":"","code":"phase0_city_state_assign_scenarios(   data,   generalist = \"General Dermatology\",   specialty = \"Pediatric Dermatology\",   case_names = c(\"Case Alpha\", \"Case Beta\", \"Case Gamma\"),   output_csv_path = \"Lizzy/data/city_state_assign_scenarios.csv\",   seed = 1978 )"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/phase0_city_state_assign_scenarios.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Assign Cases to Professionals by City and State — phase0_city_state_assign_scenarios","text":"data data frame containing professional information. Must include least columns city, state_code, specialty_primary. generalist character string specifying specialty name generalists. Default \"Generalist\". specialty character string specifying specialty name specialists. Default \"Specialist\". case_names character vector case names assign. Default c(\"Alpha\", \"Beta\", \"Gamma\"). output_csv_path character string specifying file path save output CSV. Default \"output/city_state_assign_scenarios.csv\". seed optional integer value set random seed reproducibility. Default NULL (seed set).","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/phase0_city_state_assign_scenarios.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Assign Cases to Professionals by City and State — phase0_city_state_assign_scenarios","text":"data frame assigned cases.","code":""},{"path":[]},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/phase0_city_state_assign_scenarios.html","id":"key-features-of-the-function-","dir":"Reference","previous_headings":"","what":"Key Features of the Function:","title":"Assign Cases to Professionals by City and State — phase0_city_state_assign_scenarios","text":"Generalists vs. Specialists: function differentiates generalists specialists, assigning cases accordingly. CSV Output: final output, including case assignments professional, saved CSV file using write_output_csv function.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/phase0_city_state_assign_scenarios.html","id":"use-cases-","dir":"Reference","previous_headings":"","what":"Use Cases:","title":"Assign Cases to Professionals by City and State — phase0_city_state_assign_scenarios","text":"Healthcare Assignment: Assigning different types cases healthcare professionals based specialties cities/states practice. Research Studies: Managing scenarios research studies professionals need randomly assigned cases.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/phase0_city_state_assign_scenarios.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Assign Cases to Professionals by City and State — phase0_city_state_assign_scenarios","text":"","code":"# Example 1: Using default parameters data <- data.frame(   city = c(\"CityA\", \"CityA\", \"CityB\", \"CityB\"),   state_code = c(\"State1\", \"State1\", \"State2\", \"State2\"),   specialty_primary = c(\"Generalist\", \"Specialist\", \"Generalist\", \"Specialist\"),   stringsAsFactors = FALSE ) result <- city_state_assign_scenarios(data) #> Error in city_state_assign_scenarios(data): could not find function \"city_state_assign_scenarios\" print(result) #> Error: object 'result' not found"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/phase0_city_state_check_specialty_generalist_counts.html","id":null,"dir":"Reference","previous_headings":"","what":"Check City-State Combinations for Minimum Generalists and Specialists with Logging and Summary — phase0_city_state_check_specialty_generalist_counts","title":"Check City-State Combinations for Minimum Generalists and Specialists with Logging and Summary — phase0_city_state_check_specialty_generalist_counts","text":"function checks city-state combination required number generalists specialists. logs inputs, transformations, outputs, returns two data frames: one failing city-state-specialty combinations one successful combinations. Optionally, results can saved CSV files.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/phase0_city_state_check_specialty_generalist_counts.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check City-State Combinations for Minimum Generalists and Specialists with Logging and Summary — phase0_city_state_check_specialty_generalist_counts","text":"","code":"phase0_city_state_check_specialty_generalist_counts(   data,   min_generalists,   min_specialists,   generalist_name = \"General Dermatology\",   specialist_name = \"Pediatric Dermatology\",   failing_csv_path = NULL,   successful_csv_path = NULL )"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/phase0_city_state_check_specialty_generalist_counts.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check City-State Combinations for Minimum Generalists and Specialists with Logging and Summary — phase0_city_state_check_specialty_generalist_counts","text":"data data frame containing professional information. Must include least columns city, state_code, specialty_primary. min_generalists integer specifying minimum number generalists required per city-state combination. min_specialists integer specifying minimum number specialists required per city-state combination. generalist_name string specifying specialty name generalists. Default \"General Dermatology\". specialist_name string specifying specialty name specialists. Default \"Pediatric Dermatology\". failing_csv_path optional string specifying file path save failing combinations CSV. Default NULL (file saved). successful_csv_path optional string specifying file path save successful combinations CSV. Default NULL (file saved).","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/phase0_city_state_check_specialty_generalist_counts.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check City-State Combinations for Minimum Generalists and Specialists with Logging and Summary — phase0_city_state_check_specialty_generalist_counts","text":"list containing two data frames: failing_combinations successful_combinations.","code":""},{"path":[]},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/phase0_city_state_check_specialty_generalist_counts.html","id":"key-features-","dir":"Reference","previous_headings":"","what":"Key Features:","title":"Check City-State Combinations for Minimum Generalists and Specialists with Logging and Summary — phase0_city_state_check_specialty_generalist_counts","text":"Generalists vs. Specialists: can specify names generalists specialists, function checks city-state combination required number . Logging: Extensive logging ensures inputs, transformations, results tracked. CSV Output: Optionally, function writes failing successful city-state-specialty combinations separate CSV files. Summary Logging: summary min_generalists, min_specialists, results logged end.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/phase0_city_state_sample_specialists.html","id":null,"dir":"Reference","previous_headings":"","what":"#' Sample Generalists and Specialists by City-State Combination — phase0_city_state_sample_specialists","title":"#' Sample Generalists and Specialists by City-State Combination — phase0_city_state_sample_specialists","text":"function samples specialists generalists given dataset based city-state combinations. allows sampling three types specialists generalists customizable sample sizes . results can saved CSV file returned dataframe. function samples specialists generalists given dataset based city-state combinations. allows sampling three types specialists generalists customizable sample sizes . results can saved CSV file returned dataframe.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/phase0_city_state_sample_specialists.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"#' Sample Generalists and Specialists by City-State Combination — phase0_city_state_sample_specialists","text":"","code":"phase0_city_state_sample_specialists(   data,   generalist = \"General Dermatology\",   specialist1 = \"Pediatric Dermatology\",   general_sample_size = 4,   specialist1_sample_size = 2,   specialist2 = NULL,   specialist2_sample_size = 0,   specialist3 = NULL,   specialist3_sample_size = 0,   same_phone_number = TRUE,   output_csv_path = NULL,   seed = 1978 )  phase0_city_state_sample_specialists(   data,   generalist = \"General Dermatology\",   specialist1 = \"Pediatric Dermatology\",   general_sample_size = 4,   specialist1_sample_size = 2,   specialist2 = NULL,   specialist2_sample_size = 0,   specialist3 = NULL,   specialist3_sample_size = 0,   same_phone_number = TRUE,   output_csv_path = NULL,   seed = 1978 )"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/phase0_city_state_sample_specialists.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"#' Sample Generalists and Specialists by City-State Combination — phase0_city_state_sample_specialists","text":"data dataframe containing specialist information. must columns: city, state_code, specialty_primary, phone_number. generalist character string specifying generalist specialty sample. Default \"General Dermatology\". specialist1 character string specifying first specialist specialty sample. Default \"Pediatric Dermatology\". general_sample_size integer specifying many generalists sample city-state combination. Default 4. specialist1_sample_size integer specifying many first specialists sample city-state combination. Default 1. specialist2 character string specifying second specialist specialty sample. Optional. Default NULL. specialist2_sample_size integer specifying many second specialists sample. Default 0. specialist3 character string specifying third specialist specialty sample. Optional. Default NULL. specialist3_sample_size integer specifying many third specialists sample. Default 0. same_phone_number logical value indicating whether sample generalists specialists phone number (TRUE) different phone numbers (FALSE). Default TRUE. output_csv_path character string specifying path save output CSV. provided, result returned. seed integer setting seed reproducibility. Default 1978.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/phase0_city_state_sample_specialists.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"#' Sample Generalists and Specialists by City-State Combination — phase0_city_state_sample_specialists","text":"dataframe containing sampled generalists specialists city-state combination. dataframe containing sampled generalists specialists city-state combination.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/phase0_city_state_sample_specialists.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"#' Sample Generalists and Specialists by City-State Combination — phase0_city_state_sample_specialists","text":"","code":"# Example 1: Basic usage with default generalist and specialist data <- data.frame(   city = rep(c(\"New York\", \"Los Angeles\"), each = 6),   state_code = rep(c(\"NY\", \"CA\"), each = 6),   specialty_primary = c(     \"General Dermatology\", \"Pediatric Dermatology\", \"General Dermatology\",     \"General Dermatology\", \"Pediatric Dermatology\", \"General Dermatology\",     \"General Dermatology\", \"General Dermatology\", \"Pediatric Dermatology\",     \"General Dermatology\", \"General Dermatology\", \"Pediatric Dermatology\"   ),   phone_number = rep(c(\"123\", \"456\", \"789\"), 4) ) result <- city_state_sample_specialists(data) #> Error in city_state_sample_specialists(data): could not find function \"city_state_sample_specialists\" print(result) #> Error: object 'result' not found  # Example 1: Basic usage with default generalist and specialist data <- data.frame(   city = rep(c(\"New York\", \"Los Angeles\"), each = 6),   state_code = rep(c(\"NY\", \"CA\"), each = 6),   specialty_primary = c(     \"General Dermatology\", \"Pediatric Dermatology\", \"General Dermatology\",     \"General Dermatology\", \"Pediatric Dermatology\", \"General Dermatology\",     \"General Dermatology\", \"General Dermatology\", \"Pediatric Dermatology\",     \"General Dermatology\", \"General Dermatology\", \"Pediatric Dermatology\"   ),   phone_number = rep(c(\"123\", \"456\", \"789\"), 4) ) result <- city_state_sample_specialists(data) #> Error in city_state_sample_specialists(data): could not find function \"city_state_sample_specialists\" print(result) #> Error: object 'result' not found"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/phase0_create_sampled_by_region.html","id":null,"dir":"Reference","previous_headings":"","what":"Phase 0 Sample Creation by Region for Ortho Spine — phase0_create_sampled_by_region","title":"Phase 0 Sample Creation by Region for Ortho Spine — phase0_create_sampled_by_region","text":"function processes taxonomy AAOS data, merging Census Bureau data create sampled dataset grouped region ortho spine. Outputs saved CSV.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/phase0_create_sampled_by_region.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Phase 0 Sample Creation by Region for Ortho Spine — phase0_create_sampled_by_region","text":"","code":"phase0_create_sampled_by_region(   taxonomy_and_aaos_tbl,   census_bureau_tbl,   output_csv_path = \"ortho_spine/phase_0/sampled_by_region_ortho_spine.csv\" )"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/phase0_create_sampled_by_region.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Phase 0 Sample Creation by Region for Ortho Spine — phase0_create_sampled_by_region","text":"taxonomy_and_aaos_tbl tibble containing taxonomy AAOS data. census_bureau_tbl tibble containing Census Bureau data regional information. output_csv_path file path save sampled dataset. Defaults \"ortho_spine/phase_0/sampled_by_region_ortho_spine.csv\".","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/phase0_create_sampled_by_region.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Phase 0 Sample Creation by Region for Ortho Spine — phase0_create_sampled_by_region","text":"tibble sampled ortho spine records region.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/phase0_create_sampled_by_region.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Phase 0 Sample Creation by Region for Ortho Spine — phase0_create_sampled_by_region","text":"","code":"# Example 1: Basic usage with default output path sampled_data <- phase0_create_sampled_by_region(taxonomy_and_aaos_tbl, census_bureau_tbl) #> INFO [2025-01-03 03:53:44] Starting phase0_create_sampled_by_region. #> Error in (function (e) {    args <- paste0(capture.output(str(...)), collapse = \"\\n\")    stop(paste0(\"`glue` failed in `formatter_glue` on:\\n\\n\",         args, \"\\n\\nRaw error message:\\n\\n\", conditionMessage(e),         \"\\n\\nPlease consider using another `log_formatter` or \",         \"`skip_formatter` on strings with curly braces.\"))})(structure(list(message = \"Failed to evaluate glue component {nrow(taxonomy_and_aaos_tbl)}\",     trace = structure(list(call = list(pkgdown::build_site_github_pages(new_process = FALSE,         install = FALSE), build_site(pkg, preview = FALSE, install = install,         new_process = new_process, ...), build_site_local(pkg = pkg,         examples = examples, run_dont_run = run_dont_run, seed = seed,         lazy = lazy, override = override, preview = preview,         devel = devel), build_reference(pkg, lazy = lazy, examples = examples,         run_dont_run = run_dont_run, seed = seed, override = override,         preview = FALSE, devel = devel), unwrap_purrr_error(purrr::map(topics,         build_reference_topic, pkg = pkg, lazy = lazy, examples_env = examples_env,         run_dont_run = run_dont_run)), withCallingHandlers(code,         purrr_error_indexed = function(err) {            cnd_signal(err$parent)        }), purrr::map(topics, build_reference_topic, pkg = pkg,         lazy = lazy, examples_env = examples_env, run_dont_run = run_dont_run),         map_(\"list\", .x, .f, ..., .progress = .progress), with_indexed_errors(i = i,             names = names, error_call = .purrr_error_call, call_with_cleanup(map_impl,                 environment(), .type, .progress, n, names, i)),         withCallingHandlers(expr, error = function(cnd) {            if (i == 0L) {            }            else {                message <- c(i = \"In index: {i}.\")                if (!is.null(names) && !is.na(names[[i]]) &&                   names[[i]] != \"\") {                  name <- names[[i]]                  message <- c(message, i = \"With name: {name}.\")                }                else {                  name <- NULL                }                cli::cli_abort(message, location = i, name = name,                   parent = cnd, call = error_call, class = \"purrr_error_indexed\")            }        }), call_with_cleanup(map_impl, environment(), .type,             .progress, n, names, i), .f(.x[[i]], ...), withCallingHandlers(data_reference_topic(topic,             pkg, examples_env = examples_env, run_dont_run = run_dont_run),             error = function(err) {                cli::cli_abort(\"Failed to parse Rd in {.file {topic$file_in}}\",                   parent = err, call = quote(build_reference()))            }), data_reference_topic(topic, pkg, examples_env = examples_env,             run_dont_run = run_dont_run), run_examples(tags$tag_examples[[1]],             env = if (is.null(examples_env)) NULL else new.env(parent = examples_env),             topic = tools::file_path_sans_ext(topic$file_in),             run_dont_run = run_dont_run), highlight_examples(code,             topic, env = env), downlit::evaluate_and_highlight(code,             fig_save = fig_save_topic, env = eval_env, output_handler = handler),         evaluate::evaluate(code, child_env(env), new_device = TRUE,             output_handler = output_handler), withRestarts(with_handlers({            for (expr in tle$exprs) {                ev <- withVisible(eval(expr, envir))                watcher$capture_plot_and_output()                watcher$print_value(ev$value, ev$visible, envir)            }            TRUE        }, handlers), eval_continue = function() TRUE, eval_stop = function() FALSE,             eval_error = function(cnd) {                signalCondition(cnd)                stop(cnd)            }), withRestartList(expr, restarts), withOneRestart(withRestartList(expr,             restarts[-nr]), restarts[[nr]]), doWithOneRestart(return(expr),             restart), withRestartList(expr, restarts[-nr]), withOneRestart(withRestartList(expr,             restarts[-nr]), restarts[[nr]]), doWithOneRestart(return(expr),             restart), withRestartList(expr, restarts[-nr]), withOneRestart(expr,             restarts[[1L]]), doWithOneRestart(return(expr), restart),         with_handlers({            for (expr in tle$exprs) {                ev <- withVisible(eval(expr, envir))                watcher$capture_plot_and_output()                watcher$print_value(ev$value, ev$visible, envir)            }            TRUE        }, handlers), eval(call), eval(call), withCallingHandlers(code,             message = `<fn>`, warning = `<fn>`, error = `<fn>`),         withVisible(eval(expr, envir)), eval(expr, envir), eval(expr,             envir), phase0_create_sampled_by_region(taxonomy_and_aaos_tbl,             census_bureau_tbl), logger::log_info(\"Inputs provided: taxonomy_and_aaos_tbl with {nrow(taxonomy_and_aaos_tbl)} rows and {ncol(taxonomy_and_aaos_tbl)} columns.\"),         log_level(INFO, ..., namespace = namespace, .logcall = .logcall,             .topcall = .topcall, .topenv = .topenv), lapply(definitions,             function(definition) {                if (level > definition$threshold) {                  return(NULL)                }                log_fun <- do.call(logger, definition)                structure(do.call(log_fun, log_arg), class = \"logger\")            }), FUN(X[[i]], ...), structure(do.call(log_fun,             log_arg), class = \"logger\"), do.call(log_fun, log_arg),         `<fn>`(\"Inputs provided: taxonomy_and_aaos_tbl with {nrow(taxonomy_and_aaos_tbl)} rows and {ncol(taxonomy_and_aaos_tbl)} columns.\",             level = `<loglevel>`, .logcall = logger::log_info(\"Inputs provided: taxonomy_and_aaos_tbl with {nrow(taxonomy_and_aaos_tbl)} rows and {ncol(taxonomy_and_aaos_tbl)} columns.\"),             .topcall = phase0_create_sampled_by_region(taxonomy_and_aaos_tbl,                 census_bureau_tbl), .topenv = `<env>`, namespace = \"tyler\"),         do.call(formatter, c(res$params, list(.logcall = substitute(.logcall),             .topcall = substitute(.topcall), .topenv = .topenv))),         `<fn>`(\"Inputs provided: taxonomy_and_aaos_tbl with {nrow(taxonomy_and_aaos_tbl)} rows and {ncol(taxonomy_and_aaos_tbl)} columns.\",             .logcall = logger::log_info(\"Inputs provided: taxonomy_and_aaos_tbl with {nrow(taxonomy_and_aaos_tbl)} rows and {ncol(taxonomy_and_aaos_tbl)} columns.\"),             .topcall = phase0_create_sampled_by_region(taxonomy_and_aaos_tbl,                 census_bureau_tbl), .topenv = `<env>`), withCallingHandlers(glue::glue(...,             .envir = .topenv), error = function(e) {            args <- paste0(capture.output(str(...)), collapse = \"\\n\")            stop(paste0(\"`glue` failed in `formatter_glue` on:\\n\\n\",                 args, \"\\n\\nRaw error message:\\n\\n\", conditionMessage(e),                 \"\\n\\nPlease consider using another `log_formatter` or \",                 \"`skip_formatter` on strings with curly braces.\"))        }), glue::glue(..., .envir = .topenv), glue_data(.x = NULL,             ..., .sep = .sep, .envir = .envir, .open = .open,             .close = .close, .na = .na, .null = .null, .comment = .comment,             .literal = .literal, .transformer = .transformer,             .trim = .trim), `<fn>`(\"nrow(taxonomy_and_aaos_tbl)\"),         .transformer(expr, env) %||% .null, .transformer(expr,             env), with_glue_error(eval(expr, envir), paste0(\"Failed to evaluate glue component {\",             text, \"}\")), withCallingHandlers(expr, error = function(cnd) {            rlang::abort(message, parent = cnd, call = NULL)        }), eval(expr, envir), eval(expr, envir), nrow(taxonomy_and_aaos_tbl),         .handleSimpleError(`<fn>`, \"object 'taxonomy_and_aaos_tbl' not found\",             base::quote(eval(expr, envir))), h(simpleError(msg,             call)), rlang::abort(message, parent = cnd, call = NULL)),         parent = c(0L, 1L, 2L, 3L, 4L, 5L, 4L, 7L, 8L, 9L, 8L,         8L, 12L, 12L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L,         20L, 23L, 24L, 23L, 26L, 27L, 18L, 29L, 30L, 29L, 18L,         18L, 34L, 35L, 36L, 37L, 38L, 39L, 40L, 40L, 40L, 43L,         43L, 45L, 45L, 47L, 0L, 49L, 49L, 51L, 52L, 51L, 54L,         36L, 0L, 57L, 58L), visible = c(TRUE, TRUE, TRUE, TRUE,         TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE,         TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE,         TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE,         TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE,         TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE,         TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, FALSE, FALSE,         FALSE), namespace = c(\"pkgdown\", \"pkgdown\", \"pkgdown\",         \"pkgdown\", \"pkgdown\", \"base\", \"purrr\", \"purrr\", \"purrr\",         \"base\", \"purrr\", \"pkgdown\", \"base\", \"pkgdown\", \"pkgdown\",         \"pkgdown\", \"downlit\", \"evaluate\", \"base\", \"base\", \"base\",         \"base\", \"base\", \"base\", \"base\", \"base\", \"base\", \"base\",         \"evaluate\", \"base\", \"base\", \"base\", \"base\", \"base\", \"base\",         \"tyler\", \"logger\", \"logger\", \"base\", \"logger\", \"base\",         \"base\", \"logger\", \"base\", \"logger\", \"base\", \"glue\", \"glue\",         \"glue\", NA, \"glue\", \"glue\", \"base\", \"base\", \"base\", \"base\",         \"base\", \"glue\", \"rlang\"), scope = c(\"::\", \"::\", \":::\",         \"::\", \":::\", \"::\", \"::\", \":::\", \":::\", \"::\", \":::\", \"local\",         \"::\", \":::\", \":::\", \":::\", \"::\", \"::\", \"::\", \"local\",         \"local\", \"local\", \"local\", \"local\", \"local\", \"local\",         \"local\", \"local\", \":::\", \"::\", \"::\", \"::\", \"::\", \"::\",         \"::\", \"::\", \"::\", \"::\", \"::\", \"local\", \"::\", \"::\", \"local\",         \"::\", \"local\", \"::\", \"::\", \"::\", \"local\", NA, \"local\",         \":::\", \"::\", \"::\", \"::\", \"::\", \"::\", \"local\", \"::\")), row.names = c(NA,     -59L), version = 2L, class = c(\"rlang_trace\", \"rlib_trace\",     \"tbl\", \"data.frame\")), parent = structure(list(message = \"object 'taxonomy_and_aaos_tbl' not found\",         call = eval(expr, envir)), class = c(\"simpleError\", \"error\",     \"condition\")), rlang = list(inherit = TRUE), call = NULL), class = c(\"rlang_error\", \"error\", \"condition\"))): `glue` failed in `formatter_glue` on: #>  #>  chr \"Inputs provided: taxonomy_and_aaos_tbl with {nrow(taxonomy_and_aaos_tbl)} rows and {ncol(taxonomy_and_aaos_tbl)} columns.\" #>  #> Raw error message: #>  #> Failed to evaluate glue component {nrow(taxonomy_and_aaos_tbl)} #> Caused by error: #> ! object 'taxonomy_and_aaos_tbl' not found #>  #> Please consider using another `log_formatter` or `skip_formatter` on strings with curly braces.  # Example 2: Custom output path sampled_data <- phase0_create_sampled_by_region(taxonomy_and_aaos_tbl, census_bureau_tbl,                                                 output_csv_path = \"custom_path/sample.csv\") #> INFO [2025-01-03 03:53:44] Starting phase0_create_sampled_by_region. #> Error in (function (e) {    args <- paste0(capture.output(str(...)), collapse = \"\\n\")    stop(paste0(\"`glue` failed in `formatter_glue` on:\\n\\n\",         args, \"\\n\\nRaw error message:\\n\\n\", conditionMessage(e),         \"\\n\\nPlease consider using another `log_formatter` or \",         \"`skip_formatter` on strings with curly braces.\"))})(structure(list(message = \"Failed to evaluate glue component {nrow(taxonomy_and_aaos_tbl)}\",     trace = structure(list(call = list(pkgdown::build_site_github_pages(new_process = FALSE,         install = FALSE), build_site(pkg, preview = FALSE, install = install,         new_process = new_process, ...), build_site_local(pkg = pkg,         examples = examples, run_dont_run = run_dont_run, seed = seed,         lazy = lazy, override = override, preview = preview,         devel = devel), build_reference(pkg, lazy = lazy, examples = examples,         run_dont_run = run_dont_run, seed = seed, override = override,         preview = FALSE, devel = devel), unwrap_purrr_error(purrr::map(topics,         build_reference_topic, pkg = pkg, lazy = lazy, examples_env = examples_env,         run_dont_run = run_dont_run)), withCallingHandlers(code,         purrr_error_indexed = function(err) {            cnd_signal(err$parent)        }), purrr::map(topics, build_reference_topic, pkg = pkg,         lazy = lazy, examples_env = examples_env, run_dont_run = run_dont_run),         map_(\"list\", .x, .f, ..., .progress = .progress), with_indexed_errors(i = i,             names = names, error_call = .purrr_error_call, call_with_cleanup(map_impl,                 environment(), .type, .progress, n, names, i)),         withCallingHandlers(expr, error = function(cnd) {            if (i == 0L) {            }            else {                message <- c(i = \"In index: {i}.\")                if (!is.null(names) && !is.na(names[[i]]) &&                   names[[i]] != \"\") {                  name <- names[[i]]                  message <- c(message, i = \"With name: {name}.\")                }                else {                  name <- NULL                }                cli::cli_abort(message, location = i, name = name,                   parent = cnd, call = error_call, class = \"purrr_error_indexed\")            }        }), call_with_cleanup(map_impl, environment(), .type,             .progress, n, names, i), .f(.x[[i]], ...), withCallingHandlers(data_reference_topic(topic,             pkg, examples_env = examples_env, run_dont_run = run_dont_run),             error = function(err) {                cli::cli_abort(\"Failed to parse Rd in {.file {topic$file_in}}\",                   parent = err, call = quote(build_reference()))            }), data_reference_topic(topic, pkg, examples_env = examples_env,             run_dont_run = run_dont_run), run_examples(tags$tag_examples[[1]],             env = if (is.null(examples_env)) NULL else new.env(parent = examples_env),             topic = tools::file_path_sans_ext(topic$file_in),             run_dont_run = run_dont_run), highlight_examples(code,             topic, env = env), downlit::evaluate_and_highlight(code,             fig_save = fig_save_topic, env = eval_env, output_handler = handler),         evaluate::evaluate(code, child_env(env), new_device = TRUE,             output_handler = output_handler), withRestarts(with_handlers({            for (expr in tle$exprs) {                ev <- withVisible(eval(expr, envir))                watcher$capture_plot_and_output()                watcher$print_value(ev$value, ev$visible, envir)            }            TRUE        }, handlers), eval_continue = function() TRUE, eval_stop = function() FALSE,             eval_error = function(cnd) {                signalCondition(cnd)                stop(cnd)            }), withRestartList(expr, restarts), withOneRestart(withRestartList(expr,             restarts[-nr]), restarts[[nr]]), doWithOneRestart(return(expr),             restart), withRestartList(expr, restarts[-nr]), withOneRestart(withRestartList(expr,             restarts[-nr]), restarts[[nr]]), doWithOneRestart(return(expr),             restart), withRestartList(expr, restarts[-nr]), withOneRestart(expr,             restarts[[1L]]), doWithOneRestart(return(expr), restart),         with_handlers({            for (expr in tle$exprs) {                ev <- withVisible(eval(expr, envir))                watcher$capture_plot_and_output()                watcher$print_value(ev$value, ev$visible, envir)            }            TRUE        }, handlers), eval(call), eval(call), withCallingHandlers(code,             message = `<fn>`, warning = `<fn>`, error = `<fn>`),         withVisible(eval(expr, envir)), eval(expr, envir), eval(expr,             envir), phase0_create_sampled_by_region(taxonomy_and_aaos_tbl,             census_bureau_tbl, output_csv_path = \"custom_path/sample.csv\"),         logger::log_info(\"Inputs provided: taxonomy_and_aaos_tbl with {nrow(taxonomy_and_aaos_tbl)} rows and {ncol(taxonomy_and_aaos_tbl)} columns.\"),         log_level(INFO, ..., namespace = namespace, .logcall = .logcall,             .topcall = .topcall, .topenv = .topenv), lapply(definitions,             function(definition) {                if (level > definition$threshold) {                  return(NULL)                }                log_fun <- do.call(logger, definition)                structure(do.call(log_fun, log_arg), class = \"logger\")            }), FUN(X[[i]], ...), structure(do.call(log_fun,             log_arg), class = \"logger\"), do.call(log_fun, log_arg),         `<fn>`(\"Inputs provided: taxonomy_and_aaos_tbl with {nrow(taxonomy_and_aaos_tbl)} rows and {ncol(taxonomy_and_aaos_tbl)} columns.\",             level = `<loglevel>`, .logcall = logger::log_info(\"Inputs provided: taxonomy_and_aaos_tbl with {nrow(taxonomy_and_aaos_tbl)} rows and {ncol(taxonomy_and_aaos_tbl)} columns.\"),             .topcall = phase0_create_sampled_by_region(taxonomy_and_aaos_tbl,                 census_bureau_tbl, output_csv_path = \"custom_path/sample.csv\"),             .topenv = `<env>`, namespace = \"tyler\"), do.call(formatter,             c(res$params, list(.logcall = substitute(.logcall),                 .topcall = substitute(.topcall), .topenv = .topenv))),         `<fn>`(\"Inputs provided: taxonomy_and_aaos_tbl with {nrow(taxonomy_and_aaos_tbl)} rows and {ncol(taxonomy_and_aaos_tbl)} columns.\",             .logcall = logger::log_info(\"Inputs provided: taxonomy_and_aaos_tbl with {nrow(taxonomy_and_aaos_tbl)} rows and {ncol(taxonomy_and_aaos_tbl)} columns.\"),             .topcall = phase0_create_sampled_by_region(taxonomy_and_aaos_tbl,                 census_bureau_tbl, output_csv_path = \"custom_path/sample.csv\"),             .topenv = `<env>`), withCallingHandlers(glue::glue(...,             .envir = .topenv), error = function(e) {            args <- paste0(capture.output(str(...)), collapse = \"\\n\")            stop(paste0(\"`glue` failed in `formatter_glue` on:\\n\\n\",                 args, \"\\n\\nRaw error message:\\n\\n\", conditionMessage(e),                 \"\\n\\nPlease consider using another `log_formatter` or \",                 \"`skip_formatter` on strings with curly braces.\"))        }), glue::glue(..., .envir = .topenv), glue_data(.x = NULL,             ..., .sep = .sep, .envir = .envir, .open = .open,             .close = .close, .na = .na, .null = .null, .comment = .comment,             .literal = .literal, .transformer = .transformer,             .trim = .trim), `<fn>`(\"nrow(taxonomy_and_aaos_tbl)\"),         .transformer(expr, env) %||% .null, .transformer(expr,             env), with_glue_error(eval(expr, envir), paste0(\"Failed to evaluate glue component {\",             text, \"}\")), withCallingHandlers(expr, error = function(cnd) {            rlang::abort(message, parent = cnd, call = NULL)        }), eval(expr, envir), eval(expr, envir), nrow(taxonomy_and_aaos_tbl),         .handleSimpleError(`<fn>`, \"object 'taxonomy_and_aaos_tbl' not found\",             base::quote(eval(expr, envir))), h(simpleError(msg,             call)), rlang::abort(message, parent = cnd, call = NULL)),         parent = c(0L, 1L, 2L, 3L, 4L, 5L, 4L, 7L, 8L, 9L, 8L,         8L, 12L, 12L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L,         20L, 23L, 24L, 23L, 26L, 27L, 18L, 29L, 30L, 29L, 18L,         18L, 34L, 35L, 36L, 37L, 38L, 39L, 40L, 40L, 40L, 43L,         43L, 45L, 45L, 47L, 0L, 49L, 49L, 51L, 52L, 51L, 54L,         36L, 0L, 57L, 58L), visible = c(TRUE, TRUE, TRUE, TRUE,         TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE,         TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE,         TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE,         TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE,         TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE,         TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, FALSE, FALSE,         FALSE), namespace = c(\"pkgdown\", \"pkgdown\", \"pkgdown\",         \"pkgdown\", \"pkgdown\", \"base\", \"purrr\", \"purrr\", \"purrr\",         \"base\", \"purrr\", \"pkgdown\", \"base\", \"pkgdown\", \"pkgdown\",         \"pkgdown\", \"downlit\", \"evaluate\", \"base\", \"base\", \"base\",         \"base\", \"base\", \"base\", \"base\", \"base\", \"base\", \"base\",         \"evaluate\", \"base\", \"base\", \"base\", \"base\", \"base\", \"base\",         \"tyler\", \"logger\", \"logger\", \"base\", \"logger\", \"base\",         \"base\", \"logger\", \"base\", \"logger\", \"base\", \"glue\", \"glue\",         \"glue\", NA, \"glue\", \"glue\", \"base\", \"base\", \"base\", \"base\",         \"base\", \"glue\", \"rlang\"), scope = c(\"::\", \"::\", \":::\",         \"::\", \":::\", \"::\", \"::\", \":::\", \":::\", \"::\", \":::\", \"local\",         \"::\", \":::\", \":::\", \":::\", \"::\", \"::\", \"::\", \"local\",         \"local\", \"local\", \"local\", \"local\", \"local\", \"local\",         \"local\", \"local\", \":::\", \"::\", \"::\", \"::\", \"::\", \"::\",         \"::\", \"::\", \"::\", \"::\", \"::\", \"local\", \"::\", \"::\", \"local\",         \"::\", \"local\", \"::\", \"::\", \"::\", \"local\", NA, \"local\",         \":::\", \"::\", \"::\", \"::\", \"::\", \"::\", \"local\", \"::\")), row.names = c(NA,     -59L), version = 2L, class = c(\"rlang_trace\", \"rlib_trace\",     \"tbl\", \"data.frame\")), parent = structure(list(message = \"object 'taxonomy_and_aaos_tbl' not found\",         call = eval(expr, envir)), class = c(\"simpleError\", \"error\",     \"condition\")), rlang = list(inherit = TRUE), call = NULL), class = c(\"rlang_error\", \"error\", \"condition\"))): `glue` failed in `formatter_glue` on: #>  #>  chr \"Inputs provided: taxonomy_and_aaos_tbl with {nrow(taxonomy_and_aaos_tbl)} rows and {ncol(taxonomy_and_aaos_tbl)} columns.\" #>  #> Raw error message: #>  #> Failed to evaluate glue component {nrow(taxonomy_and_aaos_tbl)} #> Caused by error: #> ! object 'taxonomy_and_aaos_tbl' not found #>  #> Please consider using another `log_formatter` or `skip_formatter` on strings with curly braces.  # Example 3: Using a subset of census_bureau_tbl for faster testing sampled_data <- phase0_create_sampled_by_region(taxonomy_and_aaos_tbl,                                                 dplyr::filter(census_bureau_tbl, Region == \"West\"),                                                 output_csv_path = \"test/sample.csv\") #> INFO [2025-01-03 03:53:44] Starting phase0_create_sampled_by_region. #> Error in (function (e) {    args <- paste0(capture.output(str(...)), collapse = \"\\n\")    stop(paste0(\"`glue` failed in `formatter_glue` on:\\n\\n\",         args, \"\\n\\nRaw error message:\\n\\n\", conditionMessage(e),         \"\\n\\nPlease consider using another `log_formatter` or \",         \"`skip_formatter` on strings with curly braces.\"))})(structure(list(message = \"Failed to evaluate glue component {nrow(taxonomy_and_aaos_tbl)}\",     trace = structure(list(call = list(pkgdown::build_site_github_pages(new_process = FALSE,         install = FALSE), build_site(pkg, preview = FALSE, install = install,         new_process = new_process, ...), build_site_local(pkg = pkg,         examples = examples, run_dont_run = run_dont_run, seed = seed,         lazy = lazy, override = override, preview = preview,         devel = devel), build_reference(pkg, lazy = lazy, examples = examples,         run_dont_run = run_dont_run, seed = seed, override = override,         preview = FALSE, devel = devel), unwrap_purrr_error(purrr::map(topics,         build_reference_topic, pkg = pkg, lazy = lazy, examples_env = examples_env,         run_dont_run = run_dont_run)), withCallingHandlers(code,         purrr_error_indexed = function(err) {            cnd_signal(err$parent)        }), purrr::map(topics, build_reference_topic, pkg = pkg,         lazy = lazy, examples_env = examples_env, run_dont_run = run_dont_run),         map_(\"list\", .x, .f, ..., .progress = .progress), with_indexed_errors(i = i,             names = names, error_call = .purrr_error_call, call_with_cleanup(map_impl,                 environment(), .type, .progress, n, names, i)),         withCallingHandlers(expr, error = function(cnd) {            if (i == 0L) {            }            else {                message <- c(i = \"In index: {i}.\")                if (!is.null(names) && !is.na(names[[i]]) &&                   names[[i]] != \"\") {                  name <- names[[i]]                  message <- c(message, i = \"With name: {name}.\")                }                else {                  name <- NULL                }                cli::cli_abort(message, location = i, name = name,                   parent = cnd, call = error_call, class = \"purrr_error_indexed\")            }        }), call_with_cleanup(map_impl, environment(), .type,             .progress, n, names, i), .f(.x[[i]], ...), withCallingHandlers(data_reference_topic(topic,             pkg, examples_env = examples_env, run_dont_run = run_dont_run),             error = function(err) {                cli::cli_abort(\"Failed to parse Rd in {.file {topic$file_in}}\",                   parent = err, call = quote(build_reference()))            }), data_reference_topic(topic, pkg, examples_env = examples_env,             run_dont_run = run_dont_run), run_examples(tags$tag_examples[[1]],             env = if (is.null(examples_env)) NULL else new.env(parent = examples_env),             topic = tools::file_path_sans_ext(topic$file_in),             run_dont_run = run_dont_run), highlight_examples(code,             topic, env = env), downlit::evaluate_and_highlight(code,             fig_save = fig_save_topic, env = eval_env, output_handler = handler),         evaluate::evaluate(code, child_env(env), new_device = TRUE,             output_handler = output_handler), withRestarts(with_handlers({            for (expr in tle$exprs) {                ev <- withVisible(eval(expr, envir))                watcher$capture_plot_and_output()                watcher$print_value(ev$value, ev$visible, envir)            }            TRUE        }, handlers), eval_continue = function() TRUE, eval_stop = function() FALSE,             eval_error = function(cnd) {                signalCondition(cnd)                stop(cnd)            }), withRestartList(expr, restarts), withOneRestart(withRestartList(expr,             restarts[-nr]), restarts[[nr]]), doWithOneRestart(return(expr),             restart), withRestartList(expr, restarts[-nr]), withOneRestart(withRestartList(expr,             restarts[-nr]), restarts[[nr]]), doWithOneRestart(return(expr),             restart), withRestartList(expr, restarts[-nr]), withOneRestart(expr,             restarts[[1L]]), doWithOneRestart(return(expr), restart),         with_handlers({            for (expr in tle$exprs) {                ev <- withVisible(eval(expr, envir))                watcher$capture_plot_and_output()                watcher$print_value(ev$value, ev$visible, envir)            }            TRUE        }, handlers), eval(call), eval(call), withCallingHandlers(code,             message = `<fn>`, warning = `<fn>`, error = `<fn>`),         withVisible(eval(expr, envir)), eval(expr, envir), eval(expr,             envir), phase0_create_sampled_by_region(taxonomy_and_aaos_tbl,             dplyr::filter(census_bureau_tbl, Region == \"West\"),             output_csv_path = \"test/sample.csv\"), logger::log_info(\"Inputs provided: taxonomy_and_aaos_tbl with {nrow(taxonomy_and_aaos_tbl)} rows and {ncol(taxonomy_and_aaos_tbl)} columns.\"),         log_level(INFO, ..., namespace = namespace, .logcall = .logcall,             .topcall = .topcall, .topenv = .topenv), lapply(definitions,             function(definition) {                if (level > definition$threshold) {                  return(NULL)                }                log_fun <- do.call(logger, definition)                structure(do.call(log_fun, log_arg), class = \"logger\")            }), FUN(X[[i]], ...), structure(do.call(log_fun,             log_arg), class = \"logger\"), do.call(log_fun, log_arg),         `<fn>`(\"Inputs provided: taxonomy_and_aaos_tbl with {nrow(taxonomy_and_aaos_tbl)} rows and {ncol(taxonomy_and_aaos_tbl)} columns.\",             level = `<loglevel>`, .logcall = logger::log_info(\"Inputs provided: taxonomy_and_aaos_tbl with {nrow(taxonomy_and_aaos_tbl)} rows and {ncol(taxonomy_and_aaos_tbl)} columns.\"),             .topcall = phase0_create_sampled_by_region(taxonomy_and_aaos_tbl,                 dplyr::filter(census_bureau_tbl, Region == \"West\"),                 output_csv_path = \"test/sample.csv\"), .topenv = `<env>`,             namespace = \"tyler\"), do.call(formatter, c(res$params,             list(.logcall = substitute(.logcall), .topcall = substitute(.topcall),                 .topenv = .topenv))), `<fn>`(\"Inputs provided: taxonomy_and_aaos_tbl with {nrow(taxonomy_and_aaos_tbl)} rows and {ncol(taxonomy_and_aaos_tbl)} columns.\",             .logcall = logger::log_info(\"Inputs provided: taxonomy_and_aaos_tbl with {nrow(taxonomy_and_aaos_tbl)} rows and {ncol(taxonomy_and_aaos_tbl)} columns.\"),             .topcall = phase0_create_sampled_by_region(taxonomy_and_aaos_tbl,                 dplyr::filter(census_bureau_tbl, Region == \"West\"),                 output_csv_path = \"test/sample.csv\"), .topenv = `<env>`),         withCallingHandlers(glue::glue(..., .envir = .topenv),             error = function(e) {                args <- paste0(capture.output(str(...)), collapse = \"\\n\")                stop(paste0(\"`glue` failed in `formatter_glue` on:\\n\\n\",                   args, \"\\n\\nRaw error message:\\n\\n\", conditionMessage(e),                   \"\\n\\nPlease consider using another `log_formatter` or \",                   \"`skip_formatter` on strings with curly braces.\"))            }), glue::glue(..., .envir = .topenv), glue_data(.x = NULL,             ..., .sep = .sep, .envir = .envir, .open = .open,             .close = .close, .na = .na, .null = .null, .comment = .comment,             .literal = .literal, .transformer = .transformer,             .trim = .trim), `<fn>`(\"nrow(taxonomy_and_aaos_tbl)\"),         .transformer(expr, env) %||% .null, .transformer(expr,             env), with_glue_error(eval(expr, envir), paste0(\"Failed to evaluate glue component {\",             text, \"}\")), withCallingHandlers(expr, error = function(cnd) {            rlang::abort(message, parent = cnd, call = NULL)        }), eval(expr, envir), eval(expr, envir), nrow(taxonomy_and_aaos_tbl),         .handleSimpleError(`<fn>`, \"object 'taxonomy_and_aaos_tbl' not found\",             base::quote(eval(expr, envir))), h(simpleError(msg,             call)), rlang::abort(message, parent = cnd, call = NULL)),         parent = c(0L, 1L, 2L, 3L, 4L, 5L, 4L, 7L, 8L, 9L, 8L,         8L, 12L, 12L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L,         20L, 23L, 24L, 23L, 26L, 27L, 18L, 29L, 30L, 29L, 18L,         18L, 34L, 35L, 36L, 37L, 38L, 39L, 40L, 40L, 40L, 43L,         43L, 45L, 45L, 47L, 0L, 49L, 49L, 51L, 52L, 51L, 54L,         36L, 0L, 57L, 58L), visible = c(TRUE, TRUE, TRUE, TRUE,         TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE,         TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE,         TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE,         TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE,         TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE,         TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, FALSE, FALSE,         FALSE), namespace = c(\"pkgdown\", \"pkgdown\", \"pkgdown\",         \"pkgdown\", \"pkgdown\", \"base\", \"purrr\", \"purrr\", \"purrr\",         \"base\", \"purrr\", \"pkgdown\", \"base\", \"pkgdown\", \"pkgdown\",         \"pkgdown\", \"downlit\", \"evaluate\", \"base\", \"base\", \"base\",         \"base\", \"base\", \"base\", \"base\", \"base\", \"base\", \"base\",         \"evaluate\", \"base\", \"base\", \"base\", \"base\", \"base\", \"base\",         \"tyler\", \"logger\", \"logger\", \"base\", \"logger\", \"base\",         \"base\", \"logger\", \"base\", \"logger\", \"base\", \"glue\", \"glue\",         \"glue\", NA, \"glue\", \"glue\", \"base\", \"base\", \"base\", \"base\",         \"base\", \"glue\", \"rlang\"), scope = c(\"::\", \"::\", \":::\",         \"::\", \":::\", \"::\", \"::\", \":::\", \":::\", \"::\", \":::\", \"local\",         \"::\", \":::\", \":::\", \":::\", \"::\", \"::\", \"::\", \"local\",         \"local\", \"local\", \"local\", \"local\", \"local\", \"local\",         \"local\", \"local\", \":::\", \"::\", \"::\", \"::\", \"::\", \"::\",         \"::\", \"::\", \"::\", \"::\", \"::\", \"local\", \"::\", \"::\", \"local\",         \"::\", \"local\", \"::\", \"::\", \"::\", \"local\", NA, \"local\",         \":::\", \"::\", \"::\", \"::\", \"::\", \"::\", \"local\", \"::\")), row.names = c(NA,     -59L), version = 2L, class = c(\"rlang_trace\", \"rlib_trace\",     \"tbl\", \"data.frame\")), parent = structure(list(message = \"object 'taxonomy_and_aaos_tbl' not found\",         call = eval(expr, envir)), class = c(\"simpleError\", \"error\",     \"condition\")), rlang = list(inherit = TRUE), call = NULL), class = c(\"rlang_error\", \"error\", \"condition\"))): `glue` failed in `formatter_glue` on: #>  #>  chr \"Inputs provided: taxonomy_and_aaos_tbl with {nrow(taxonomy_and_aaos_tbl)} rows and {ncol(taxonomy_and_aaos_tbl)} columns.\" #>  #> Raw error message: #>  #> Failed to evaluate glue component {nrow(taxonomy_and_aaos_tbl)} #> Caused by error: #> ! object 'taxonomy_and_aaos_tbl' not found #>  #> Please consider using another `log_formatter` or `skip_formatter` on strings with curly braces."},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/physician_age.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate and Summarize Physician Age — physician_age","title":"Calculate and Summarize Physician Age — physician_age","text":"function calculates median age, well 25th 75th percentiles (Interquartile Range, IQR) specified age column data frame. returns sentence summarizing statistics.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/physician_age.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate and Summarize Physician Age — physician_age","text":"","code":"physician_age(df, age_column)"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/physician_age.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate and Summarize Physician Age — physician_age","text":"df data frame containing age data. age_column character string representing name column df contains age data.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/physician_age.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate and Summarize Physician Age — physician_age","text":"character string summarizing median age IQR specified age column dataset.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/physician_age.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Calculate and Summarize Physician Age — physician_age","text":"function calculates median, 25th percentile (Q1), 75th percentile (Q3) age data, rounding results two decimal places median one decimal place percentiles. constructs summary sentence describing statistics.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/physician_age.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate and Summarize Physician Age — physician_age","text":"","code":"# Example 1: Basic usage with a small dataset df <- data.frame(age = c(30, 40, 50, 60, 35, 45, 55, 65)) summary_sentence <- physician_age(df, \"age\") print(summary_sentence) #> [1] \"The median age of the dataset was 47.5 (IQR 25th percentile 38.8 to 75th percentile 56.2).\"  # Example 2: Handling missing data df_with_na <- data.frame(age = c(30, 40, NA, 60, 35, NA, 55, 65)) summary_sentence <- physician_age(df_with_na, \"age\") print(summary_sentence) #> [1] \"The median age of the dataset was 47.5 (IQR 25th percentile 36.2 to 75th percentile 58.8).\"  # Example 3: Different age distribution df_large <- data.frame(age = c(rep(30, 70), rep(40, 30), rep(50, 20), rep(60, 10))) summary_sentence <- physician_age(df_large, \"age\") print(summary_sentence) #> [1] \"The median age of the dataset was 30 (IQR 25th percentile 30 to 75th percentile 40).\""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/pipe.html","id":null,"dir":"Reference","previous_headings":"","what":"Pipe operator — %>%","title":"Pipe operator — %>%","text":"See magrittr::%>% details.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/pipe.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pipe operator — %>%","text":"","code":"lhs %>% rhs"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/pipe.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pipe operator — %>%","text":"lhs value magrittr placeholder. rhs function call using magrittr semantics.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/pipe.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Pipe operator — %>%","text":"result calling rhs(lhs).","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/plot_and_save_emmeans.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot and Save Estimated Marginal Means (EMMs) with Error Handling — plot_and_save_emmeans","title":"Plot and Save Estimated Marginal Means (EMMs) with Error Handling — plot_and_save_emmeans","text":"function computes estimated marginal means (EMMs) model object, creates plot EMMs confidence intervals, saves plot specified directory. includes robust error handling, detailed logging, default behaviors work box.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/plot_and_save_emmeans.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot and Save Estimated Marginal Means (EMMs) with Error Handling — plot_and_save_emmeans","text":"","code":"plot_and_save_emmeans(   model_object,   specs,   variable_of_interest,   color_by,   output_dir = \"Ari/Figures\",   y_min = NULL,   y_max = NULL )"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/plot_and_save_emmeans.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot and Save Estimated Marginal Means (EMMs) with Error Handling — plot_and_save_emmeans","text":"model_object fitted model object EMMs computed. can generalized linear model (GLM), linear model, suitable models. specs character string formula specifying predictor variable(s) EMMs computed. example, treatment groups, scenarios, demographic variables. variable_of_interest character string specifying variable plotted x-axis. Typically, specs parameter. color_by character string specifying variable used color points error bars. categorical variable gender, insurance type, academic affiliation. output_dir character string specifying directory plot saved. Defaults \"Ari/Figures\". y_min Minimum value y-axis. Defaults NULL, means calculated automatically data. y_max Maximum value y-axis. Defaults NULL, means calculated automatically data.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/plot_and_save_emmeans.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot and Save Estimated Marginal Means (EMMs) with Error Handling — plot_and_save_emmeans","text":"list containing estimated marginal means data (data) ggplot object (plot).","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/plot_and_save_emmeans.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plot and Save Estimated Marginal Means (EMMs) with Error Handling — plot_and_save_emmeans","text":"function logs data transformation, inputs, outputs, output files saved. uses emmeans package compute EMMs creates plot using ggplot2. function ensures logging key steps assist debugging auditing.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/plot_region_counts.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Regional Physician Counts by Specified Grouping — plot_region_counts","title":"Plot Regional Physician Counts by Specified Grouping — plot_region_counts","text":"function creates choropleth map visualizing physician counts region, options grouping states custom regions. handles merging state counts regional data, calculating centroids text labels, generating plots using ggplot2. Logging included provide insights execution flow data transformations.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/plot_region_counts.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Regional Physician Counts by Specified Grouping — plot_region_counts","text":"","code":"plot_region_counts(state_counts, region_df, region_col, save_path = NULL)"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/plot_region_counts.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Regional Physician Counts by Specified Grouping — plot_region_counts","text":"state_counts dataframe containing state-level physician counts. Must columns state_code (lowercase state names) total_available (numerical counts). region_df dataframe mapping states regions. Must include State (state names lowercase) column region grouping. region_col string specifying column region_df use grouping states regions (e.g., \"Region\"). save_path Optional. string specifying file path save plot image. NULL (default), plot displayed onscreen saved.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/plot_region_counts.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Regional Physician Counts by Specified Grouping — plot_region_counts","text":"ggplot object representing choropleth map.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/plot_region_counts.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plot Regional Physician Counts by Specified Grouping — plot_region_counts","text":"function merges state_counts region_df state name, aggregates physician counts region, maps counts onto choropleth. Labels representing counts added region centroids.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/plot_region_counts.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Regional Physician Counts by Specified Grouping — plot_region_counts","text":"","code":"# Example 1: Plot and save a map grouped by ENT_BOG regions ent_bog_regions <- data.frame(   State = c(\"alabama\", \"alaska\", \"arizona\"),   ENT_BOG_Region = c(\"Region 4\", \"Region 9\", \"Region 9\") ) state_counts <- data.frame(   state_code = c(\"alabama\", \"alaska\", \"arizona\"),   total_available = c(10, 15, 8) ) plot_region_counts(   state_counts = state_counts,   region_df = ent_bog_regions,   region_col = \"ENT_BOG_Region\",   save_path = \"ent_bog_region_map.png\" ) #> INFO [2025-01-03 03:53:45] Function `plot_region_counts` called with inputs: #> INFO [2025-01-03 03:53:45] state_counts dataframe with columns: state_code, total_available #> INFO [2025-01-03 03:53:45] region_df dataframe with columns: State, ENT_BOG_Region #> INFO [2025-01-03 03:53:45] Region column for grouping: ENT_BOG_Region #> INFO [2025-01-03 03:53:45] Save path specified: ent_bog_region_map.png #> INFO [2025-01-03 03:53:45] Transforming state codes in `state_counts` and `region_df` to lowercase. #> INFO [2025-01-03 03:53:45] Merging `state_counts` with `region_df` based on the State and `ENT_BOG_Region` columns. #> INFO [2025-01-03 03:53:45] Completed merge and aggregation. Resulting `state_counts_with_regions` has 2 rows. #> INFO [2025-01-03 03:53:45] Retrieving US state map data and converting region names to lowercase. #> Error in ggplot2::map_data(\"state\"): The package \"maps\" is required for `map_data()`.  # Example 2: Plot ACOG Districts without saving ACOG_Districts_sf <- data.frame(   State = c(\"california\", \"nevada\", \"utah\"),   ACOG_District = c(\"District IX\", \"District IX\", \"District VIII\") ) state_counts <- data.frame(   state_code = c(\"california\", \"nevada\", \"utah\"),   total_available = c(20, 12, 5) ) plot_region_counts(   state_counts = state_counts,   region_df = ACOG_Districts_sf,   region_col = \"ACOG_District\" ) #> INFO [2025-01-03 03:53:45] Function `plot_region_counts` called with inputs: #> INFO [2025-01-03 03:53:45] state_counts dataframe with columns: state_code, total_available #> INFO [2025-01-03 03:53:45] region_df dataframe with columns: State, ACOG_District #> INFO [2025-01-03 03:53:45] Region column for grouping: ACOG_District #> INFO [2025-01-03 03:53:45] No save path specified; plot will only display on screen. #> INFO [2025-01-03 03:53:45] Transforming state codes in `state_counts` and `region_df` to lowercase. #> INFO [2025-01-03 03:53:45] Merging `state_counts` with `region_df` based on the State and `ACOG_District` columns. #> INFO [2025-01-03 03:53:45] Completed merge and aggregation. Resulting `state_counts_with_regions` has 2 rows. #> INFO [2025-01-03 03:53:45] Retrieving US state map data and converting region names to lowercase. #> Error in ggplot2::map_data(\"state\"): The package \"maps\" is required for `map_data()`.  # Example 3: Plot custom regions and save output custom_regions <- data.frame(   State = c(\"texas\", \"new york\", \"florida\"),   Custom_Region = c(\"South\", \"Northeast\", \"South\") ) state_counts <- data.frame(   state_code = c(\"texas\", \"new york\", \"florida\"),   total_available = c(25, 17, 13) ) plot_region_counts(   state_counts = state_counts,   region_df = custom_regions,   region_col = \"Custom_Region\",   save_path = \"custom_region_map.png\" ) #> INFO [2025-01-03 03:53:45] Function `plot_region_counts` called with inputs: #> INFO [2025-01-03 03:53:45] state_counts dataframe with columns: state_code, total_available #> INFO [2025-01-03 03:53:45] region_df dataframe with columns: State, Custom_Region #> INFO [2025-01-03 03:53:45] Region column for grouping: Custom_Region #> INFO [2025-01-03 03:53:45] Save path specified: custom_region_map.png #> INFO [2025-01-03 03:53:45] Transforming state codes in `state_counts` and `region_df` to lowercase. #> INFO [2025-01-03 03:53:45] Merging `state_counts` with `region_df` based on the State and `Custom_Region` columns. #> INFO [2025-01-03 03:53:45] Completed merge and aggregation. Resulting `state_counts_with_regions` has 2 rows. #> INFO [2025-01-03 03:53:45] Retrieving US state map data and converting region names to lowercase. #> Error in ggplot2::map_data(\"state\"): The package \"maps\" is required for `map_data()`."},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/prepare_dataset.html","id":null,"dir":"Reference","previous_headings":"","what":"Prepare the Dataset by Excluding Certain Columns with Logging — prepare_dataset","title":"Prepare the Dataset by Excluding Certain Columns with Logging — prepare_dataset","text":"function prepares dataset excluding specified columns predictor variables. logs process, including inputs outputs.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/prepare_dataset.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prepare the Dataset by Excluding Certain Columns with Logging — prepare_dataset","text":"","code":"prepare_dataset(df, target_variable, excluded_columns)"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/prepare_dataset.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prepare the Dataset by Excluding Certain Columns with Logging — prepare_dataset","text":"df data frame containing dataset. target_variable string representing name target variable. excluded_columns vector strings representing names columns exclude predictors.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/prepare_dataset.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Prepare the Dataset by Excluding Certain Columns with Logging — prepare_dataset","text":"vector strings representing names predictor variables.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/process_and_save_isochrones.html","id":null,"dir":"Reference","previous_headings":"","what":"Process and Save Isochrones — process_and_save_isochrones","title":"Process and Save Isochrones — process_and_save_isochrones","text":"function takes input file locations, retrieves isochrones location, saves shapefiles. processes data chunks 25 rows time prevent data loss case errors.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/process_and_save_isochrones.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process and Save Isochrones — process_and_save_isochrones","text":"","code":"process_and_save_isochrones(input_file, chunk_size = 25)"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/process_and_save_isochrones.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process and Save Isochrones — process_and_save_isochrones","text":"input_file data frame containing location data columns \"lat\" \"long.\" input file represent geographic coordinates isochrones calculated. chunk_size number rows process chunk. Default 25.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/process_and_save_isochrones.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Process and Save Isochrones — process_and_save_isochrones","text":"sf (simple features) data frame containing isochrone polygons.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/process_and_save_isochrones.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Process and Save Isochrones — process_and_save_isochrones","text":"function uses hereR package calculate isochrones based provided geographic coordinates. retrieves isochrones location input file, processes data chunks minimize risk data loss case errors, saves isochrones shapefiles analysis.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/process_and_save_isochrones.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Process and Save Isochrones — process_and_save_isochrones","text":"","code":"# Load the input file (e.g., from a CSV) input_file <- read_csv(\"data/locations.csv\") #> Error in read_csv(\"data/locations.csv\"): could not find function \"read_csv\"  # Process and save isochrones for the input file (chunk size set to 25) isochrones_data <- process_and_save_isochrones(input_file, chunk_size = 25) #> Error in process_and_save_isochrones(input_file, chunk_size = 25): could not find function \"process_and_save_isochrones\"  # Optionally, write the combined isochrones to a shapefile sf::st_write(isochrones_data, dsn = \"data/isochrones/isochrones_all_combined\",              layer = \"isochrones\", driver = \"ESRI Shapefile\", quiet = FALSE) #> Error: object 'isochrones_data' not found"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/remove_constant_vars.html","id":null,"dir":"Reference","previous_headings":"","what":"Remove Constant Variables from a Data Frame — remove_constant_vars","title":"Remove Constant Variables from a Data Frame — remove_constant_vars","text":"function takes data frame returns new data frame constant variables removed.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/remove_constant_vars.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Remove Constant Variables from a Data Frame — remove_constant_vars","text":"","code":"remove_constant_vars(data_frame)"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/remove_constant_vars.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Remove Constant Variables from a Data Frame — remove_constant_vars","text":"data_frame data frame constant variables removed.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/remove_constant_vars.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Remove Constant Variables from a Data Frame — remove_constant_vars","text":"data frame constant variables removed.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/remove_constant_vars.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Remove Constant Variables from a Data Frame — remove_constant_vars","text":"","code":"if (FALSE) { # \\dontrun{ new_data <- remove_constant_vars(data_frame) } # }"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/remove_near_zero_var.html","id":null,"dir":"Reference","previous_headings":"","what":"Remove Near-Zero Variance Variables from a Data Frame — remove_near_zero_var","title":"Remove Near-Zero Variance Variables from a Data Frame — remove_near_zero_var","text":"function takes data frame returns new data frame near-zero variance variables removed.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/remove_near_zero_var.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Remove Near-Zero Variance Variables from a Data Frame — remove_near_zero_var","text":"","code":"remove_near_zero_var(data_frame, freqCut = 19, uniqueCut = 10)"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/remove_near_zero_var.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Remove Near-Zero Variance Variables from a Data Frame — remove_near_zero_var","text":"data_frame data frame near-zero variance variables removed. freqCut ratio common value second common value. Defaults 19. uniqueCut percentage distinct values number total samples. Defaults 10.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/remove_near_zero_var.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Remove Near-Zero Variance Variables from a Data Frame — remove_near_zero_var","text":"data frame near-zero variance variables removed.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/remove_near_zero_var.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Remove Near-Zero Variance Variables from a Data Frame — remove_near_zero_var","text":"","code":"if (FALSE) { # \\dontrun{ new_data <- remove_near_zero_var(data_frame) } # }"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/results_section_medicaid_summary.html","id":null,"dir":"Reference","previous_headings":"","what":"Results Section: Medicaid Summary with Logging and Error Handling — results_section_medicaid_summary","title":"Results Section: Medicaid Summary with Logging and Error Handling — results_section_medicaid_summary","text":"function generates summary sentence results section based significant predictor variables Medicaid acceptance rates. logs process, performs error checking, includes default behavior robust execution.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/results_section_medicaid_summary.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Results Section: Medicaid Summary with Logging and Error Handling — results_section_medicaid_summary","text":"","code":"results_section_medicaid_summary(   significant_predictors,   medicaid_acceptance_rate,   accepted_medicaid_count,   total_medicaid_physicians_count )"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/results_section_medicaid_summary.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Results Section: Medicaid Summary with Logging and Error Handling — results_section_medicaid_summary","text":"significant_predictors data frame containing significant predictor variables, directions, formatted p-values. columns: \"Variable\", \"Direction\", \"Formatted_P_Value\". medicaid_acceptance_rate numeric value representing Medicaid acceptance rate (percentage). accepted_medicaid_count integer representing count physicians accepting Medicaid. total_medicaid_physicians_count integer representing total count physicians considered Medicaid.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/results_section_medicaid_summary.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Results Section: Medicaid Summary with Logging and Error Handling — results_section_medicaid_summary","text":"character string representing summary sentence.","code":""},{"path":[]},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/results_section_summarize_common_provider_info.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarize the Most Common Gender, Specialty, Training, and Academic Affiliation in Provider Data — results_section_summarize_common_provider_info","title":"Summarize the Most Common Gender, Specialty, Training, and Academic Affiliation in Provider Data — results_section_summarize_common_provider_info","text":"function calculates returns summary sentence describing common gender, specialty, training, academic affiliation provided dataset. filters missing values column determining common value, calculates proportion common value relative total non-missing values column.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/results_section_summarize_common_provider_info.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarize the Most Common Gender, Specialty, Training, and Academic Affiliation in Provider Data — results_section_summarize_common_provider_info","text":"","code":"results_section_summarize_common_provider_info(   provider_info,   gender_col,   specialty_col,   training_col,   academic_affiliation_col )"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/results_section_summarize_common_provider_info.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarize the Most Common Gender, Specialty, Training, and Academic Affiliation in Provider Data — results_section_summarize_common_provider_info","text":"provider_info data frame containing provider information. gender_col Name column representing gender. specialty_col Name column representing specialty. training_col Name column representing training credentials. academic_affiliation_col Name column representing academic affiliation.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/results_section_summarize_common_provider_info.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summarize the Most Common Gender, Specialty, Training, and Academic Affiliation in Provider Data — results_section_summarize_common_provider_info","text":"character string summarizing common gender, specialty, training, academic affiliation along respective proportions.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/results_section_summarize_common_provider_info.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summarize the Most Common Gender, Specialty, Training, and Academic Affiliation in Provider Data — results_section_summarize_common_provider_info","text":"","code":"# Example usage with specified columns provider_info <- data.frame(   gender = c(\"Male\", \"Female\", \"Female\", \"Male\", \"Male\"),   specialty = c(\"Cardiology\", \"Cardiology\", \"Neurology\", \"Cardiology\", \"Neurology\"),   Provider.Credential.Text = c(\"MD\", \"MD\", \"DO\", \"MD\", \"DO\"),   academic_affiliation = c(\"Yes\", \"No\", \"Yes\", \"No\", \"Yes\") ) summarize_common_provider_info(   provider_info,   gender_col = \"gender\",   specialty_col = \"specialty\",   training_col = \"Provider.Credential.Text\",   academic_affiliation_col = \"academic_affiliation\" ) #> Error in summarize_common_provider_info(provider_info, gender_col = \"gender\",     specialty_col = \"specialty\", training_col = \"Provider.Credential.Text\",     academic_affiliation_col = \"academic_affiliation\"): could not find function \"summarize_common_provider_info\""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/results_section_wait_time_median_stats.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate Wait Time Statistics and Summary Sentences with Logging and Error Handling — results_section_wait_time_median_stats","title":"Generate Wait Time Statistics and Summary Sentences with Logging and Error Handling — results_section_wait_time_median_stats","text":"function calculates median wait time, 25th percentile (Q1), 75th percentile (Q3) business_days_until_appointment column overall grouped specified variable. logs step console includes error handling ensure robustness.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/results_section_wait_time_median_stats.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate Wait Time Statistics and Summary Sentences with Logging and Error Handling — results_section_wait_time_median_stats","text":"","code":"results_section_wait_time_median_stats(   appointment_data,   wait_time_col = \"business_days_until_appointment\",   group_var = NULL,   round_digits = 1 )"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/results_section_wait_time_median_stats.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate Wait Time Statistics and Summary Sentences with Logging and Error Handling — results_section_wait_time_median_stats","text":"appointment_data data frame containing appointment wait time data. wait_time_col Character string; name column representing wait time business days. group_var Character string; name column group grouped statistics (e.g., \"Subspecialty\"). NULL, overall statistics calculated. round_digits Integer; number decimal places round Q1 Q3 values.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/results_section_wait_time_median_stats.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate Wait Time Statistics and Summary Sentences with Logging and Error Handling — results_section_wait_time_median_stats","text":"list containing two tibbles: stat_summary tibble calculated statistics median wait time, Q1, Q3, Group. sentence_summary tibble summary sentences group.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/results_section_wait_time_median_stats.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate Wait Time Statistics and Summary Sentences with Logging and Error Handling — results_section_wait_time_median_stats","text":"","code":"# Example usage results <- results_section_wait_time_median_stats(   appointment_data = df,   wait_time_col = \"business_days_until_appointment\",   group_var = \"Subspecialty\",   round_digits = 1 ) #> INFO [2025-01-03 03:53:46] Starting wait time statistics calculation. #> INFO [2025-01-03 03:53:46]  #> INFO [2025-01-03 03:53:46] Error: Input must be a data frame. #> Error in results_section_wait_time_median_stats(appointment_data = df,     wait_time_col = \"business_days_until_appointment\", group_var = \"Subspecialty\",     round_digits = 1): Error: Input must be a data frame. results$stat_summary  # Contains statistical data #> Error: object 'results' not found results$sentence_summary  # Contains summary sentences #> Error: object 'results' not found"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/save_quality_check_table.html","id":null,"dir":"Reference","previous_headings":"","what":"Save Quality Check Table — save_quality_check_table","title":"Save Quality Check Table — save_quality_check_table","text":"function takes data frame containing 'npi' 'name' columns creates quality check table. table includes count observations 'npi' 'name' combination count greater 2. resulting table saved CSV file.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/save_quality_check_table.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Save Quality Check Table — save_quality_check_table","text":"","code":"save_quality_check_table(df, filepath)"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/save_quality_check_table.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Save Quality Check Table — save_quality_check_table","text":"df data frame containing columns 'npi' 'name'. filepath path CSV file saved.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/save_quality_check_table.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Save Quality Check Table — save_quality_check_table","text":"Prints message console indicating CSV file saved successfully.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/search_npi.html","id":null,"dir":"Reference","previous_headings":"","what":"Search NPI Numbers for Given Names — search_npi","title":"Search NPI Numbers for Given Names — search_npi","text":"function searches NPI (National Provider Identifier) numbers based given first last names. can accept input data form dataframe, CSV file, RDS file columns named 'first' 'last' representing first names last names, respectively.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/search_npi.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Search NPI Numbers for Given Names — search_npi","text":"","code":"search_npi(input_data)"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/search_npi.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Search NPI Numbers for Given Names — search_npi","text":"input_data dataframe, file path CSV, RDS file containing first last names.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/search_npi.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Search NPI Numbers for Given Names — search_npi","text":"dataframe containing NPI numbers provided names match specified taxonomies.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/search_npi.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Search NPI Numbers for Given Names — search_npi","text":"","code":"# Input as a dataframe input_df <- data.frame(   first = c(\"John\", \"Jane\", \"Alice\"),   last = c(\"Doe\", \"Smith\", \"Johnson\") ) npi_results <- search_npi(input_df) #> Error in validate_wildcard_rules(x): x must be a character vector with length 1  # Input as a CSV file input_csv <- \"path/to/input.csv\" npi_results <- search_npi(input_csv) #> Error: 'path/to/input.csv' does not exist in current working directory ('/home/runner/work/mystery/mystery/docs/reference')."},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/states_where_physicians_were_NOT_contacted.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarize States Where Physicians Were NOT Contacted — states_where_physicians_were_NOT_contacted","title":"Summarize States Where Physicians Were NOT Contacted — states_where_physicians_were_NOT_contacted","text":"function summarizes demographic details identifying states physicians successfully contacted included.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/states_where_physicians_were_NOT_contacted.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarize States Where Physicians Were NOT Contacted — states_where_physicians_were_NOT_contacted","text":"","code":"states_where_physicians_were_NOT_contacted(filtered_data, all_states = NULL)"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/states_where_physicians_were_NOT_contacted.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarize States Where Physicians Were NOT Contacted — states_where_physicians_were_NOT_contacted","text":"filtered_data data frame containing filtered data contacted physicians. all_states character vector possible states including Washington, DC. provided, default set states used.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/states_where_physicians_were_NOT_contacted.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summarize States Where Physicians Were NOT Contacted — states_where_physicians_were_NOT_contacted","text":"character string summarizing inclusion exclusion states.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/states_where_physicians_were_NOT_contacted.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summarize States Where Physicians Were NOT Contacted — states_where_physicians_were_NOT_contacted","text":"","code":"# Example with provided all_states filtered_data <- data.frame(state = c(\"California\", \"New York\", \"Texas\")) all_states <- c(\"Alabama\", \"Alaska\", \"Arizona\", \"Arkansas\", \"California\", \"Colorado\",                  \"Connecticut\", \"Delaware\", \"Florida\", \"Georgia\", \"Hawaii\", \"Idaho\",                  \"Illinois\", \"Indiana\", \"Iowa\", \"Kansas\", \"Kentucky\", \"Louisiana\",                  \"Maine\", \"Maryland\", \"Massachusetts\", \"Michigan\", \"Minnesota\",                  \"Mississippi\", \"Missouri\", \"Montana\", \"Nebraska\", \"Nevada\",                  \"New Hampshire\", \"New Jersey\", \"New Mexico\", \"New York\",                  \"North Carolina\", \"North Dakota\", \"Ohio\", \"Oklahoma\", \"Oregon\",                  \"Pennsylvania\", \"Rhode Island\", \"South Carolina\", \"South Dakota\",                  \"Tennessee\", \"Texas\", \"Utah\", \"Vermont\", \"Virginia\",                  \"Washington\", \"West Virginia\", \"Wisconsin\", \"Wyoming\",                  \"District of Columbia\") states_where_physicians_were_NOT_contacted(filtered_data, all_states) #> [1] \"Physicians were successfully contacted in 3 states including the District of Columbia. The excluded states include Alabama, Alaska, Arizona, Arkansas, Colorado, Connecticut, Delaware, Florida, Georgia, Hawaii, Idaho, Illinois, Indiana, Iowa, Kansas, Kentucky, Louisiana, Maine, Maryland, Massachusetts, Michigan, Minnesota, Mississippi, Missouri, Montana, Nebraska, Nevada, New Hampshire, New Jersey, New Mexico, North Carolina, North Dakota, Ohio, Oklahoma, Oregon, Pennsylvania, Rhode Island, South Carolina, South Dakota, Tennessee, Utah, Vermont, Virginia, Washington, West Virginia, Wisconsin, Wyoming and District of Columbia.\"  # Example with default all_states filtered_data <- data.frame(state = c(\"California\", \"New York\", \"Texas\", \"Nevada\")) states_where_physicians_were_NOT_contacted(filtered_data) #> [1] \"Physicians were successfully contacted in 4 states including the District of Columbia. The excluded states include Alabama, Alaska, Arizona, Arkansas, Colorado, Connecticut, Delaware, Florida, Georgia, Hawaii, Idaho, Illinois, Indiana, Iowa, Kansas, Kentucky, Louisiana, Maine, Maryland, Massachusetts, Michigan, Minnesota, Mississippi, Missouri, Montana, Nebraska, New Hampshire, New Jersey, New Mexico, North Carolina, North Dakota, Ohio, Oklahoma, Oregon, Pennsylvania, Rhode Island, South Carolina, South Dakota, Tennessee, Utah, Vermont, Virginia, Washington, West Virginia, Wisconsin, Wyoming and District of Columbia.\""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/taxonomy.html","id":null,"dir":"Reference","previous_headings":"","what":"Taxonomy Codes for Healthcare Providers — taxonomy","title":"Taxonomy Codes for Healthcare Providers — taxonomy","text":"dataset contains taxonomy codes healthcare providers, including classifications specializations, defined National Uniform Claim Committee (NUCC). particularly useful mapping provider types respective NUCC taxonomy codes.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/taxonomy.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Taxonomy Codes for Healthcare Providers — taxonomy","text":"","code":"taxonomy"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/taxonomy.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Taxonomy Codes for Healthcare Providers — taxonomy","text":"data frame 862 rows 3 variables: Code NUCC taxonomy code healthcare providers (e.g., \"101Y00000X\"). Classification general classification provider (e.g., \"Counselor\"). Specialization specific specialization within classification (e.g., \"Addiction (Substance Use Disorder)\"). May NA applicable.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/taxonomy.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Taxonomy Codes for Healthcare Providers — taxonomy","text":"NUCC taxonomy codes, version 23.0: https://www.nucc.org/images/stories/PDF/taxonomy_23_0.pdf","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/taxonomy.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Taxonomy Codes for Healthcare Providers — taxonomy","text":"dataset includes taxonomy codes across various provider types, limited Obstetricians Gynecologists. NUCC taxonomy widely used healthcare credentialing, claims processing, provider directories. dataset can assist linking provider specialties taxonomy codes research administrative purposes.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/taxonomy.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Taxonomy Codes for Healthcare Providers — taxonomy","text":"","code":"# Load the taxonomy dataset data(taxonomy)  # View the first few rows head(taxonomy) #> # A tibble: 6 × 3 #>   Code       Classification Specialization                     #>   <chr>      <chr>          <chr>                              #> 1 101Y00000X Counselor      NA                                 #> 2 101YA0400X Counselor      Addiction (Substance Use Disorder) #> 3 101YM0800X Counselor      Mental Health                      #> 4 101YP1600X Counselor      Pastoral                           #> 5 101YP2500X Counselor      Professional                       #> 6 101YS0200X Counselor      School                              # Filter for Obstetricians and Gynecologists obgyn_taxonomy <- taxonomy %>%   dplyr::filter(grepl(\"Obstetrics|Gynecology\", Classification, ignore.case = TRUE))  # Count the number of unique classifications dplyr::count(taxonomy, Classification) #> # A tibble: 241 × 2 #>    Classification                         n #>    <chr>                              <int> #>  1 Acupuncturist                          1 #>  2 Adult Companion                        1 #>  3 Advanced Practice Dental Therapist     1 #>  4 Advanced Practice Midwife              1 #>  5 Air Carrier                            1 #>  6 Allergy & Immunology                   3 #>  7 Alzheimer Center (Dementia Center)     1 #>  8 Ambulance                              4 #>  9 Anaplastologist                        1 #> 10 Anesthesiologist Assistant             1 #> # ℹ 231 more rows"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/test_and_process_isochrones.html","id":null,"dir":"Reference","previous_headings":"","what":"Test and Process Isochrones — test_and_process_isochrones","title":"Test and Process Isochrones — test_and_process_isochrones","text":"function tests processes isochrones location input file. identifies reports errors encountered isochrone retrieval process.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/test_and_process_isochrones.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Test and Process Isochrones — test_and_process_isochrones","text":"","code":"test_and_process_isochrones(input_file)"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/test_and_process_isochrones.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Test and Process Isochrones — test_and_process_isochrones","text":"input_file data frame containing location data columns \"lat\" \"long.\" input file represent geographic coordinates isochrones calculated.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/test_and_process_isochrones.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Test and Process Isochrones — test_and_process_isochrones","text":"Prints messages indicating errors, , isochrone retrieval.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/test_and_process_isochrones.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Test and Process Isochrones — test_and_process_isochrones","text":"function uses hereR package calculate isochrones based provided geographic coordinates. retrieves isochrones location input file, identifies errors retrieval process, reports errors. function designed used input data meets specific requirements, including valid latitude longitude values.","code":""},{"path":[]},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/tm_write2pdf.html","id":null,"dir":"Reference","previous_headings":"","what":"Save Arsenal Table to PDF — tm_write2pdf","title":"Save Arsenal Table to PDF — tm_write2pdf","text":"function saves Arsenal table PDF.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/tm_write2pdf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Save Arsenal Table to PDF — tm_write2pdf","text":"","code":"tm_write2pdf(object, filename)"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/tm_write2pdf.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Save Arsenal Table to PDF — tm_write2pdf","text":"object Arsenal table object. filename file path saving PDF.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/tyler-package.html","id":null,"dir":"Reference","previous_headings":"","what":"tyler: Common Functions for Mystery Caller or Audit Studies Evaluating Patient Access to Care — tyler-package","title":"tyler: Common Functions for Mystery Caller or Audit Studies Evaluating Patient Access to Care — tyler-package","text":"'tyler' package provides collection functions designed facilitate mystery caller studies, often used evaluating patient access healthcare. includes tools searching processing National Provider Identifier (NPI) numbers based names analyzing demographic data associated NPIs. package simplifies handling NPI data creation informative tables analysis reporting.","code":""},{"path":[]},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/validate_and_remove_invalid_npi.html","id":null,"dir":"Reference","previous_headings":"","what":"Validate and Remove Invalid NPI Numbers — validate_and_remove_invalid_npi","title":"Validate and Remove Invalid NPI Numbers — validate_and_remove_invalid_npi","text":"function reads CSV file containing NPI numbers, validates format using npi package, removes rows missing invalid NPIs.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/validate_and_remove_invalid_npi.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Validate and Remove Invalid NPI Numbers — validate_and_remove_invalid_npi","text":"","code":"validate_and_remove_invalid_npi(input_data)"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/validate_and_remove_invalid_npi.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Validate and Remove Invalid NPI Numbers — validate_and_remove_invalid_npi","text":"input_data Either dataframe containing NPI numbers path CSV file.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/validate_and_remove_invalid_npi.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Validate and Remove Invalid NPI Numbers — validate_and_remove_invalid_npi","text":"dataframe containing valid NPI numbers.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/validate_and_remove_invalid_npi.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Validate and Remove Invalid NPI Numbers — validate_and_remove_invalid_npi","text":"","code":"# Example usage: # input_data <- \"~/path/to/your/NPI/file.csv\" # valid_df <- validate_and_remove_invalid_npi(input_data)"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/write_output_csv.html","id":null,"dir":"Reference","previous_headings":"","what":"Write a Data Frame to CSV with Robust Logging and Error Handling — write_output_csv","title":"Write a Data Frame to CSV with Robust Logging and Error Handling — write_output_csv","text":"function writes data frame CSV file specified output directory. includes detailed logging inform user function's progress potential issues.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/write_output_csv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Write a Data Frame to CSV with Robust Logging and Error Handling — write_output_csv","text":"","code":"write_output_csv(   df,   filename,   output_dir = \"ortho_sports_med/Figures\",   verbose = TRUE )"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/write_output_csv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Write a Data Frame to CSV with Robust Logging and Error Handling — write_output_csv","text":"df data frame written CSV file. filename string specifying name output file (.csv extension). output_dir string specifying directory CSV file saved. Default \"ortho_sports_med/Figures\". verbose boolean indicating whether print detailed logs. Default TRUE.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/write_output_csv.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Write a Data Frame to CSV with Robust Logging and Error Handling — write_output_csv","text":"NULL. function saves CSV file specified location.","code":""},{"path":[]},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/write_output_csv.html","id":"key-features-of-the-function-","dir":"Reference","previous_headings":"","what":"Key Features of the Function:","title":"Write a Data Frame to CSV with Robust Logging and Error Handling — write_output_csv","text":"Directory Creation: specified output directory exist, function attempts create . Logging: Verbose logging informs user progress potential errors writing process. Error Handling: function handles errors invalid input types directory creation failures.","code":""},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/reference/write_output_csv.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Write a Data Frame to CSV with Robust Logging and Error Handling — write_output_csv","text":"","code":"# Example 1: Save a data frame to the default directory with detailed logging df <- data.frame(Name = c(\"John\", \"Jane\"), Age = c(30, 25)) write_output_csv(df, \"output.csv\") #> Output directory does not exist. Attempting to create directory: ortho_sports_med/Figures  #> File successfully saved to: ortho_sports_med/Figures/output.csv   # Example 2: Save a data frame to a custom directory without logging df <- data.frame(Product = c(\"Apple\", \"Banana\"), Price = c(1.2, 0.5)) write_output_csv(df, \"output.csv\", output_dir = \"custom/directory\", verbose = FALSE)  # Example 3: Save a large data frame with detailed logging df_large <- data.frame(ID = 1:1000, Value = rnorm(1000)) write_output_csv(df_large, \"large_output.csv\", output_dir = \"data/outputs\", verbose = TRUE) #> Output directory does not exist. Attempting to create directory: data/outputs  #> File successfully saved to: data/outputs/large_output.csv"},{"path":"https://mufflyt.github.io/tyler/mysteryshopper/news/index.html","id":"tyler-0009000","dir":"Changelog","previous_headings":"","what":"tyler 0.0.0.9000","title":"tyler 0.0.0.9000","text":"November 1, 2024 * narrowed focus package include mystery caller study functions. mapping isochrone functions kept separately. November 1, 2024 started better naming conventions named part project used: “nppes_” may helpful processing NPI file using duck database “phase0_” - Able gather data clean (genderize, standardize phone numbers, geocode) “clean_phase_1” - Sets confirmation calls. “phase2_” - Sets REDCap database inputs, quality control. “results_section_” - Creates prose results section. “figure_” - plotting data results section. “map_” - mapping data dot map honeycomb plot region. November 2, 2024 * continue struggle issues getting pkgdown website post github. looks like related use exploratory::statecode() function may public exportable @export? * hard time getting phase1 vignette post.","code":""}]
