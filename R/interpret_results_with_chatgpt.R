#' Interpret Poisson Regression Results Using ChatGPT
#'
#' This function sends Poisson regression results, including estimated wait times and their 95% confidence intervals,
#' to ChatGPT via the OpenAI API. ChatGPT processes the results and provides an interpretation, highlighting scenarios
#' with significantly higher or lower estimated wait times and offering insights based on the confidence intervals.
#'
#' @param stat_summary A tibble containing Poisson regression statistics for each group, including:
#'   \describe{
#'     \item{\code{Group}}{The name of the group or category.}
#'     \item{\code{median_wait_time}}{The median wait time (e.g., in business days) for the group.}
#'     \item{\code{wait_time_q1}}{The 25th percentile of wait time for the group.}
#'     \item{\code{wait_time_q3}}{The 75th percentile of wait time for the group.}
#'   }
#' @param sentence_summary A tibble containing pre-computed summary sentences for each group, explaining
#'   the estimated wait times and highlighting significant findings.
#'
#' @return A character string containing the interpretation of the Poisson regression results, as generated by ChatGPT.
#'
#' @details
#' The function converts the input tibbles into a JSON-compatible format and sends them to the OpenAI GPT-4 model
#' using the OpenAI API. ChatGPT analyzes the provided data and responds with a concise interpretation,
#' focusing on scenarios with statistically significant differences in estimated wait times.
#'
#' This function requires an active OpenAI API key to make requests. Ensure the environment variable
#' \code{OPENAI_API_KEY} is set before using this function.
#'
#' @note
#' Use this function with caution for sensitive data, as it relies on third-party APIs for interpretation.
#'
#' @importFrom httr POST content add_headers
#' @importFrom jsonlite toJSON fromJSON
#' @examples
#' \dontrun{
#' # Example: Using the function to interpret Poisson regression results
#' # Assume `results$stat_summary` and `results$sentence_summary` are precomputed tibbles.
#' interpretation <- interpret_results_with_chatgpt(
#'   stat_summary = results$stat_summary,
#'   sentence_summary = results$sentence_summary
#' )
#'
#' # Print the interpretation provided by ChatGPT
#' cat(interpretation)
#' }
#'
#' # Example: Constructing tibbles manually for demonstration
#' library(dplyr)
#' stat_summary <- tibble(
#'   Group = c("Group A", "Group B", "Group C"),
#'   median_wait_time = c(5, 10, 15),
#'   wait_time_q1 = c(4, 8, 12),
#'   wait_time_q3 = c(6, 12, 18)
#' )
#'
#' sentence_summary <- tibble(
#'   Group = c("Group A", "Group B", "Group C"),
#'   summary_sentence = c(
#'     "Group A has the shortest median wait time (5 days).",
#'     "Group B has a moderate wait time (10 days).",
#'     "Group C has the longest wait time (15 days)."
#'   )
#' )
#'
#' interpretation <- interpret_results_with_chatgpt(
#'   stat_summary = stat_summary,
#'   sentence_summary = sentence_summary
#' )
#' cat(interpretation)
#'
#' @keywords Poisson regression, ChatGPT, interpretation, wait time
interpret_results_with_chatgpt <- function(stat_summary, sentence_summary) {
  # Convert tibbles to JSON-compatible format
  stat_summary_json <- toJSON(stat_summary, pretty = TRUE)
  sentence_summary_json <- toJSON(sentence_summary, pretty = TRUE)

  # Define the prompt to send to ChatGPT
  prompt <- paste(
    "I have run an R function to calculate estimated wait times using Poisson regression for different scenarios,",
    "along with 95% confidence intervals. Here are the summarized results:\n",
    "Stat Summary:\n", stat_summary_json, "\n",
    "Sentence Summary:\n", sentence_summary_json, "\n",
    "Please provide an interpretation of these results, identifying scenarios with significantly higher or lower",
    "wait times compared to the overall estimate, and any insights based on the confidence intervals."
  )

  # Make the API call to ChatGPT
  response <- POST(
    url = "https://api.openai.com/v1/chat/completions",
    add_headers(Authorization = paste("Bearer", Sys.getenv("OPENAI_API_KEY"))),
    content_type("application/json"),
    body = toJSON(list(
      model = "gpt-4",
      messages = list(list(role = "user", content = prompt)),
      max_tokens = 300
    ), auto_unbox = TRUE)
  )

  # Parse the response
  result <- content(response, "text")
  result_json <- fromJSON(result)
  interpretation <- result_json$choices[[1]]$message$content

  # Return the interpretation
  return(interpretation)
}
