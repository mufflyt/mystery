#' Interpret Poisson Regression Results with ChatGPT
#'
#' This function sends Poisson regression results (wait time estimates and confidence intervals) to ChatGPT
#' via the OpenAI API for interpretation. ChatGPT returns a summary, identifying scenarios with
#' significantly higher or lower estimated wait times and providing insights based on the confidence intervals.
#'
#' @param stat_summary A tibble containing Poisson regression statistics for each group, including wait time estimates
#'                     and confidence intervals.
#' @param sentence_summary A tibble containing summary sentences for each group, explaining the estimated wait times.
#'
#' @return A character string containing the interpretation of the results generated by ChatGPT.
#' @examples
#' \dontrun{
#' # Example usage:
#' interpretation <- interpret_results_with_chatgpt(stat_summary = results$stat_summary,
#'                                                  sentence_summary = results$sentence_summary)
#' cat(interpretation)
#' }
#' @noRd
interpret_results_with_chatgpt <- function(stat_summary, sentence_summary) {
  # Convert tibbles to JSON-compatible format
  stat_summary_json <- toJSON(stat_summary, pretty = TRUE)
  sentence_summary_json <- toJSON(sentence_summary, pretty = TRUE)

  # Define the prompt to send to ChatGPT
  prompt <- paste(
    "I have run an R function to calculate estimated wait times using Poisson regression for different scenarios,",
    "along with 95% confidence intervals. Here are the summarized results:\n",
    "Stat Summary:\n", stat_summary_json, "\n",
    "Sentence Summary:\n", sentence_summary_json, "\n",
    "Please provide an interpretation of these results, identifying scenarios with significantly higher or lower",
    "wait times compared to the overall estimate, and any insights based on the confidence intervals."
  )

  # Make the API call to ChatGPT
  response <- POST(
    url = "https://api.openai.com/v1/chat/completions",
    add_headers(Authorization = paste("Bearer", Sys.getenv("OPENAI_API_KEY"))),
    content_type("application/json"),
    body = toJSON(list(
      model = "gpt-4",
      messages = list(list(role = "user", content = prompt)),
      max_tokens = 300
    ), auto_unbox = TRUE)
  )

  # Parse the response
  result <- content(response, "text")
  result_json <- fromJSON(result)
  interpretation <- result_json$choices[[1]]$message$content

  # Return the interpretation
  return(interpretation)
}
